

[toc]

# ä¸€ã€HiveåŸºæœ¬æ¦‚å¿µ

## 1.1ã€ä»€ä¹ˆæ˜¯Hive

**Hive**ï¼šæœ€æ—©ç”±Facebookå¼€æºç”¨äºè§£å†³**æµ·é‡ç»“æ„åŒ–æ—¥å¿—**çš„æ•°æ®ç»Ÿè®¡

> Hiveæ˜¯åŸºäºHadoopçš„ä¸€ä¸ª**æ•°æ®ä»“åº“å·¥å…·**ï¼Œå¯ä»¥å°†**ç»“æ„åŒ–çš„æ•°æ®æ–‡ä»¶æ˜ å°„æˆä¸ºä¸€å¼ è¡¨**ï¼Œå¹¶æä¾›**ç±»SQLçš„æŸ¥è¯¢åŠŸèƒ½**

==æœ¬è´¨ï¼šå°±æ˜¯å°†HQLï¼ˆHive Query Languageï¼‰è½¬åŒ–ä¸ºMapReduceç¨‹åº==

ç®€å•åŸç†å›¾ï¼š

![image-20200708104406002](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708104406002.png)

å…¶å®**æ•´ä¸ªè¿‡ç¨‹è¿˜æ˜¯è¦ä¾æ‰˜Hadoopçš„ç»„ä»¶æ¥å®Œæˆçš„ã€‚æ¯”å¦‚MapReduceçš„è¿è¡Œéœ€è¦Yarnæ¥è¿›è¡Œèµ„æºè°ƒåº¦ç®¡ç†ï¼Œè®¡ç®—çš„æ•°æ®å’Œç»“æœè¿˜æ˜¯å­˜æ”¾åœ¨HDFSä¸Š**ï¼Œæ‰€ä»¥ç°åœ¨å°±å¾ˆå¥½ç†è§£ä¸ºä»€ä¹ˆè¯´Hiveæ˜¯Hadoopçš„æ•°æ®ä»“åº“å·¥å…·äº†ã€‚

> æ€»ç»“ï¼š
>
> 1. Hiveçš„å¤„ç†æ•°æ®æ˜¯å­˜æ”¾åœ¨HDFSä¸Šçš„
> 2. Hiveåˆ†ææ•°æ®åº•å±‚çš„é»˜è®¤å®ç°æ˜¯MapReduceï¼ˆå¯ä»¥ä¿®æ”¹ï¼‰
> 3. æ‰§è¡Œç¨‹åºï¼ˆåº•å±‚æ˜¯MapReduceï¼‰æ˜¯è¿è¡Œåœ¨Yarnä¸Šçš„



## 1.2ã€Hiveçš„ä¼˜ç¼ºç‚¹

> ä¼˜ç‚¹

1. æ“ä½œæ¥å£é‡‡ç”¨**ç±»SQLçš„è¯­æ³•**ï¼Œç®€å•å®¹æ˜“ä¸Šæ‰‹
2. **é¿å…äº†å†™MapReduceç¨‹åº**ï¼Œé™ä½äº†å­¦ä¹ æˆæœ¬
3. Hiveç”±äºé‡‡ç”¨MRè¿›è¡Œæ•°æ®åˆ†æè®¡ç®—ï¼Œæ‰€ä»¥æ‰§è¡Œå»¶è¿Ÿè¾ƒé«˜ï¼Œ**é€‚ç”¨äºå¯¹å®æ—¶æ€§è¦æ±‚ä¸é«˜çš„åœºæ™¯**
4. **Hiveå–„äºå¤„ç†å¤§æ•°æ®ï¼Œä¸é€‚åˆå¤„ç†å°æ–‡ä»¶**ï¼Œå…¶å®æ˜¯MRçš„ä¼˜åŠ¿å’Œä¸è¶³
5. **Hiveæ”¯æŒç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°**ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„ä¸šåŠ¡éœ€è¦æ¥å®šåˆ¶è‡ªå·±çš„å‡½æ•°



> ç¼ºç‚¹

1. Hiveçš„HQLè¡¨è¾¾èƒ½åŠ›æœ‰é™ï¼Œä¸»è¦è¡¨ç°åœ¨ï¼š
   - å¯¹äº**è¿­ä»£å¼ç®—æ³•æ— æ³•è¡¨è¾¾**ï¼ˆè¿­ä»£å¼ç®—æ³•ï¼šå¯¹è®¡ç®—ç»“æœè¿›è¡Œè¿­ä»£å¤„ç†ï¼‰
   - **æ•°æ®æŒ–æ˜æ–¹é¢ä¸æ“…é•¿**ï¼ˆæ•°æ®æŒ–æ˜æœ¬è´¨å°±æ˜¯é€šè¿‡ä½¿ç”¨è¿­ä»£å¼ç®—æ³•ï¼‰
2. Hiveçš„æ•ˆç‡è¾ƒä½
   - Hiveè‡ªåŠ¨ç”Ÿæˆçš„MapReduceç¨‹åºï¼Œé€šå¸¸æƒ…å†µä¸‹**ä¸å¤Ÿæ™ºèƒ½åŒ–**ï¼ˆè‡ªåŠ¨ç”Ÿæˆçš„æ²¡æœ‰å…¨æ‰‹å†™çš„æ¥å¾—æ™ºèƒ½ï¼‰
   - Hiveçš„**è°ƒä¼˜æ¯”è¾ƒå›°éš¾**ï¼Œç²’åº¦è¾ƒç²—ï¼ˆå› ä¸ºæ˜¯ä½¿ç”¨MapReduceæ¨¡æ¿ï¼Œæ‰€ä»¥å³æ—¶è°ƒä¼˜ä¹Ÿä¸èƒ½ç²¾ç¡®åˆ°MapReduceçš„æ–¹æ³•ä¸­ï¼‰



## 1.3ã€Hiveæ¶æ„åŸç†

ç®€æ˜“æ¶æ„å›¾

![image-20200708132550467](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708132550467.png)

å…ˆä¸çœ‹HDFSå’ŒMapReduceã€‚æ•´ä¸ªHiveç»„æˆæ ¸å¿ƒå°±æ˜¯==è§£æå™¨ã€ç¼–è¯‘å™¨ã€ä¼˜åŒ–å™¨ã€æ‰§è¡Œå™¨ä»¥åŠå…ƒæ•°æ®å­˜å‚¨==

- CLIã€JDBCã€Driveréƒ½æ˜¯Hiveå¯¹å¤–å¼€æ”¾çš„ç”¨æˆ·æ“ä½œæ¥å£
- å…ƒæ•°æ®MateDataï¼šå­˜æ”¾Hiveé€šè¿‡æ˜ å°„HDFSä¸­æ–‡ä»¶ç”Ÿæˆè¡¨çš„ä¸€äº›æ•°æ®ï¼ŒåŒ…æ‹¬è¡¨åã€æ‰€å±æ•°æ®åº“ã€å­—æ®µå±æ€§ã€å­—æ®µåä»¥åŠè¡¨æ•°æ®çš„è·¯å¾„ç­‰ã€‚**é»˜è®¤å­˜å‚¨åœ¨è‡ªå¸¦çš„derbyæ•°æ®åº“ä¸­ï¼Œä½†æ˜¯æ¨èä½¿ç”¨MySQLè¿›è¡Œå­˜å‚¨å…ƒæ•°æ®**
- è§£æå™¨ï¼šä¸»è¦æ˜¯æ£€æŸ¥SQLçš„è¯­æ³•ä»¥åŠæ•°æ®åˆæ³•æ€§çš„æ£€æŸ¥
- ç¼–è¯‘å™¨ï¼šå°†è§£æé€šè¿‡çš„SQLï¼Œç»“åˆMapReduceçš„æ¨¡æ¿ç¿»è¯‘æˆå¯¹åº”çš„MapReduceç¨‹åºã€‚
- ä¼˜åŒ–å™¨ï¼šå¯¹è¦æ‰§è¡Œçš„ç¨‹åºè¿›è¡Œç®€å•çš„ä¼˜åŒ–å¤„ç†
- æ‰§è¡Œå™¨ï¼šæäº¤æ‰§è¡ŒMR



## 1.4ã€Hiveå¯¹æ¯”æ•°æ®åº“

ç”±äºHiveé‡‡ç”¨çš„ç±»SQLæŸ¥è¯¢è¯­è¨€ï¼Œä»¥åŠè¡¨ã€æ•°æ®ç±»å‹ã€æ•°æ®åº“ç­‰éƒ½å’Œæ•°æ®åº“æ¯”è¾ƒç›¸ä¼¼ï¼Œæ‰€ä»¥å¾ˆå®¹æ˜“è¯¯ä»¥ä¸ºHiveä¹Ÿæ˜¯ä¸€æ¬¾æ•°æ®åº“è½¯ä»¶ï¼Œå…¶å®Hiveåªæ˜¯é’ˆå¯¹Hadoopçš„ä¸€ä¸ªæ•°æ®ä»“åº“çš„å·¥å…·ï¼Œå’Œæ•°æ®åº“ç›¸æ¯”åŒºåˆ«è¿˜æ˜¯æ¯”è¾ƒå¤§çš„ã€‚

> æŸ¥è¯¢è¯­è¨€

Hiveï¼šHQLï¼ˆHive Query Languageï¼‰ï¼ŒMySQLï¼šSQLï¼ˆStructured Query Languageï¼‰ä¸¤è€…è™½ç„¶è¯­æ³•å¤§è‡´ç›¸åŒï¼Œä½†æ˜¯å‰è€…é’ˆå¯¹å¤§æ•°æ®ç¯å¢ƒï¼Œè¿˜æä¾›äº†ä¸€äº›ç‰¹æ®Šçš„åŠŸèƒ½è¯­æ³•ã€‚

> æ•°æ®çš„å­˜å‚¨ä½ç½®

Hiveæ˜¯å»ºç«‹åœ¨Hadoopä¹‹ä¸Šçš„ï¼Œæ‰€ä»¥Hiveçš„æ•°æ®éƒ½æ˜¯å­˜æ”¾åœ¨HDFSä¸Šçš„ã€‚è€Œæ•°æ®åº“åˆ™æ˜¯å°†æ•°æ®å­˜æ”¾åœ¨å—è®¾å¤‡æˆ–è€…æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸­ã€‚

> æ•°æ®æ›´æ–°

Hiveæ˜¯é’ˆå¯¹æ•°æ®ä»“åº“è®¾è®¡çš„ï¼Œè€Œæ•°æ®ä»“åº“ä¸­çš„å†…å®¹éƒ½æ˜¯å¤šè¯»å°‘å†™çš„ï¼Œæ‰€ä»¥Hiveå¯¹æ•°æ®çš„æ“ä½œåŸºæœ¬éƒ½æ˜¯æŸ¥è¯¢ï¼Œä¸å»ºè®®å¯¹å·²æœ‰çš„æ•°æ®è¿›è¡Œæ”¹å†™ï¼Œè€Œæ•°æ®åº“åˆ™æ˜¯é¢å‘ä¸ç”¨æˆ·äº¤äº’å¯¹æ•°æ®è¿›è¡Œå­˜æ”¾çš„ï¼Œæ‰€ä»¥æ•°æ®åº“å¯¹æ•°æ®çš„æ›´æ–°å°±åŒ…æ‹¬å¢åˆ æ”¹æŸ¥ã€‚

> ç´¢å¼•

MySQLä¸­ä½¿ç”¨æ•°æ®å­˜å‚¨å¼•æ“InnoDBæ˜¯æ”¯æŒç´¢å¼•çš„ï¼Œåœ¨æ•°æ®åº“ä¸­å»ºç«‹ç´¢å¼•ä¸»è¦æ˜¯ä¼˜åŒ–SQLçš„æŸ¥è¯¢é€Ÿåº¦ã€‚è€ŒHiveä¸­æ˜¯ä¸æ”¯æŒåˆ›å»ºç´¢å¼•çš„ï¼Œå³æ—¶æœ‰ç´¢å¼•åœ¨æµ·é‡æ•°æ®çš„åœºæ™¯ä¸‹ä¼˜åŒ–çš„å¹…åº¦ä¹Ÿä¸æ˜æ˜¾ã€‚

> æ‰§è¡Œ

Hiveçš„æœ¬è´¨æ˜¯å°†HQLè½¬åŒ–ä¸ºMRç¨‹åºè¿è¡Œï¼Œè€Œæ•°æ®åº“ä¸€èˆ¬éƒ½æœ‰è‡ªå·±çš„æ‰§è¡Œå¼•æ“ã€‚

> æ‰§è¡Œå»¶æ—¶

ç”±äºHiveæ˜¯é‡‡ç”¨MRè¿›è¡Œæ•°æ®åˆ†æè®¡ç®—ï¼Œæ‰€ä»¥MRæ…¢çš„ç‰¹æ€§å°±æé«˜äº†Hiveçš„æ‰§è¡Œå»¶æ—¶ã€‚è€ŒSQLçš„æ‰§è¡Œæ•ˆç‡ç›¸æ¯”è¾ƒæ¥è¯´åœ¨æ•°æ®é‡ç“¶é¢ˆä¹‹å‰è¦å¿«å¾—å¤šã€‚

> å¯æ‰©å±•æ€§

å¾—ç›ŠäºHadoopçš„ä¼˜è‰¯æ‰©å±•æ€§ï¼ŒHiveçš„æ‰©å±•æ€§ä¹Ÿç›¸åº”æå‡ï¼Œè€Œåè§‚æ•°æ®åº“æ‰©å±•æ€§å´ä¸é‚£ä¹ˆç†æƒ³ã€‚

> æ•°æ®è§„æ¨¡

Hiveèƒ½å¤„ç†çš„æ•°æ®éƒ½æ˜¯å¤§è§„æ¨¡çš„æ•°æ®ï¼Œè€Œæ•°æ®åº“çš„æ€§èƒ½ç“¶é¢ˆçš„åŸå› 2000ä¸‡æ¡æ•°æ®æ˜¯å•å°æ•°æ®åº“æ‰€èƒ½æ¥æ”¶çš„æœ€å¤§æ•°æ®é‡ã€‚



# äºŒã€Hiveå®‰è£…

[Hiveå®˜ç½‘](https://hive.apache.org/)ã€[å®˜æ–¹æ–‡æ¡£](https://cwiki.apache.org/confluence/display/Hive/GettingStarted)ã€[ä¸­æ–‡æ‰‹å†Œ](https://www.docs4dev.com/docs/zh/apache-hive/3.1.1/reference)ã€[ä¸‹è½½åœ°å€](https://hive.apache.org/downloads.html)

## 2.1ã€å®‰è£…åŒ…å‡†å¤‡

1. Hive 1.2.xï¼ˆå¯ä»¥å°è¯•æ–°ç‰ˆæœ¬2.3.xï¼‰

2. MySQLçš„ç›¸å…³å®‰è£…æ–‡ä»¶

   <img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708152609390.png" alt="image-20200708152609390" style="zoom:80%;" />

3. åˆ°è™šæ‹Ÿæœºä¸Šè§£å‹Hiveï¼šï¼ˆåˆå§‹ç›®å½•ç»“æ„ï¼‰

   

## 2.2ã€ç›¸å…³é…ç½®å’Œå¯åŠ¨

1. é¦–å…ˆç¡®ä¿Hadoopçš„ç¯å¢ƒé…ç½®æ²¡æœ‰é—®é¢˜

2. hiveçš„confç›®å½•ä¸­`hive-env.sh.template`æ–‡ä»¶ä¿®æ”¹

   ```shell
   export HADOOP_HOME=/opt/module/hadoop-2.7.7
   export HIVE_CONF_DIR=/opt/module/hive-2.3.7/conf
   ```

3. å¯åŠ¨Hadoopï¼ˆNNã€DNã€RMã€NMï¼‰

4. ä½¿ç”¨`bin/hive`å¯åŠ¨hiveå³å¯

   <img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708172753600.png" alt="image-20200708172753600" style="zoom:67%;" />
   
   å¯åŠ¨åç›®å½•ä¸­å¤šäº†`derby.log`ã€`metastore_db`æ–‡ä»¶ï¼Œæ˜¯å’Œå…ƒæ•°æ®å­˜å‚¨ç›¸å…³çš„æ–‡ä»¶ã€‚
   
5. æ‰§è¡Œä¸€äº›ç®€å•å‘½ä»¤ï¼š

   `show databases;`

   ![image-20200708173035042](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708173035042.png)

   `create table xxx(xx)`åˆ›å»ºä¸€å¼ è¡¨

   ![image-20200708173225910](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708173225910.png)

   `insert`æ’å…¥æ•°æ®

   ![image-20200708173436331](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708173436331.png)

   æˆ‘ä»¬åšä¸€æ¬¡æ•°æ®æ’å…¥ï¼Œä»–å±…ç„¶å¯åŠ¨äº†ä¸€ä¸ªMapReduce Jobï¼ï¼

   å¹¶ä¸”è¿˜åœ¨HDFSä¸­åˆ›å»ºäº†ä¸€äº›æ–‡ä»¶ç›®å½•ï¼š

   `/user/hive/warehouse/000000_0`ï¼Œä¸‹è½½è¿™ä¸ªæ–‡ä»¶æŸ¥çœ‹ï¼Œé‡Œé¢æ”¾ç€å°±æ˜¯æˆ‘ä»¬æ’å…¥çš„æ•°æ®

   ![shadow-image-20200708173937382](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708173937382.png)

   ![image-20200708174011703](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708174011703.png)

    

   `select`æŸ¥è¯¢æ•°æ®

   ![image-20200708174043316](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708174043316.png)

   `count(*)`ç»Ÿè®¡æ•°æ®æ•°

   ![image-20200708174235220](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708174235220.png)

   åªè¦æ˜¯è®¾è®¡æ•°æ®çš„å˜åŠ¨å’Œè®¡ç®—çš„éƒ½ä¼šå¯åŠ¨MapReduceè¿›è¡Œå¤„ç†ã€‚



## 2.3ã€æœ¬åœ°æ–‡ä»¶å¯¼å…¥Hive

è¦çŸ¥é“Hiveæ˜¯åº”ç”¨äºå¤§æ•°æ®åœºæ™¯ä¸‹çš„ï¼Œæ‰‹åŠ¨å½•å…¥æ•°æ®æ˜¾ç„¶æ˜¯ä¸å¯èƒ½çš„ï¼ŒHiveæä¾›äº†ä»æ–‡ä»¶å¯¼å…¥æ•°æ®åˆ°Hiveçš„åŠŸèƒ½ã€‚

### 2.3.1ã€Linuxæœ¬åœ°æ–‡ä»¶å¯¼å…¥

1. åœ¨Linuxæ–‡ä»¶ç³»ç»Ÿä¸­åˆ›å»ºä¸€ä¸ªstu.txtæ–‡ä»¶ï¼ˆ/opt/module/data/stu.txtï¼‰

   ```markdown
   2	lisi
   3	wangwu
   4	sonliu
   ```

   å­—æ®µä¹‹é—´ä»¥/tåˆ†éš”

2. åœ¨Hiveä¸­ä½¿ç”¨å‘½ä»¤ä»æœ¬åœ°å¯¼å…¥

   `load data local inpath â€˜/opt/module/data/stu.txtâ€™ into table student;`

   ![image-20200708180602505](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708180602505.png)

   ==æ³¨æ„ï¼šä»Linuxæœ¬åœ°å¯¼å…¥æ•°æ®è¦åœ¨load dataååŠ ä¸Š local ï¼ï¼==

3. å¯¼å…¥æ•°æ®åï¼Œå´æ„å¤–å‘ç°å¯¼å…¥çš„æ•°æ®æ— æ³•è¢«æ­£å¸¸è¯»å–åˆ°

   è¿™æ˜¯æ­£å¸¸æƒ…å†µï¼Œæ€»ä¸èƒ½è¯´éšä¾¿æ¥ä¸ªæ•°æ®åƒå¯¼å…¥å°±å¯¼å…¥å§ï¼**å¿…é¡»ä¿è¯æ•°æ®çš„æ ¼å¼å’Œå·²æœ‰çš„æ•°æ®æ–‡ä»¶æ ¼å¼ä¸€è‡´ï¼ï¼**æˆ‘ä»¬åœ¨åˆ›å»ºè¡¨çš„æ—¶å€™ï¼Œå¹¶æ²¡æœ‰è§„å®šæ•°æ®ä¹‹é—´ä»¥`\t`åˆ†å‰²ï¼Œè€Œé»˜è®¤æ˜¯<0x01>

   ![image-20200708181126674](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708181126674.png)

   å¾ˆæ˜æ˜¾ä¸¤ä¸ªæ–‡ä»¶çš„æ•°æ®æ ¼å¼å°±ä¸ä¸€æ ·ï¼

4. é‡æ–°å»ºè¡¨è§„å®šæ•°æ®æ ¼å¼

   `create table stu(id int, name string) row format delimited fields terminated by '\t';`

   è§„å®šå­—æ®µä¹‹é—´ä½¿ç”¨\tä½œä¸ºåˆ†éš”ç¬¦ã€‚

5. å†æ¬¡å¯¼å…¥æ•°æ®è¿›æ–°è¡¨

   ![image-20200708191020019](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708191020019.png)

6. å‘ç°HDFSä¸­å¯¹åº”è¡¨çš„æ•°æ®æ–‡ä»¶ä¸­å‡ºç°äº†stu.txtæ–‡ä»¶

   ![image-20200708191128303](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708191128303.png)

   > æ—¢ç„¶å°±æ˜¯å°†æ–‡ä»¶ç§»åŠ¨åˆ°äº†HDFSä¸­å¯¹åº”çš„æ–‡ä»¶å¤¹é‡Œé¢ï¼Œé‚£ä¹ˆæˆ‘ä»¬ä½¿ç”¨hdfså‘½ä»¤æ‰‹åŠ¨putæ–‡ä»¶åˆ°è¿™ä¸ªæ–‡ä»¶å¤¹ä¸­è¡Œä¸è¡Œå‘¢ï¼Ÿ

7. æ‰‹åŠ¨putæ–‡ä»¶åˆ°HDFSæµ‹è¯•

   - å‡†å¤‡æ–‡ä»¶ï¼ˆ/opt/module/data/stu2.txtï¼‰

     ```markdown
     5	xiaoming
     6	xiaohong
     7	xiaoqiang
     ```

   - HDFSå‘½ä»¤ä¸Šä¼ æ–‡ä»¶åˆ°/user/hive/warehouse/stu

     ![image-20200708191658260](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708191658260.png)

   - hiveæŸ¥è¯¢

     <img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708191744550.png" alt="image-20200708191744550" style="zoom:67%;" />

     æ²¡æœ‰æ¯›ç—…ï¼

   > åˆæ­¥åˆ¤æ–­æœ¬åœ°å¯¼å…¥æ•°æ®ï¼Œå°±æ˜¯å°†æœ¬åœ°çš„æ•°æ®æ‹·è´åˆ°äº†HDFSä¸Šçš„æ•°æ®ç›®å½•ä¸‹

---



### 2.3.2ã€HDFSæ–‡ä»¶å¯¼å…¥

åˆšæ‰æµ‹è¯•çš„æ˜¯ä»Linuxæ–‡ä»¶ç³»ç»Ÿå¯¼å…¥æ•°æ®ï¼Œç°åœ¨æˆ‘ä»¬ç›´æ¥åœ¨HDFSä¸Šå¯¼å…¥æ•°æ®ã€‚

1. å‡†å¤‡æ•°æ®å¯¼å…¥åˆ°HDFSï¼ˆhdfs:///stu3.txtï¼‰

   ```markdown
   8	aaa
   9	bbb
   10	ccc
   ```

   ![image-20200708192350386](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708192350386.png)

2. Hiveå¯¼å…¥æ•°æ®

   `load data inpath â€˜/stu3.txtâ€™ into table stu;`

3. æŸ¥è¯¢ç»“æœ

   <img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708192613119.png" alt="image-20200708192613119" style="zoom:80%;" />

4. ä½†æ˜¯è¹Šè··çš„äº‹æƒ…å‘ç”Ÿäº†ï¼šåŸæ•°æ®æ–‡ä»¶åœ¨HDFSä¸­ä¸è§äº†

   ![image-20200708192718514](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708192718514.png)

   ![image-20200708192811883](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708192811883.png)

   ä¸å‡ºæ„å¤–æ•°æ®è¿˜æ˜¯åœ¨Hiveçš„è¡¨æ•°æ®ç›®å½•ä¸­

   > éš¾é“çœŸçš„æ˜¯å‘ç”Ÿäº†æ•°æ®è¿ç§»ï¼Ÿ

   è¦çŸ¥é“è¿™ç§ç§»åŠ¨çš„æ•ˆæœåªæ˜¯åœ¨HDFSè¿™ä¸ªå¯è§†åŒ–ç•Œé¢ä¸Šäº§ç”Ÿï¼Œåœ¨Linuxçš„Hadoopä¸­æ•°æ®çš„ä½ç½®å¹¶æ²¡æœ‰å‘ç”Ÿå˜åŒ–ï¼Œæˆ‘ä»¬ä¹‹å‰è¯´çš„Hadoopçš„æ•°æ®å†…å®¹ä¸å…ƒæ•°æ®æ˜¯åˆ†ç¦»çš„å…ƒæ•°æ®æ”¾åœ¨NameNodeä¸­ï¼Œä¹Ÿå°±æ˜¯è¯´æƒ³è¦è¾¾åˆ°è§†è§‰ä¸Šçš„æ•°æ®ç§»åŠ¨ï¼Œåªéœ€è¦ä¿®æ”¹NameNodeä¸­stu3.txtæ–‡ä»¶çš„å…ƒæ•°æ®ï¼ˆä¸­çš„è·¯å¾„ï¼‰å³å¯ã€‚

   ![image-20200708193843632](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708193843632.png)

   çœŸå®çš„æ•°æ®å…¶å®ä¸€ç›´éƒ½åœ¨è¿™é‡Œæ²¡æœ‰åŠ¨ã€‚åªæ˜¯ä¿®æ”¹å…¶å…ƒæ•°æ®ä¸­çš„è·¯å¾„å±æ€§ã€‚

---



## 2.4ã€å®‰è£…MySQL

> ä¸ºä»€ä¹ˆå®‰è£…MySQLå‘¢ï¼Ÿ

é»˜è®¤ä½¿ç”¨derbyå­˜å‚¨å…ƒæ•°æ®ï¼Œä½†æ˜¯å­˜åœ¨ç¼ºé™·ï¼šåªå…è®¸åŒæ—¶ä¸€ä¸ªå®¢æˆ·ç«¯çª—å£è¿æ¥ï¼Œå¼€å¤šçª—å£çš„è¿æ¥hiveæ—¶æŠ¥é”™ï¼Œæ— æ³•è¿æ¥ï¼š

![image-20200708194936333](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708194936333.png)

æ‰€ä»¥æ”¹ç”¨MySQLæ¥å­˜å‚¨å…ƒæ•°æ®ã€‚

MySQLçš„å®‰è£…æ­¥éª¤å‚è€ƒï¼š[MySQLå­¦ä¹ ç¬”è®°](/home/sakura/æ–‡æ¡£/git-local-repo/StudyNote/Mysqlå­¦ä¹ æ–‡ä»¶/MySQLå­¦ä¹ ç¬”è®°.md)

==ä»…ä»…å®‰è£…é…ç½®MySQLè¿˜ä¸å¤Ÿï¼Œè¿˜éœ€è¦ä¸€ä¸ªMySQLçš„è¿æ¥é©±åŠ¨ï¼Œç¨åä¼šå°†å…¶è§£å‹æ–‡ä»¶ä¸­çš„é©±åŠ¨jaråŒ…åŠ å…¥åˆ°Hiveçš„libç›®å½•ä¸‹==

![image-20200708203755484](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708203755484.png)



> ä¿®æ”¹Hiveçš„é…ç½®æ–‡ä»¶ï¼ˆhive-site.xml(é¦–æ¬¡æ–°å»º)ï¼‰

[é…ç½®å‚è€ƒåšå®¢](https://www.jianshu.com/p/02ec73752e1c)

hive-site.xml

```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <!--MySQLè¿æ¥çš„URLï¼Œå­˜æ”¾å…ƒæ•°æ®çš„åº“ï¼šmetastore-->
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://hadoop102:3306/metastore?createDatabaseIfNotExist=true</value>
  </property>
 
  <!--è¿æ¥é©±åŠ¨çš„å®Œæ•´ç±»å-->
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.cj.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>
 
  <!--è¿æ¥ç”¨æˆ·å-->
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>root</value>
    <description>Username to use against metastore database</description>
  </property>
 
  <!--è¿æ¥çš„å¯†ç -->
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>hive</value>
    <description>password to use against metastore database</description>
  </property>
    
</configuration>
```

åœ¨hive-default.xmlä¸­é»˜è®¤ä½¿ç”¨çš„è¿æ¥é©±åŠ¨æ˜¯derby

![image-20200708205314112](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708205314112.png)



> é‡å¯æµ‹è¯•

é…ç½®å®Œæˆåï¼Œé‡å¯hiveï¼Œæ­¤æ—¶ä¼šå‘ç°ä¹‹å‰çš„æ‰€æœ‰æ•°æ®æ²¡æœ‰äº†ï¼Œ==è¡¨ç¤ºå…ƒæ•°æ®å·²ç»æˆåŠŸè¿ç§»åˆ°äº†MySQLä¸Šï¼==

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708210230594.png" alt="image-20200708210230594" style="zoom:50%;" />

æ­¤æ—¶å†å›åˆ°Hiveä¸­ï¼Œå°è¯•å¤šçª—å£å¯åŠ¨hiveä¹Ÿä¸ä¼šæŠ¥é”™äº†ï¼ï¼

==æ–°ç‰ˆæœ¬å¿…é¡»å…ˆè®¾ç½®å…ƒæ•°æ®å­˜æ”¾åœ¨MySQLï¼Œä½†æ˜¯ç›´æ¥é‡å¯åå¹¶æ²¡æœ‰ç”Ÿæˆå…ƒæ•°æ®åº“ï¼Œé€šè¿‡ç½‘ä¸ŠæŸ¥é˜…èµ„æ–™åï¼Œå‘ç°æ˜¯éœ€è¦ç”¨`bin/schematool -dbType mysql -initSchema`æ¥æ‰‹åŠ¨ç”Ÿæˆå…ƒæ•°æ®ï¼ï¼==



> æ¥çœ‹çœ‹Hiveå­˜æ”¾å†MySQLä¸­çš„å…ƒæ•°æ®

![image-20200708211220703](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708211220703.png)

é‡Œé¢ç©ºç©ºå¦‚ä¹Ÿï¼Œä¹Ÿå°±å¾ˆå¥½è§£é‡Šä¸ºä»€ä¹ˆæˆ‘ä»¬çš„Hiveä¸­æ²¡æœ‰æ•°æ®äº†ã€‚



## 2.5ã€Hiveçš„JDBCè®¿é—®ï¼ˆäº†è§£ï¼‰

> æœ‰åŠ©äºæˆ‘ä»¬åæœŸå­¦ä¹ ç¬¬ä¸‰æ–¹æ¡†æ¶ï¼Œæ¥æ›¿æ¢é»˜è®¤çš„MapReduce

å…ˆå‘Hiveä¸­æ·»åŠ ä¸€äº›æ•°æ®ã€‚

```shell
hive> select * from aaa;
OK
1
2
3
4
5
6
7
Time taken: 0.03 seconds, Fetched: 7 row(s)
```



1. å¯åŠ¨hiveserver2æœåŠ¡

   `bin/hiveserver2`(è¿™æ˜¯ä¸€ä¸ªé˜»å¡è¿›ç¨‹ï¼Œå½“æˆ‘ä»¬è¿æ¥ä¸Šè¿›è¡Œæ“ä½œæ—¶ä¼šè¾“å‡ºç›¸åº”çš„æç¤ºä¿¡æ¯)

2. å¯åŠ¨beeline

   `bin/beeline`

3. è¿æ¥hiveserver2

   beeline> `!connect jdbc:hive2://hadoop102:10000`

   è¾“å…¥ç”¨æˆ·åï¼šsakuraï¼Œå¯†ç ï¼šæ²¡æœ‰ä¸è¾“å…¥

4. è¿æ¥æˆåŠŸ

   <img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708232011311.png" alt="image-20200708232011311" style="zoom:67%;" />

   ä¸€è¾¹æ‰§è¡Œï¼Œhiveserver2çš„é˜»å¡è¿›ç¨‹ä¹Ÿåœ¨ä¸åœçš„è¾“å‡ºå‘½ä»¤çš„æ‰§è¡Œæƒ…å†µï¼š

   ![image-20200708232435801](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200708232435801.png)



## 2.6ã€Hiveå¸¸ç”¨äº¤äº’å‘½ä»¤

å½“å‰æˆ‘ä»¬ä½¿ç”¨Hiveå­˜åœ¨ä¸€äº›å±€é™ï¼ŒHiveçš„å‘½ä»¤è¡Œéƒ½æ˜¯åœ¨hiveçš„å‘½ä»¤è¡Œå»å®Œæˆï¼Œå¯æ˜¯æˆ‘ä»¬å¤„ç†æ•°æ®ä¸€èˆ¬åœ¨å‡Œæ™¨ä½¿ç”¨è„šæœ¬å»è‡ªåŠ¨å®Œæˆï¼Œé‚£èƒ½ä¸èƒ½==ä¸è¿›å…¥hiveåœ¨Linuxå‘½ä»¤è¡Œä¸­å°±å®ŒæˆHiveçš„å‘½ä»¤æ‰§è¡Œå‘¢ï¼Ÿ==

Hiveç»™å‡ºäº†ä¸¤ç§æ–¹æ¡ˆï¼š**æ‰§è¡Œå‘½ä»¤è¡Œä¸­çš„æŸ¥è¯¢è¯­å¥**ã€**æ‰§è¡Œæ–‡ä»¶ä¸­çš„æŸ¥è¯¢è¯­å¥**

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200709082810345.png" alt="image-20200709082810345" style="zoom:67%;" />

> ä»å‘½ä»¤è¡Œè¯»å–HQLæ‰§è¡Œ

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200709082954941.png" alt="image-20200709082954941" style="zoom:50%;" />

è™½ç„¶è¯´æ˜¯æœ‰ç‚¹æ…¢ï¼Œä½†æ˜¯ä¸å¿…è¿›å…¥Hiveå†å»æ‰§è¡ŒæŸ¥è¯¢äº†ã€‚

> ä»æ–‡ä»¶è¯»å–HQLæ‰§è¡Œ

åœ¨æ–‡ä»¶ä¸­å…ˆå†™å¥½è¦æ‰§è¡Œçš„æŸ¥è¯¢è¯­å¥ï¼Œä½¿ç”¨-fé€‰é¡¹åŠ ä¸Šæ–‡ä»¶è·¯å¾„æ‰§è¡Œå³å¯

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200709083322381.png" alt="image-20200709083322381" style="zoom:50%;" />



æœ‰äº†ä»¥ä¸Šä¸¤ç§æ–¹æ³•ï¼Œå°±å¯ä»¥æ–¹ä¾¿æˆ‘ä»¬ä½¿ç”¨å®šæ—¶ä»»åŠ¡å’Œè„šæœ¬æ¥è‡ªåŠ¨å®Œæˆä¸€äº›äº‹æƒ…ã€‚ä»¥ä¸Šçš„ä¸¤ä¸ªå‘½ä»¤éƒ½å¯ä»¥ä½¿ç”¨`>`å°†ç»“æœè¿½åŠ å†™å…¥åˆ°æ–‡ä»¶ä¸­ã€‚



> å…¶ä»–å‘½ä»¤

1. åœ¨Hiveå®¢æˆ·ç«¯ä¸­æ“ä½œHDFS

   `dfs -ls /xx/xx`(dfs -xx)

   ```shell
   hive> dfs -ls /;
   Found 2 items
   drwx-wx-wx   - sakura supergroup          0 2020-07-08 17:33 /tmp
   drwxr-xr-x   - sakura supergroup          0 2020-07-08 23:11 /user
   hive> dfs -ls /user;
   Found 2 items
   drwxr-xr-x   - sakura supergroup          0 2020-07-08 17:31 /user/hive
   drwx------   - sakura supergroup          0 2020-07-08 23:11 /user/sakura
   ```

2. åœ¨Hiveå®¢æˆ·ç«¯æ“ä½œæœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ

   `!ls /xx/xx`(!mkdirç­‰)

   ```shell
   hive> !ls .;
   bin
   conf
   derby.log
   examples
   hcatalog
   lib
   LICENSE
   metastore_db
   NOTICE
   README.txt
   RELEASE_NOTES.txt
   scripts
   ```

3. æŸ¥çœ‹ä½ hiveçš„å†å²æ‰§è¡Œå‘½ä»¤

   åœ¨å½“å‰ç”¨æˆ·çš„å®¶ç›®å½•ä¸­æœ‰ä¸€ä¸ª`.hivehistory`éšè—æ–‡ä»¶å¯ä»¥æŸ¥çœ‹

   ```shell
   [sakura@hadoop102 ~]$ cat .hivehistory
   show databases;
   show database;
   show tables;
   ```

---



## 2.7ã€Hiveå¸¸è§å±æ€§é…ç½®

### 2.7.1ã€å¸¸ç”¨é…ç½®å‚æ•°

ä»¥ä¸‹é…ç½®å‡å¯ä»¥åœ¨hive-default.xml.templateä¸­æ‰¾åˆ°ï¼Œä½†æ˜¯éœ€è¦==åœ¨hive-site.xmlä¸­è¿›è¡Œä¿®æ”¹==ï¼

> Defaultæ•°æ®åº“è¡¨æ•°æ®çš„å­˜æ”¾è·¯å¾„ï¼ˆé»˜è®¤ï¼šhdfs://hadoop102:9000/user/hive/warehouseï¼‰

```xml
<property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
    <description>location of default database for the warehouse</description>
</property>
```



> Hiveå‘½ä»¤è¡Œæ˜¾ç¤ºå½“å‰æ‰€åœ¨åº“ã€æŸ¥è¯¢è¾“å‡ºè¡¨å¤´ï¼ˆé»˜è®¤éƒ½æ˜¯å…³é—­(false)ï¼‰

```xml
<!--æ˜¾ç¤ºå½“å‰æ‰€åœ¨åº“-->
<property>
    <name>hive.cli.print.current.db</name>
    <value>true</value>
    <description>Whether to include the current database in the Hive prompt.</description>
</property>
<!--å¼€å¯è¡¨å¤´è¾“å‡º-->
<property>
    <name>hive.cli.print.header</name>
    <value>true</value>
    <description>Whether to print the names of the columns in query output.</description>
</property>
```



> æ—¥å¿—æ–‡ä»¶çš„è¾“å‡ºä½ç½®

1. é¦–å…ˆå°†confç›®å½•ä¸‹çš„**hive-log4j.properties.template**æ”¹ä¸º`hive-log4j.properties`

2. é»˜è®¤é…ç½®

   ```properties
   hive.log.dir=${java.io.tmpdir}/${user.name}
   hive.log.file=hive.log
   ```

   é»˜è®¤æ˜¯åœ¨`/tmp/sakura(ç”¨æˆ·å)`ç›®å½•ä¸‹ï¼Œæ–‡ä»¶åæ˜¯hive.log

   ![image-20200709091417200](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200709091417200.png)

   å¹¶ä¸”æ—¥å¿—æ–‡ä»¶æ˜¯**æŒ‰å¤©æ»šåŠ¨**çš„ã€‚

3. ä¿®æ”¹é…ç½®

   å°†æ—¥å¿—æ–‡ä»¶ä½ç½®æ”¹åˆ°`/opt/module/hive-1.2.2/logs/`

---

ä»¥ä¸Šé…ç½®å®Œæˆï¼Œé‡å¯hiveæŸ¥çœ‹å˜åŒ–ã€‚

![image-20200709091805054](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200709091805054.png)



### 2.7.2ã€ä¿®æ”¹é…ç½®çš„æ–¹å¼

==æ³¨æ„==ï¼šæ‰€æœ‰ç”¨æˆ·è‡ªå®šä¹‰çš„é…ç½®éƒ½ä¼šè¦†ç›–åŸæœ‰çš„é»˜è®¤é…ç½®ï¼Œå¹¶ä¸”Hiveä¼šè¯»å–Hadoopçš„é…ç½®ï¼Œæ‰€ä»¥Hiveä¸Šå¯¹Hadoopçš„å‚æ•°é…ç½®ä¹Ÿä¼šè¦†ç›–åŸæœ‰çš„Hadoopé…ç½®ã€‚



> Hiveå‘½ä»¤è¡ŒæŸ¥çœ‹ï¼Œä¿®æ”¹å‚æ•°`set`

åªæœ‰setï¼Œä¸èµ‹å€¼å°±æ˜¯æŸ¥çœ‹

```shell
hive (default)> set hadoop.tmp.dir;
hadoop.tmp.dir=/opt/module/hadoop-2.7.7/data/tmp
hive (default)> set mapred.reduce.tasks;
mapred.reduce.tasks=-1
```

setèµ‹å€¼åªæ˜¯ä¸´æ—¶ä¿®æ”¹ï¼Œ**ä»…åœ¨æœ¬å®¢æˆ·ç«¯æœ‰æ•ˆ**

```shell
hive (default)> set mapred.reduce.tasks=10;
hive (default)> set mapred.reduce.tasks;
mapred.reduce.tasks=10
```



> Linuxå‘½ä»¤è¡Œä¿®æ”¹ï¼ˆå¯åŠ¨æ—¶é…ç½®ï¼‰`--hiveconf property=value`

```shell
[sakura@hadoop102 hive-1.2.2]$ bin/hive --hiveconf mapred.reduce.tasks=2

Logging initialized using configuration in file:/opt/module/hive-1.2.2/conf/hive-log4j.properties
hive (default)> set mapred.reduce.tasks;
mapred.reduce.tasks=2
```

åŒæ ·è¿™ç§ä¹Ÿæ˜¯ä¸´æ—¶ä¿®æ”¹ï¼Œä»…æœ¬æ¬¡å¯åŠ¨æœ‰æ•ˆ



> é…ç½®æ–‡ä»¶è¦†ç›–

åˆ›å»ºçš„`hive-site.xml`ä¸­é…ç½®ä¿¡æ¯ä¼š**è¦†ç›–**HiveåŸæœ‰çš„hive-default.xmlä¸­çš„å¯¹åº”é…ç½®ï¼ï¼
ä¿®æ”¹hive-default.xml.templateæ˜¯æ¯«æ— æ„ä¹‰çš„ï¼ï¼





# ä¸‰ã€Hiveæ•°æ®ç±»å‹

## 3.1ã€åŸºæœ¬æ•°æ®ç±»å‹

|         Hiveæ•°æ®ç±»å‹          | Javaæ•°æ®ç±»å‹ | é•¿åº¦                                               |
| :---------------------------: | :----------: | -------------------------------------------------- |
|            tinyint            |     byte     | 1ä¸ªå­—èŠ‚æœ‰ç¬¦å·æ•´æ•°                                  |
|           smallint            |    short     | 2ä¸ªå­—èŠ‚æœ‰ç¬¦å·æ•´æ•°                                  |
|  <font color=red>int</font>   |     int      | 4ä¸ªå­—èŠ‚æœ‰ç¬¦å·æ•´æ•°                                  |
| <font color=red>bigint</font> |     long     | 8ä¸ªå­—èŠ‚æœ‰ç¬¦å·æ•´æ•°                                  |
|            boolean            |   boolean    | å¸ƒå°”ç±»å‹ï¼Œtrue or false                            |
|             float             |    float     | å•ç²¾åº¦æµ®ç‚¹æ•°                                       |
| <font color=red>double</font> |    double    | åŒç²¾åº¦æµ®ç‚¹æ•°                                       |
| <font color=red>string</font> |    String    | å­—ç¬¦ä¸²ç±»å‹ï¼Œä½¿ç”¨åŒå¼•å·æˆ–å•å¼•å·è¡¨ç¤ºï¼Œå¯ä»¥æŒ‡å®šå­—ç¬¦é›† |
|           timestamp           |              | æ—¶é—´æˆ³                                             |
|            binary             |              | å­—èŠ‚æ•°ç»„                                           |

==Hiveçš„æ•°æ®ç±»å‹æ˜¯å¤§å°å†™ä¸æ•æ„Ÿçš„==ï¼Œstringç±»å‹ç›¸å½“äºMySQLçš„varcharï¼Œæ˜¯ä¸å¯å˜çš„ï¼Œä¸èƒ½æŒ‡å®šå­˜å‚¨é•¿åº¦ï¼Œæœ€å¤šå¯ä»¥å­˜å‚¨2Gçš„å­—ç¬¦æ•°ã€‚



## 3.2ã€é›†åˆæ•°æ®ç±»å‹

| æ•°æ®ç±»å‹ | æè¿°                              | è¯­æ³•ç¤ºä¾‹             |
| -------- | --------------------------------- | -------------------- |
| struct   | ç»“æ„ä½“ç±»å‹ï¼Œç±»ä¼¼äºCè¯­è¨€ä¸­çš„ç»“æ„ä½“ | structName.fieldNmae |
| map      | é›†åˆMapç±»å‹ï¼Œä»¥KVå½¢å¼å­˜æ”¾æ•°æ®     | mapName[â€˜keyNameâ€™]   |
| array    | æ•°ç»„ç±»å‹ï¼ŒæŒ‰é¡ºåºå­˜å‚¨æ•°æ®          | arrayName[index]     |



## 3.3ã€æ•°æ®ç±»å‹è½¬æ¢

å’ŒJavaä¸€æ ·ï¼ŒHiveä¸­çš„æ•°æ®ç±»å‹ä¹Ÿæ”¯æŒéšå¼è½¬æ¢å’Œæ˜¾ç¤ºè½¬æ¢ï¼Œæ€»ä½“æ¥è¯´è½¬æ¢è§„åˆ™å¯ä»¥æ€»ç»“ä¸ºï¼š

==è¡¨ç¤ºèŒƒå›´å°çš„çš„æ•°æ®ç±»å‹å¯ä»¥å‘è¡¨ç¤ºèŒƒå›´å¤§çš„æ•°æ®ç±»å‹è½¬æ¢==

- tinyintã€smallintå¯ä»¥è½¬æ¢ä¸ºintï¼Œåä¹‹åˆ™ä¸è¡Œã€‚ï¼ˆä¸è¿‡å¯ä»¥ä½¿ç”¨cast()è¿›è¡Œå¼ºè½¬ï¼‰
- intã€floatã€stringåœ¨æ•°å€¼æ­£ç¡®çš„æƒ…å†µä¸‹å¯ä»¥è½¬æ¢ä¸ºdouble
- booleanç±»å‹ä¸æ”¯æŒæ•°æ®è½¬æ¢

åœ¨hiveå®¢æˆ·ç«¯å¯ä»¥ä½¿ç”¨`select cast(xx as xx)`æ¥å°è¯•åšæ•°æ®ç±»å‹è½¬æ¢

```shell
hive (default)> select cast('1' as int);
OK
_c0
1
Time taken: 0.189 seconds, Fetched: 1 row(s)
hive (default)> select cast('1.23' as double);
OK
_c0
1.23
```



## 3.4ã€é›†åˆæ•°æ®ç±»å‹å®æ“

ä¸Šé¢ä»‹ç»äº†é›†åˆæ•°æ®ç±»å‹ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•åœ¨è¡¨ä¸­è¿›è¡Œä½¿ç”¨å‘¢ï¼Ÿ

> æ•°æ®æ ¼å¼åŒ–é—®é¢˜

åœ¨Javaå¼€å‘ä¸­ä½¿ç”¨JSONä¼ é€’æ•°æ®ï¼ŒJSONå¯¹äºæ•°æ®æ ¼å¼è¦æ±‚ä¸¥æ ¼ï¼Œåªæœ‰==ç¬¦åˆæ•°æ®æ ¼å¼çš„æ•°æ®æ‰èƒ½è¢«æ­£ç¡®è§£æ==ã€‚è¿™é‡Œä¹Ÿæ˜¯ç›¸åŒçš„é“ç†ï¼Œè¦æƒ³Hiveèƒ½ä»æ–‡ä»¶ä¸­æ­£ç¡®è§£æå‡ºæ•°æ®å­˜å‚¨è¦åšå¥½ä¸¤ä»¶äº‹æƒ…ï¼š

- è§„å®šå¥½è¡¨æ•°æ®æ ¼å¼
- æŒ‰ç…§è§„å®šå¥½çš„æ ¼å¼ç¼–å†™æ•°æ®



> å»ºè¡¨å¹¶è§„å®šæ•°æ®æ ¼å¼

```sql
create table student(
    name string,
    friends array<string>,
    score map<string,int>,
    address struct<street:string, city:string>
)
--æ•°æ®æ ¼å¼è§„å®š--
row format delimited
fields terminated by ',' --å­—æ®µä½¿ç”¨ ',' åˆ†éš”--
collection items terminated by '_' --é›†åˆå…ƒç´ ä¹‹é—´ä½¿ç”¨ '_' åˆ†éš”--
map keys terminated by ':' --mapä¸­kvä¹‹é—´ä½¿ç”¨ ':' åˆ†éš”--
lines terminated by '\n'; --è¡Œæ•°æ®ä»¥ '\n' åˆ†éš”-- 
```

è§„å®šå¥½äº†è¡¨ä¸­æ•°æ®çš„æ ¼å¼åï¼Œå°±è¦æŒ‰ç…§è¦æ±‚å†™æ•°æ®äº†ã€‚



> æŒ‰è§„å®šå¯¹æ•°æ®æ ¼å¼åŒ–

æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹å¯¹åº”çš„æ•°æ®çš„JSONè¡¨è¾¾

```json
{
    "name": "sakura",
    "friends": ["zhangsan","lisi"],
    "score": [
        "math": 78,
        "computer": 80,
        "english": 71
    ],
    "address": {
        "street": "danyangdadao",
        "city": "yichang"
    }
}
```

æŒ‰ç…§æˆ‘ä»¬è§„å®šçš„æ ¼å¼å¯¹æ•°æ®è¿›è¡Œæ ¼å¼åŒ–åï¼š

```markdown
sakura,zhangsan_lisi,math:78_computer:80_english:71,danyangdadao_yichang
```

å°†æ ¼å¼åŒ–çš„æ•°æ®å†™åˆ°æ–‡ä»¶ä¸­ï¼Œåœ¨hiveä¸­ä»æ–‡ä»¶ä¸­åŠ è½½æ•°æ®æµ‹è¯•ï¼š

```shell
hive (default)> select * from student;
OK
student.name    student.friends student.score   student.address
sakura  ["zhangsan","lisi"]     {"math":78,"computer":80,"english":71}  {"street":"danyangdadao","city":"yichang"}
```

é—®é¢˜æ¥äº†ï¼Œæ•°æ®æ’å…¥æˆåŠŸäº†ï¼Œæˆ‘è¦æ€ä¹ˆå–å‡ºå¯¹åº”çš„è¿™äº›é›†åˆä¸­çš„æ•°æ®å‘¢ï¼Ÿ



> é›†åˆæ•°æ®æŸ¥è¯¢

- arrayæ•°æ®æŸ¥è¯¢`arrayName[index]`

  ```shell
  hive (default)> select friends[0],friends[1] from student;
  OK
  _c0     _c1
  zhangsan        lisi
  ```

  ç›´æ¥ä½¿ç”¨æ•°ç»„åå’Œä¸‹æ ‡å°±èƒ½å–åˆ°æ•°æ®ã€‚

  

- mapæ•°æ®æŸ¥è¯¢`mapName[keyName]`

  ```java
  hive (default)> select score['math'],score['english'] from student;
  OK
  _c0     _c1
  78      71
  ```

  ä½¿ç”¨mapååŠ ä¸Škeyå°±èƒ½å–åˆ°å¯¹åº”çš„valueå€¼ã€‚

  

- structå–å€¼`structName.fieldName`

  ```shell
  hive (default)> select address.city,address.street from student;
  OK
  city    street
  yichang danyangdadao
  ```

----



# å››ã€DDLæ•°æ®å®šä¹‰

DDL(Data Definition Language):æ•°æ®å®šä¹‰è¯­è¨€ï¼Œä¸»è¦ç”¨äºæ“ä½œæ•°æ®åº“åŸºæœ¬å¯¹è±¡ï¼ˆæ•°æ®åº“ã€è¡¨ç­‰ï¼‰

## 4.1ã€æ•°æ®åº“ç›¸å…³æ“ä½œ

> åˆ›å»ºæ•°æ®åº“

åœ¨Hiveä¸­æœ‰ä¸€ä¸ªåˆå§‹çš„æ•°æ®åº“ï¼š`default`ï¼Œæ•°æ®é»˜è®¤å­˜æ”¾ç›®å½•æ˜¯`/user/hive/warehouse`ã€‚

åˆ›å»ºæ•°æ®åº“çš„åŸºæœ¬å‘½ä»¤ï¼š`create databases dbName`
ä¸ºäº†å®‰å…¨èµ·è§ä¸€èˆ¬ä½¿ç”¨`create databases if not exists dbName`

```shell
hive (default)> create database if not exists firstdb;
OK
```

é»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ›å»ºçš„æ•°æ®åº“ç›®å½•æ”¾åœ¨/user/hive/warehouseç›®å½•ä¸‹ï¼Œä»¥ `æ•°æ®åº“å.db` å‘½åï¼ŒMySQLä¸­çš„å­˜æ”¾çš„å…ƒæ•°æ®ä¹Ÿè®°å½•äº†è¿™ä¸ªè·¯å¾„ 

![image-20200709213326451](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200709213326451.png)

åœ¨è¿™ä¸ªåº“ä¸‹åˆ›å»ºçš„æ‰€æœ‰è¡¨æ•°æ®éƒ½æ”¾åœ¨è¿™ä¸ªç›®å½•ä¸‹ã€‚



**Qï¼šå¯ä¸å¯ä»¥ä¿®æ”¹æ•°æ®åº“ç›®å½•çš„ä½ç½®å‘¢ï¼Ÿ**:accept:

åœ¨ä¹‹å‰çš„å‘½ä»¤çš„åŸºç¡€ä¸Šä½¿ç”¨`.. location â€˜pathâ€™`å³å¯æŒ‡å®šæ•°æ®åº“çš„æ•°æ®æ–‡ä»¶å­˜æ”¾è·¯å¾„

```shell
hive (default)> create database if not exists seconddb location '/hivedb/seconddb';
OK
```

å…ƒæ•°æ®ä¸­ä¹Ÿä¼šè®°å½•ä¸‹è¿™ä¸ªè·¯å¾„ï¼š

![image-20200709214424528](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200709214424528.png)

---



> æŸ¥è¯¢æ•°æ®åº“

- æ˜¾ç¤ºæ‰€æœ‰æ•°æ®åº“`show databases;`(ä¸ç”¨å¤šè¯´å§)

  ```shell
  hive (default)> show databases;
  OK
  database_name # è¿™ä¸ªæ˜¯è¡¨å¤´
  default
  firstdb
  seconddb
  ```

  ä¹Ÿå¯ä»¥è¿›è¡Œæ¨¡ç³ŠæŸ¥è¯¢æ˜¾ç¤ºå“¦ï¼(é€šé…ç¬¦å’Œmysqlä¸åŒ)

  ```shell
  hive (default)> show databases like '*db';
  OK
  database_name
  firstdb
  seconddb
  ```

- æ˜¾ç¤ºæ•°æ®åº“çš„è¯¦ç»†ä¿¡æ¯`desc database dbName;`

  ```shell
  hive (default)> desc database firstdb;
  OK
  db_name comment location        owner_name      owner_type      parameters
  firstdb         hdfs://hadoop102:9000/user/hive/warehouse/firstdb.db    sakura  USER
  
  hive (default)> desc database default;
  OK
  db_name comment location        owner_name      owner_type      parameters
  default Default Hive database   hdfs://hadoop102:9000/user/hive/warehouse       public  ROLE
  ```

  å…¶å®è¿™äº›ä¸œè¥¿å°±æ˜¯MySQLä¸­DBSè¡¨ä¸­å­˜æ”¾ä¸ªå„ä¸ªæ•°æ®åº“çš„å…ƒæ•°æ®

  ![image-20200709215232778](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200709215232778.png)

- æ˜¾ç¤ºæ•°æ®åº“å…¶ä»–æ‰©å±•ä¿¡æ¯`desc database extended dbName`

  åœ¨æ²¡æœ‰è®¾ç½®é¢å¤–ä¿¡æ¯çš„æ—¶å€™ï¼Œè¿™æ¡å‘½ä»¤çš„è¾“å‡ºå’Œå‰è€…æ˜¯ä¸€æ ·çš„ã€‚åœ¨ä¿®æ”¹æ•°æ®åº“ä¸­ä¼šä½¿ç”¨è¿™æ¡å‘½ä»¤ã€‚

---



> ä¿®æ”¹æ•°æ®åº“

è¿™é‡Œæ‰€è¯´çš„ä¿®æ”¹å…¶å®å¹¶ä¸æ˜¯å¯¹æ•°æ®åº“çš„å…ƒæ•°æ®è¿›è¡Œä¿®æ”¹ï¼Œï¼ˆæ¯”å¦‚==æ•°æ®å­˜æ”¾ä½ç½®ã€æ‰€æœ‰è€…ã€æ•°æ®åº“åç­‰è¿™äº›éƒ½æ˜¯ä¸æ”¯æŒä¿®æ”¹çš„==ï¼‰ï¼Œè¿™é‡Œçš„ä¿®æ”¹æ˜¯æŒ‡å¯¹æ•°æ®åº“çš„æ‰©å±•ä¿¡æ¯(DBPROPERTIES)å¢æ”¹é”®å€¼å¯¹ã€‚ä¹Ÿå°±æŸ¥è¯¢æ•°æ®åº“è¯¦ç»†ä¿¡æ¯ä¸­çš„parameterså­—æ®µã€‚

**Qï¼šé‚£ä¹ˆä»€ä¹ˆæ˜¯æ•°æ®åº“æ‰©å±•ä¿¡æ¯å‘¢ï¼Ÿ**

**Aï¼š**ç®€å•æ¥è¯´å°±æ˜¯é™¤äº†æ•°æ®åº“çš„å…ƒæ•°æ®ä¹‹å¤–ï¼Œäººä¸ºæ·»åŠ çš„ä¸€äº›æ•°æ®åº“ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼šåˆ›å»ºæ—¶é—´ç­‰ï¼‰ã€‚

ç°åœ¨æ¥å¢åŠ åˆ›å»ºä¸€æ¡æ‰©å±•ä¿¡æ¯ï¼š`alter database dbName set dbproperties('key'='value')`

```shell
hive (default)> alter database firstdb set dbproperties('createtime'='2020/07/09');
OK
```

åœ¨MySQLçš„`DATABASE_PARAMS`è¡¨ä¸­å°±ä¼šå­˜ä¸‹è¿™æ¡æ‰©å±•ä¿¡æ¯å¹¶è®°å½•è¿™æ˜¯å±äºå“ªä¸ªæ•°æ®åº“çš„ã€‚

![image-20200709220944237](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200709220944237.png)



ç°åœ¨æˆ‘ä»¬å†ä½¿ç”¨`desc database extended dbName`å°±å¯ä»¥çœ‹åˆ°è¿™æ¡æ‰©å±•ä¿¡æ¯äº†ï¼š

```shell
hive (default)> desc database extended firstdb;
OK
db_name comment location        owner_name      owner_type      parameters
firstdb         hdfs://hadoop102:9000/user/hive/warehouse/firstdb.db    sakura  USER    {createtime=2020/07/09}
```

---



> åˆ é™¤æ•°æ®åº“ï¼ˆå±ï¼ï¼‰

åˆ é™¤ç©ºæ•°æ®åº“ï¼š`drop database dbName;`ï¼Œä¿é™©èµ·è§åŠ ä¸Š`if exists`

```shell
hive (default)> drop database if exists seconddb;
Moved: 'hdfs://hadoop102:9000/hivedb/seconddb' to trash at: hdfs://hadoop102:9000/user/sakura/.Trash/Current
OK
```

åˆ é™¤æ•°æ®åº“çš„åŒæ—¶è¿˜ç§»é™¤äº†æ•°æ®åº“æ•°æ®ç›®å½•ï¼ˆå¥½è´´å¿ƒğŸ˜ï¼‰

å¦‚æœ==åˆ é™¤å°šå­˜æ•°æ®çš„æ•°æ®åº“ä½¿ç”¨dropæ˜¯æ— æ³•åˆ é™¤çš„==ï¼š

```shell
hive (firstdb)> drop database if exists firstdb;
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. InvalidOperationException(message:Database firstdb is not empty. One or more tables exist.)
# æç¤ºæ•°æ®åº“ä¸ä¸ºç©ºï¼Œå­˜åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªè¡¨
```

ä¸¤ç§åŠæ³•ï¼š

- å…ˆåˆ é™¤æ‰€æœ‰è¡¨ï¼Œç„¶ååˆ åº“ã€‚ï¼ˆå¤ªæ…¢äº†ï¼Œåˆ åº“è·‘è·¯è¦å¿«ï¼å¼€ç©ç¬‘ğŸ¤£ï¼‰
- ä½¿ç”¨`drop database dbName cascade;`(éœ¸ç‹ç¡¬ä¸Šå¼“ï¼Œå¼ºåˆ¶åˆ é™¤)

```shell
hive (firstdb)> drop database firstdb cascade;
Moved: 'hdfs://hadoop102:9000/user/hive/warehouse/firstdb.db/aaa' to trash at: hdfs://hadoop102:9000/user/sakura/.Trash/Current
Moved: 'hdfs://hadoop102:9000/user/hive/warehouse/firstdb.db' to trash at: hdfs://hadoop102:9000/user/sakura/.Trash/Current
OK
```

----



## 4.2ã€è¡¨ç›¸å…³æ“ä½œ

### 4.2.1ã€åˆ›å»ºè¡¨

==å»ºè¡¨è¯­æ³•ï¼ˆé‡è¦ï¼ï¼‰==

```sql
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name(
	col_name data_type [COMMENT 'col_comment'],
    ..
)[COMMENT 'table_comment']
[PARTITIONED BY (col_name data_type [COMMENT 'col_comment'],..)] --åˆ†åŒºç›¸å…³--
[CLUSTERED BY (col1_name, col2_name,..) 
 	[SORTED BY (col_name [ASC|DESC],..)] INTO num_buckets BUCKETS] --åˆ†æ¡¶ã€æ’åºç›¸å…³--
[ROW FORMAT row_format] --æ•°æ®æ–‡ä»¶è¡¨æ•°æ®æ ¼å¼è§„å®š--
[STORED AS file_format] --è¡¨æ•°æ®å¯¼å…¥æ–‡ä»¶æ ¼å¼è§„å®š--
[LOCATION hdfs_path] --è¡¨æ•°æ®å­˜å‚¨è·¯å¾„--
```

ä»¥ä¸Šå¤§å†™å­—æ¯å‡ä¸ºå…³é”®å­—ï¼Œ[]ä¸ºå¯é€‰é¡¹ã€‚

Hiveæä¾›äº†æŸ¥çœ‹è¡¨å®Œæ•´åˆ›å»ºè¯­å¥çš„å‘½ä»¤ï¼š`show create table table_name;`

```shell
hive (default)> show create table student;
OK
createtab_stmt
CREATE TABLE `student`(
  `name` string,
  `friends` array<string>,
  `score` map<string,int>,
  `address` struct<street:string,city:string>)
ROW FORMAT DELIMITED
  FIELDS TERMINATED BY ','
  COLLECTION ITEMS TERMINATED BY '_'
  MAP KEYS TERMINATED BY ':'
  LINES TERMINATED BY '\n'
STORED AS INPUTFORMAT
  'org.apache.hadoop.mapred.TextInputFormat'
OUTPUTFORMAT
  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION
  'hdfs://hadoop102:9000/user/hive/warehouse/student'
TBLPROPERTIES (
  'COLUMN_STATS_ACCURATE'='true',
  'numFiles'='1',
  'totalSize'='73',
  'transient_lastDdlTime'='1594264278')
```

é»˜è®¤è¡¨çš„æ•°æ®æ˜¯æ”¾åœ¨æ•°æ®åº“æ–‡ä»¶ç›®å½•ä¸‹çš„ï¼Œåœ¨å»ºè¡¨çš„æ—¶å€™å¯ä»¥ä½¿ç”¨`location`è¿›è¡ŒæŒ‡å®šã€‚
åœ¨å»ºè¡¨çš„æ—¶å€™å¯ä»¥ä½¿ç”¨`like`æ¥å¤åˆ¶æŸä¸€å¼ è¡¨çš„ç»“æ„ï¼Œè€Œä¸å¤åˆ¶æ•°æ®ã€‚



### 4.2.2ã€ç®¡ç†è¡¨(å†…éƒ¨è¡¨)å’Œå¤–éƒ¨è¡¨

**Qï¼šç®¡ç†è¡¨å’Œå¤–éƒ¨è¡¨ä¹‹é—´æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**

**Aï¼š**æˆ‘ä»¬åœ¨å»ºè¡¨è¯­æ³•ä¸­æœ‰ä¸€ä¸ªå…³é”®è¯`EXTERNAL`ï¼ŒåŠ ä¸Šè¿™ä¸ªå…³é”®è¯åˆ›å»ºçš„è¡¨å°±æ˜¯å¤–éƒ¨è¡¨ï¼Œåä¹‹åˆ™ä¸ºç®¡ç†è¡¨ã€‚å…¶å®å¾ˆå®¹æ˜“ç†è§£ï¼šè¡¨å…¶å®å°±æ˜¯ç”¨æ¥ç®¡ç†æ˜¾ç¤ºæ•°æ®çš„ï¼Œä¸€å¼ è¡¨çš„æ•°æ®åˆåˆ†ä¸ºè¡¨å®é™…æ•°æ®ï¼ˆå­˜å‚¨åœ¨HDFSï¼‰å’Œè¡¨ä¿¡æ¯å…ƒæ•°æ®ï¼ˆå­˜åœ¨MySQLï¼‰ã€‚

==ç®¡ç†è¡¨ï¼ˆå†…éƒ¨è¡¨ï¼‰è®¤ä¸ºå®é™…æ•°æ®å’Œå…ƒæ•°æ®éƒ½ç”±æˆ‘ä¸€æ‰‹ç®¡ç†ï¼Œåœ¨åˆ é™¤è¡¨çš„æ—¶å€™å…ƒæ•°æ®å’Œå®é™…æ•°æ®ä¸€å¹¶åˆ é™¤ï¼==ï¼ˆä¹Ÿå°±æ˜¯å¹³æ—¶æˆ‘ä»¬åˆ è¡¨çš„æ—¶å€™ï¼Œå­˜æ”¾åœ¨MySQLä¸­çš„å…ƒæ•°æ®å’ŒHDFSä¸Šçš„æ•°æ®æ–‡ä»¶ç»Ÿç»Ÿåˆ é™¤ï¼‰

==å¤–éƒ¨è¡¨åˆ™è®¤ä¸ºåªæ˜¯ç®¡ç†ä¸€å¼ è¡¨çš„å…ƒæ•°æ®ï¼ŒçœŸå®æ•°æ®ä¸ç”±æˆ‘æŒæ§ï¼Œæˆ‘åˆ è¡¨çš„æ—¶å€™æŠŠè‡ªå·±çš„å…ƒæ•°æ®åˆ å¹²å‡€å°±è¡Œï¼==ï¼ˆè¿™ç§æƒ…å†µä¸‹ï¼ŒMySQLä¸­è¡¨çš„å…ƒæ•°æ®ä¼šè¢«åˆ é™¤ï¼Œä½†æ˜¯å…ƒæ•°æ®æŒ‡å‘çš„çœŸå®æ•°æ®ç›®å½•å¹¶æ²¡æœ‰åˆ é™¤ï¼‰



**å®è·µæµ‹è¯•ï¼ˆåˆ é™¤å¤–éƒ¨è¡¨ï¼‰**

1. åˆ›å»ºå¤–éƒ¨è¡¨

   ```shell
   hive (default)> create external table test (id int);
   OK
   ```

2. å¯¼å…¥æ•°æ®åï¼Œæˆ‘ä»¬åˆ°HDFSä¸ŠæŸ¥çœ‹è¡¨çš„æ•°æ®æ–‡ä»¶

   ![image-20200710093307224](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200710093307224.png)

   MySQLä¸­è¡¨çš„å…ƒæ•°æ®

   <img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200710093514584.png" alt="image-20200710093514584" style="zoom: 50%;" />

   å¯ä»¥çœ‹åˆ°å¤–éƒ¨è¡¨ç›¸å¯¹äºç®¡ç†è¡¨æ¥è¯´è¿˜æ˜¯å­˜åœ¨ä¸€äº›åŒºåˆ«çš„ï¼

3. å°è¯•åˆ é™¤å¤–éƒ¨è¡¨

   ```shell
   hive (default)> drop table test;
   OK
   hive (default)> show tables;
   OK
   tab_name
   aaa
   student
   # æ­£å¸¸åˆ é™¤
   ```

   å…ƒæ•°æ®åˆ é™¤æˆåŠŸï¼š

   <img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200710093904980.png" alt="image-20200710093904980" style="zoom:50%;" />

   çœŸå®æ•°æ®è¢«ä¿ç•™:

   <img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200710094012400.png" alt="image-20200710094012400" style="zoom:67%;" />

   

   è¿™å°±å¾ˆæœ‰æ„æ€äº†ï¼Œé‚£æ¢å¤ï¼ˆé‡å»ºï¼‰testè¡¨,è¿˜èƒ½ä¸èƒ½æ­£å¸¸è¯»åˆ°æ•°æ®å‘¢ï¼Ÿ

4. é‡å»ºè¡¨ï¼Œè¯•å›¾æ¢å¤

   ```shell
   hive (default)> create external table test (id int); # é‡å»ºè¡¨
   OK
   
   hive (default)> select * from test;
   OK
   test.id
   1
   2
   3
   4
   5
   6
   ```

   OHHHHHHHHHHHHHï¼ï¼å±…ç„¶å¯ä»¥ï¼ï¼

   > è¿˜è®°å¾—æˆ‘ä»¬æœ€å¼€å§‹è¯´Hiveçš„æ¡†æ¶åŸç†éƒ¨åˆ†çš„æ—¶å€™å°±ç€é‡å¼ºè°ƒäº†å…ƒæ•°æ®å’ŒçœŸå®æ•°æ®ä¹‹é—´çš„å…³ç³»ï¼Œé€šè¿‡å…ƒæ•°æ®çš„ä¿¡æ¯æ¥é”å®šçœŸå®æ•°æ®ï¼
   >
   > æ‰€ä»¥ï¼Œ==å…ƒæ•°æ®å’ŒçœŸå®æ•°æ®çš„å…ˆåé¡ºåºæ²¡æœ‰è¦æ±‚ï¼Œåªè¦ä¸¤è€…ä¹‹é—´èƒ½å¤Ÿå½¢æˆæ˜ å°„å°±èƒ½æ­£å¸¸è·å–åˆ°æ•°æ®ã€‚==



**Qï¼šç®¡ç†è¡¨å’Œå¤–éƒ¨è¡¨èƒ½ä¸èƒ½ç›¸äº’è½¬åŒ–å‘¢ï¼Ÿå¦‚ä½•è½¬ï¼Ÿ**

**Aï¼š**

åœ¨æˆ‘ä»¬æŸ¥çœ‹å…ƒæ•°æ®çš„æ—¶å€™ï¼Œç®¡ç†è¡¨å’Œå¤–éƒ¨è¡¨çš„ä¸¤ä¸ªåŒºåˆ«ï¼š

- TBL_TYPEï¼ˆTBLSè¡¨ï¼‰:
  - ç®¡ç†è¡¨ï¼šMANAGED_TABLE
  - å¤–éƒ¨è¡¨ï¼šEXTERNAL_TABLE
- EXTERNALï¼ˆTABLE_PARAMSè¡¨ï¼‰ï¼š
  - ç®¡ç†è¡¨ï¼šæ— 
  - å¤–éƒ¨è¡¨ï¼šTRUE

==TBLSè¡¨å’ŒDBSè¡¨ä¸€æ ·æ˜¯åŸºæœ¬å…ƒæ•°æ®æ˜¯ä¸èƒ½ä¿®æ”¹çš„ï¼ï¼==
TABLE_PARAMSå’ŒDATABASE_PARAMSè¡¨ä¸€æ ·ï¼Œæ˜¯æ‰©å±•ä¿¡æ¯è¡¨ï¼Œå¯ä»¥ä¿®æ”¹ï¼

ä½¿ç”¨å‘½ä»¤å°†`EXTERNAL`ç½®ä¸ºfalseå°±å¯ä»¥å°†å¤–éƒ¨è¡¨æ”¹ä¸ºç®¡ç†è¡¨ã€‚



Hiveå‘½ä»¤è¡Œï¼Œæä¾›äº†æŸ¥çœ‹è¡¨è¯¦ç»†ä¿¡æ¯çš„å‘½ä»¤

- `desc table_name`:æŸ¥çœ‹è¡¨å­—æ®µä¿¡æ¯
- `desc formatted table_name`:æŸ¥çœ‹è¡¨å®Œæ•´ä¿¡æ¯

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200710100016001.png" alt="image-20200710100016001" style="zoom:50%;" />



ä½¿ç”¨`alter table table_name set tblproperties('key'='value')`ä¿®æ”¹è¡¨æ‰©å±•ä¿¡æ¯

```shell
hive (default)> alter table test set tblproperties('EXTERNAL'='FALSE');
OK
```

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200710100553671.png" alt="image-20200710100553671" style="zoom:50%;" />

==!!æ‰©å±•ä¿¡æ¯é‡Œé¢çš„KEYã€VALUEä¿è¯ä¸åŸæ•°æ®å¤§å°å†™ä¸€è‡´ï¼==ï¼ˆâ€˜externalâ€™=â€˜trueâ€™æ˜¯æ— æ•ˆçš„å“¦ï¼‰

----



**Qï¼šç®¡ç†è¡¨å’Œå¤–éƒ¨è¡¨å“ªä¸ªå¥½ï¼Ÿåˆ†åˆ«ç”¨äºä»€ä¹ˆåœºæ™¯ï¼Ÿ**

**Aï¼š**ä»æ•°æ®å®‰å…¨è§’åº¦æ¥è¯´ï¼Œæ— ç–‘æ˜¯å¤–éƒ¨è¡¨å®‰å…¨æ€§æ›´é«˜ã€‚
ç®¡ç†è¡¨ä¸€èˆ¬åªé€‚åˆç”¨äºåšä¸´æ—¶è¡¨ã€‚
å­˜æ”¾ä¸šåŠ¡æ•°æ®çš„è¡¨æˆ–å¤šéƒ¨é—¨å…±äº«çš„è¡¨è¿˜æ˜¯æ¨èä½¿ç”¨å¤–éƒ¨è¡¨ï¼Œæ¯•ç«Ÿæ•°æ®åœ°å®‰å…¨æ€§æ›´é«˜ã€‚



### 4.2.3ã€åˆ†åŒºè¡¨

**Q1ï¼šä¸ºä»€ä¹ˆå‡ºç°åˆ†åŒºï¼Ÿ**

**A1ï¼š**ç”±äºHiveæœ¬èº«å¯¹æ•°æ®æ˜¯æ— æ³•åˆ›å»ºç´¢å¼•çš„ï¼Œæ‰€ä»¥æ¯æ¬¡æŸ¥è¯¢æ•°æ®åœ¨æ²¡æœ‰å¯¹æ•°æ®è¿›è¡Œå¤„ç†çš„æƒ…å†µä¸‹ï¼Œéƒ½è¦å¯¹å…¨æ•°æ®æ‰«æï¼å°ç‚¹çš„æ•°æ®è¿˜å¥½ï¼Œä¸€æ—¦æµ·é‡çš„æ•°æ®å…¨æ‰«ææ•ˆç‡å°±éå¸¸ä¹‹ä½ï¼Œæ‰€ä»¥è€ƒè™‘å¯¹æ•°æ®åˆ†åŒºï¼Œå°†æ•°æ®å®šä½åˆ°æŸä¸ªåŒºï¼Œé‚£æ ·æ¯æ¬¡æ‰«æå°±åªéœ€è¦æ‰«ææŸä¸ªåŒºå³å¯ã€‚

**Q2ï¼šåˆ†åŒºæ˜¯ä»€ä¹ˆæ¦‚å¿µï¼Ÿæ–‡ä»¶ä¸­å¦‚ä½•å®ç°ï¼Ÿ**

**A2ï¼š**åœ¨æ™®é€šæƒ…å†µä¸‹ï¼Œæ‰€æœ‰çš„æ•°æ®æ–‡ä»¶éƒ½ä¼šæ”¾åœ¨è¡¨æ•°æ®ç›®å½•ä¸‹ï¼ˆæ··åœ¨ä¸€èµ·ï¼‰ï¼Œè€Œè¿›è¡Œåˆ†åŒºæ—¶éœ€è¦æŒ‡å®šä¸€ä¸ªåˆ†åŒºå­—æ®µï¼ˆè¿™ä¸ªåˆ†åŒºå­—æ®µæ˜¯ç‹¬ç«‹äºè¡¨ä¸­å­—æ®µçš„ï¼‰ï¼Œä½¿ç”¨è¿™ä¸ªå­—æ®µä»¥åŠå­—æ®µå€¼åˆ›å»ºä¸€ä¸ªäºŒçº§ç›®å½•ï¼ˆ.../table_name/partitoncol=valueï¼‰ï¼Œåœ¨æ’å…¥çš„æ•°æ®çš„é€‚åˆè¦æŒ‡å®šåˆ†åŒºå­—æ®µçš„å€¼ï¼Œé€šè¿‡å¯¹åº”çš„å€¼å°†æ•°æ®æ”¾å…¥åˆ°å¯¹åº”çš„åˆ†åŒºç›®å½•ä¸­ã€‚

**Q3ï¼šåˆ†åŒºè¡¨å¦‚ä½•åˆ›å»ºï¼Ÿ**

**A3ï¼š**å»ºè¡¨çš„é€‚åˆåŠ ä¸Š`partitioned by (col_name data_type)`

```sql
create table employee(id int,name string)
partitioned by (department string)
row format delimited
fields terminated by '\t';
```

ç°åœ¨å¾€é‡Œé¢å¡æ•°æ®ä½¿ç”¨ä¹‹å‰çš„æ–¹æ³•æ˜¯ä¸è¡Œå“’ï¼

```she
hive (default)> load data local inpath '/opt/module/data/emp01.txt' into table employee;
FAILED: SemanticException [Error 10062]: Need to specify partition columns because the destination table is partitioned
```

ç°åœ¨æ’å…¥æ•°æ®å‘Šè¯‰æˆ‘ä»¬éœ€è¦æŒ‡å®šåˆ†åŒºï¼Œå› ä¸ºè¡¨æ˜¯åˆ†åŒºè¡¨ã€‚

æ‰€ä»¥ç°åœ¨æ’å…¥æ•°æ®çš„æ­£ç¡®æ“ä½œæ˜¯ï¼š`load data local inpath '/opt/module/data/emp01.txt' into table employee partition(department='dev');`

==æˆ–è€…ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨HDFSç›´æ¥putæ•°æ®åˆ°å¯¹åº”çš„åˆ†åŒºé‡Œé¢ä¹Ÿå¯ä»¥ï¼Œå‰æä¿è¯æ•°æ®å¯è¢«è§£æã€‚==

> é‡åˆ°ä¸€ä¸ªå°æ’æ›²ï¼šæƒŠå¥‡çš„å‘ç°æˆ‘çš„MySQLå…ƒæ•°æ®åº“ä¸­æ²¡æœ‰PARTIONSè¡¨ï¼ï¼ï¼å‡ºå¤§é—®é¢˜ï¼Œè¿™ç›´æ¥å¯¼è‡´æˆ‘åœ¨æ’å…¥åˆ†åŒºæ•°æ®çš„æ—¶å€™åå¤æŠ¥é”™ï¼š
>
> ```shell
> Failed with exception MetaException(message:For direct MetaStore DB connections, we don't support retries at the client level.)
> FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask
> ```
>
> è™½ç„¶æ•°æ®æ–‡ä»¶åœ¨åˆ†åŒºç›®å½•ä¸­ï¼Œä½†æ˜¯æ€ä¹ˆéƒ½æŸ¥ä¸å‡ºæ¥æ•°æ®ï¼Œè¿™å°±æ˜¯å› ä¸ºåˆ†åŒºä¿¡æ¯æ²¡æœ‰è¢«å­˜å‚¨åˆ°å…ƒæ•°æ®ä¸­ã€‚ï¼ˆå…¶å®ä¸æ˜¯æ²¡æœ‰å­˜ï¼Œè€Œæ˜¯æ²¡æœ‰åœ°æ–¹å­˜ï¼‰å°±æ˜¯å› ä¸ºPARTIONSè¡¨æ²¡æœ‰ã€‚
>
> é¦–å…ˆæˆ‘ç”¨äº†`MSCK REPAIR TABLE table_name`ä¿®å¤åˆ†åŒºï¼Œå‘Šè¯‰æˆ‘patitionä¸åœ¨å…ƒæ•°æ®ä¸­ã€‚åæ¥æˆ‘å»çœ‹äº†ä¸‹æ—¥å¿—æ–‡ä»¶ï¼Œå…¶ä¸­æœ‰ä¸€æ¡æ—¥å¿—ä¿¡æ¯
>
> ```markdown
> Table 'metastore.PARTITIONS' doesn't exist
> ```
>
> å»æŸ¥äº†ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼Œç»™å‡ºçš„ç­”æ¡ˆæ˜¯ï¼š`MySQLæ•°æ®åº“å’ŒMySQLè¿æ¥é©±åŠ¨çš„é—®é¢˜`ã€‚
>
> æˆ‘ç”¨çš„MySQLç‰ˆæœ¬æ˜¯5.7.26ï¼Œä½†æ˜¯ç”¨çš„é©±åŠ¨æ˜¯8.0.19ï¼Œå®˜æ–¹ç»™å‡ºçš„è§£é‡Šæ˜¯8.0+çš„é©±åŠ¨æ˜¯å¯ä»¥å…¼å®¹5.0+ç‰ˆæœ¬çš„MySQLï¼Œä¹Ÿå°±æ˜¯è¯´å¯ä»¥æ­£å¸¸ä½¿ç”¨çš„ã€‚ä½†æ˜¯Hiveä¸è®¤å•Šï¼Œå“æ— å¥ˆæ¢æˆ5.1.48çš„é©±åŠ¨jaråŒ…ï¼Œåˆ é™¤ä¹‹å‰çš„metastoreã€‚æŠŠé…ç½®æ–‡ä»¶ä¸­è¿æ¥é©±åŠ¨æ”¹æˆcom.mysql.jdbc.Driverã€‚
>
> ç„¶åé‡å¯Hiveï¼ŒPartitionsè¡¨å›æ¥äº†ï¼ï¼~~
>
> åˆ°è¿™é‡Œé—®é¢˜è¿˜ä¸ç®—å®Œå…¨è§£å†³ï¼Œåœ¨æ¯æ¬¡å¯åŠ¨éƒ½ä¼šæœ‰ä¸€å †æç¤ºï¼Œå…³äºSSLçš„ï¼Œå¦‚ä¸‹ï¼ˆè‡ªè¡Œç¿»è¯‘ï¼‰ï¼š
>
> ```shell
> Fri Jul 10 20:23:27 CST 2020 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
> ```
>
> æ‰€ä»¥å†ä¿®æ”¹ä¸€æ³¢è¿æ¥URLï¼šåŠ ä¸Š`&amp;useSSL=false`ï¼Œ==åœ¨XMLä¸­ç”¨\&amp;ä»£æ›¿&==

---

æ’å…¥åˆ†åŒºæ•°æ®æˆåŠŸåï¼Œæˆ‘ä»¬çœ‹ä¸‰ä¸ªåœ°æ–¹ï¼šHDFSæ–‡ä»¶ã€Hiveæ•°æ®ã€MySQLä¸­å…ƒæ•°æ®

HDFSæ–‡ä»¶ï¼š

![image-20200711092115285](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200711092115285.png)

åˆ†åŒºç›®å½•ï¼š![image-20200711092527336](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200711092527336.png)

---

Hiveä¸­æŸ¥è¯¢æ•°æ®ï¼š

```shell
hive (default)> select * from employee where department='dev';
OK
employee.id     employee.name   employee.department
1       zhangsan        dev
2       liming  dev
3       wanglei dev
4       laowang dev
```

æœ€åé‚£ä¸ªdepartmentå­—æ®µ ï¼Œæ˜¯åˆ†åŒºæ‰€ç”¨å¾—å­—æ®µä½†æ˜¯æŸ¥è¯¢çš„æ—¶å€™ä¹Ÿä¼šå¸¦ä¸Šï¼Œæˆ‘ä»¬æƒ³è¦ç¼©å°æˆ‘ä»¬çš„æœç´¢èŒƒå›´ï¼Œåœ¨æŸ¥è¯¢ä¸­ä½¿ç”¨whereæŒ‡å®šå¯¹åº”çš„åˆ†åŒºå°±å¥½äº†ã€‚

---

MySQLä¸­å…ƒæ•°æ®ï¼š

- å…ˆçœ‹å›°æ‰°äº†æˆ‘å¾ˆä¹…çš„partitionsè¡¨ï¼ˆå…³è”ä¸€ä¸ªSDSè¡¨ï¼‰

  <img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200711092913130.png" alt="image-20200711092913130" style="zoom:67%;" />

- å…¶ä»–å‡ ä¸ªå’Œåˆ†åŒºç›¸å…³çš„è¡¨ï¼šï¼ˆå‡ å¼ è¡¨ç›¸äº’å…³è”ï¼‰

  <img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200711093255876.png" alt="image-20200711093255876" style="zoom:67%;" />

---



#### 4.2.3.aã€åˆ†åŒºè¡¨æ“ä½œ

> å¢åŠ åˆ†åŒº`alter table table_name add patition(key=value) [partition(key=value) ..]`

```shell
hive (default)> alter table employee add partition(department='financial') partition(department='person');
```

å¢åŠ å¤šä¸ªåˆ†åŒºçš„æ—¶å€™ï¼Œåˆ†åŒºä¹‹é—´ä»¥`ç©ºæ ¼`é—´éš”

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200711100900038.png" alt="image-20200711100900038" style="zoom: 80%;" />

å…ƒæ•°æ®å’ŒHDFSæ–‡ä»¶éƒ½ä¼šäº§ç”Ÿç›¸åº”çš„å˜åŒ–ã€‚



> åˆ é™¤åˆ†åŒº`alter table table_name drop partition(key='value')[,patition(key-value),..] `

```shell
hive (default)> alter table employee drop partition(department='financial'),partition(department='person');
Dropped the partition department=financial
Dropped the partition department=person
OK
```

æ³¨æ„ï¼šå½“åˆ é™¤å¤šä¸ªåˆ†åŒºçš„æ—¶å€™ä¸æ˜¯ä½¿ç”¨ç©ºæ ¼éš”å¼€äº†ï¼ï¼åˆ†åŒºä¹‹é—´ä½¿ç”¨`,`éš”å¼€ã€‚



> æŸ¥çœ‹åˆ†åŒºæ•°é‡ã€åˆ†åŒºè¡¨ç»“æ„ä¿¡æ¯

æŸ¥çœ‹åˆ†åŒºæ•°é‡ï¼š`show partitions table_name`

```shell
hive (default)> show partitions employee;
OK
partition
department=dev
department=prod
```

æŸ¥çœ‹åˆ†åŒºè¡¨ç»“æ„ä¿¡æ¯ï¼š`desc formatted table_name`

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/image-20200711103324507.png" alt="image-20200711103324507" style="zoom:67%;" />



> äºŒçº§(å¤šçº§)åˆ†åŒºåˆ›å»º

é“ç†å’Œä¸€çº§åˆ†åŒºæ˜¯ç›¸åŒçš„ï¼Œåªæ˜¯å¯¹åˆ†åŒºå†åˆ†åŒºã€‚==åˆ›å»ºåˆ†åŒºè¡¨çš„æ—¶å€™å†™ä¸Šä¸¤ä¸ªå­—æ®µå°±å¯ä»¥äº†ï¼Œåˆ†åŒºå­—æ®µçš„é¡ºåºå†³å®šäº†è°æ˜¯ä¸€çº§ç›®å½•è°æ˜¯äºŒçº§ç›®å½•ï¼==ï¼Œæ­¤æ—¶æ’å…¥æ•°æ®åå°±è¦åŒæ—¶å¡«ä¸Šä¸¤ä¸ªåˆ†åŒºå­—æ®µçš„ä¿¡æ¯ã€‚



> å…³äºåŠ å…¥åˆ†åŒºæ•°æ®çš„é—®é¢˜

ä¸€å…±æœ‰ä¸‰ç§æ–¹å¼å¯ä»¥å¼•å…¥åˆ†åŒºæ•°æ®ã€‚

1. æ–¹æ³•ä¸€ï¼šä½¿ç”¨åˆ†åŒºä¿®å¤å‘½ä»¤`msck repait table table_name`

   ä¹‹å‰æˆ‘ä»¬è¯•è¿‡åˆ›å»ºå¥½åˆ†åŒºç›´æ¥å¾€é‡Œé¢putæ•°æ®ï¼Œè¿™æ ·æ˜¯å¯ä»¥çš„ï¼ç°åœ¨æˆ‘ä»¬æ¥ä¸ªæ›´ç‹ çš„ï¼Œç›´æ¥putä¸€ä¸ªåˆ†åŒºç›®å½•ã€‚

   ```shell
   [sakura@hadoop102 data]$ hadoop fs -mkdir /user/hive/warehouse/employee/department=other
   [sakura@hadoop102 data]$ hadoop fs -put ./emp01.txt /user/hive/warehouse/employee/department=other
   ```

   è™½è¯´HDFSä¸­æœ‰æ•°æ®äº†ï¼Œä½†æ˜¯MySQLé‡Œé¢æ²¡æœ‰å¯¹åº”çš„åˆ†åŒºå…ƒæ•°æ®ï¼Œæ‰€ä»¥ç°åœ¨å¯ä»¥è‚¯å®šçš„è¯´è¿™ä¸ªåˆ†åŒºæ˜¯æ— æ•ˆçš„ï¼Œæ˜¯æŸ¥ä¸å‡ºæ•°æ®çš„ï¼š

   ```shell
   hive (default)> show partitions employee;
   OK
   partition
   department=dev
   department=prod
   ```

   ä½¿ç”¨ä¿®å¤å‘½ä»¤ä¿®å¤åˆ†åŒºï¼š

   ```shell
   hive (default)> msck repair table employee;
   OK
   Partitions not in metastore:    employee:department=other # æé†’åˆ†åŒºä¸åœ¨å…ƒæ•°æ®ä¸­
   Repair: Added partition to metastore employee:department=other # ä¿®å¤æ—¥å¿—ï¼šå¢åŠ åˆ†åŒº
   ```

   å†æŸ¥æ•°æ®ï¼š

   ```shell
   hive (default)> show partitions employee;
   OK
   partition
   department=dev
   department=other
   department=prod
   ```

   OKï¼Œå¥½èµ·æ¥äº†ã€‚

   ---

2. æ–¹æ³•äºŒï¼šå…ˆåŠ æ•°æ®å†åŠ åˆ†åŒº

   åˆšæ‰çš„ä¿®å¤æ—¥å¿—ç»™äº†æˆ‘ä»¬çµæ„Ÿï¼Œä¿®å¤å°±æ˜¯å¢åŠ äº†ä¸€ä¸ªåˆ†åŒºã€‚å› ä¸ºçœŸå®æ•°æ®å·²ç»åœ¨é‚£äº†ï¼Œå°±å·®å…ƒæ•°æ®äº†ï¼Œæˆ‘ä»¬ç»™è¿™ä¸ªåˆ†åŒºåˆ›å»ºä¸€ä¸‹å…ƒæ•°æ®ä¸å°±è¡Œäº†ä¹ˆã€‚

3. æ–¹æ³•ä¸‰ï¼šä½¿ç”¨loadæ–¹å¼ï¼Œå¢åŠ æ•°æ®çš„åŒæ—¶è‡ªåŠ¨åˆ›å»ºåˆ†åŒºã€‚



### 4.2.5ã€ä¿®æ”¹è¡¨

å¯ä»¥ä½¿ç”¨ç›¸åº”çš„å‘½ä»¤æ¥ä¿®æ”¹è¡¨åã€è¡¨å­—æ®µåã€è¡¨å­—æ®µç±»å‹ï¼Œä»¥åŠå¯¹è¡¨çš„å­—æ®µå¢åˆ æ›¿æ¢ã€‚

> é‡å‘½åï¼š`alter table old_table_name rename to new_table_name`

```shell
hive (default)> alter table stu rename to staff;
OK

hive (default)> show tables;
OK
tab_name
employee
staff
```



> åˆ—ä¿®æ”¹ï¼ˆå¢ã€æ”¹ã€æ›¿æ¢ï¼‰

- å¢åŠ åˆ—ADDï¼š`alter table table_name add columns (col_name data_type,..)`

  ```shell
  hive (default)> alter table staff add columns (sex tinyint, age int);
  OK
  Time taken: 0.244 seconds
  hive (default)> select * from staff;
  OK
  staff.id        staff.name      staff.sex       staff.age
  2       		lisi    		NULL    		NULL
  3       		wangwu  		NULL    		NULL
  4       		songliu 		NULL    		NULL
  
  hive (default)> desc staff;
  OK
  col_name        data_type       comment
  id              int
  name            string
  sex             tinyint
  age             int
  ```

  

- ä¿®æ”¹å­—æ®µCHANGEï¼š`alter table table_name change [column] old_col_name new_col_name data_type`

  ```shell
  hive (default)> alter table staff change sex tel string;
  OK
  
  hive (default)> desc staff;
  OK
  col_name        data_type       comment
  id              int
  name            string
  tel             string
  age             int
  ```

  

- å­—æ®µæ›¿æ¢REPLACEï¼š`alter table table_name replace columns (col_name data_type [COMMENT],..)`

  è¿™ä¸ªæ›¿æ¢æ˜¯å¯¹å½“å‰è¡¨çš„æ‰€æœ‰å­—æ®µè¿›è¡Œä¸€æ¬¡æ›¿æ¢ï¼

  ```shell
  hive (default)> alter table staff replace columns (name string,birth string,addr string);
  OK
  
  hive (default)> desc staff;
  OK
  col_name        data_type       comment
  name            string
  birth           string
  addr            string
  ```



==ä»¥ä¸Šæ‰€æœ‰çš„ä¿®æ”¹åªæ¶‰åŠåˆ°è¡¨ç»“æ„åŠå…ƒæ•°æ®çš„ä¿®æ”¹ï¼Œè¡¨ä¸­çœŸå®æ•°æ®ä¸ä¼šå‘ç”Ÿå˜åŒ–ï¼Œæ˜¾ç¤ºä¸ºNULLåªæ˜¯å› ä¸ºæ•°æ®æ— æ³•è½¬åŒ–ä¸ºå¯¹åº”çš„ç±»å‹ã€‚==

---



> åˆ é™¤è¡¨ï¼š`drop table table_name`

---



# äº”ã€DMLæ•°æ®æ“ä½œ

## 5.1ã€æ•°æ®å¯¼å…¥

### 5.1.1ã€ä½¿ç”¨Loadå‘è¡¨ä¸­è£…è½½æ•°æ®

> å®Œæ•´è¯­æ³•

```shell
load data [local] inpath 'file_path' [overwrite] into table table_name [partition(..)];
```

- localï¼ˆå¯é€‰ï¼‰ï¼šè¡¨ç¤ºä»Linuxæœ¬åœ°æ–‡ä»¶ç³»ç»Ÿå¯¼å…¥æ•°æ®
- overwriteï¼ˆå¯é€‰ï¼‰ï¼šè¡¨ç¤ºè¦†ç›–åŸæœ‰çš„æ‰€æœ‰æ•°æ®
- partitionï¼ˆå¯é€‰ï¼‰ï¼šåˆ†åŒºç›¸å…³çš„æ•°å€¼



### 5.1.2ã€ä½¿ç”¨ Insertæ‰‹åŠ¨æ’å…¥æ•°æ®

é™¤äº†åŸå§‹çš„æ‰‹æ•²æ•°æ®ï¼Œè¿˜å¯ä»¥ç›´æ¥æŠŠæŸ¥è¯¢ç»“æœä½œä¸ºæ•°æ®æ’å…¥åˆ°è¡¨ä¸­ã€‚

1. å¤åˆ¶ä¸€å¼ employeeè¡¨

   ```shell
   hive (default)> create table aaa like employee;
   OK
   ```

2. æµ‹è¯•åŸºæœ¬çš„æ•°æ®æ’å…¥

   ```shell
   hive (default)> insert into table aaa partition(department='clean') values(8,'laoba');
   
   hive (default)> select * from aaa;
   OK
   aaa.id  aaa.name        aaa.department
   8       laoba   		clean
   ```

3. æ ¹æ®æŸ¥è¯¢ç»“æœæ’å…¥

   ```shell
   hive (default)> insert overwrite table aaa partition(department='clean')
                 > select id,name
                 > from employee
                 > where department='dev';
                 
   hive (default)> select * from aaa;
   OK
   aaa.id  aaa.name        aaa.department
   1       zhangsan        clean
   2       liming  		clean
   3       wanglei 		clean
   4       laowang 		clean
   ```

   å¥½å¥‡çš„äººå·²ç»å‘ç°é—®é¢˜äº†ï¼Œè€å…«å‘¢ï¼ŸinsertåŒæ ·æ”¯æŒä½¿ç”¨overwriteè¦†ç›–å†™å…¥ï¼Œä¸è¿‡ä¸loadè¯­æ³•æœ‰ä¸€ç‚¹ä¸åŒï¼Œä¸éœ€è¦intoã€‚
   ==è¿™ä¸€å¼ è¡¨æŸ¥è¯¢å¯ä»¥ï¼Œå¤šå¼ è¡¨å½“ç„¶ä¹Ÿè¡Œï¼åœ¨ä¸€ä¸ªè¯­å¥ä¸­ä¸åœä½¿ç”¨insertå°±å¯ä»¥å®ç°å¤šå¼ è¡¨æŸ¥è¯¢ç»“æœçš„æ’å…¥ã€‚==



### 5.1.3ã€As Selectåˆ›å»ºè¡¨å¹¶ç›´æ¥åŠ è½½æ•°æ®

è¿™ä¸ªå’Œåˆ›å»ºè¡¨æ—¶å€™ä½¿ç”¨çš„likeåŠŸèƒ½å¾ˆæƒ³ï¼ŒåŒºåˆ«åœ¨äºä½¿ç”¨As Selectç›´æ¥è¿æ¬å¸¦æŠ„ç›´æ¥æŠŠæ•°æ®ä¹Ÿæ‹¿äº†è¿‡æ¥ã€‚

```shell
hive (default)> create table if not exists bbb
              > as select id,name from aaa;
              
hive (default)> select * from bbb; # æ•°æ®å®Œæ•´åœ°æ‹¿è¿‡æ¥
OK
bbb.id  bbb.name
1       zhangsan
2       liming
3       wanglei
4       laowang
1       zhangsan
2       liming
3       wanglei
4       laowang

hive (default)> desc bbb; # ç»“æ„ä¹Ÿæ˜¯ä¸€æ¨¡ä¸€æ ·
OK
col_name        data_type       comment
id                      int
name                    string
```



### 5.1.4ã€å»ºè¡¨ä½¿ç”¨Locationç›´æ¥åŠ è½½æ•°æ®

è¿™ç§å¯¼å…¥æ•°æ®çš„æ–¹å¼åŸç†å¾ˆç®€å•ï¼Œå°±æ˜¯åˆ©ç”¨HDFSä¸Šå·²æœ‰çš„æ•°æ®å†åŠ ä¸Šå¯¹åº”çš„å…ƒæ•°æ®ï¼Œå°±å¯ä»¥é€šè¿‡è¡¨æ¥è¯»å–å’Œç®¡ç†è¿™äº›æ•°æ®ã€‚è¯´ç™½äº†å®ƒä»¬å°±æ˜¯å·®ä¸€ä¸ªè¡¨ï¼Œå·®ä¸€äº›å…ƒæ•°æ®ã€‚
åœ¨å»ºè¡¨çš„è¯­å¥ä¸­ä½¿ç”¨`location`æŒ‡å‘è¿™ä¸ªå·²æœ‰çš„æ•°æ®ç›®å½•å°±å¯ä»¥äº†ã€‚

### 5.1.5ã€ä½¿ç”¨Importå¯¼å…¥æ•°æ®

è¿™ä¸ªimportå’Œload dataä¸åŒï¼Œä¸æ˜¯éšéšä¾¿ä¾¿ä¸€ä¸ªæ–‡ä»¶ä½ å°±å¯ä»¥æ‹¿æ¥Importçš„ï¼Œé¦–å…ˆè¢«Importçš„æ–‡ä»¶æ˜¯ç»è¿‡exportå¯¼å‡ºçš„æ‰è¡Œï¼Œä¸‹ä¸€èŠ‚å­¦ä¹ æ•°æ®å¯¼å‡ºæ—¶å†æ¥è¿›è¡Œå®æ“æ¼”ç¤ºã€‚



## 5.2ã€æ•°æ®å¯¼å‡º

### 5.2.1ã€Insertå¯¼å‡º

åœ¨å¯¼å…¥æ•°æ®çš„æ—¶å€™æˆ‘ä»¬ä½¿ç”¨Load data inpathå‘½ä»¤ï¼Œå¯ä»¥é€‰æ‹©ä»æœ¬åœ°æˆ–è€…HDFSä¸Šå¯¼å…¥ï¼Œè¿™é‡ŒInsertæ•°æ®å¯¼å‡ºä¹ŸåŒæ ·æ”¯æŒæœ¬åœ°å’Œè¿œç¨‹ã€‚

å®Œæ•´å‘½ä»¤ï¼š`insert [overwrite] [local] directory 'path' [row format ..] select * from table_name;`

> å¯¼å‡ºåˆ°æœ¬åœ°local

ç›´æ¥å¯¼å‡ºæ•°æ®ï¼ˆæ— æ•°æ®æ ¼å¼ï¼‰

```shell
hive (default)> insert overwrite local directory '/opt/module/data/employee_insert' select * from employee;
# æ— æ•°æ®æ ¼å¼å¯¼å‡ºåˆ°Linuxæ–‡ä»¶ç³»ç»Ÿ
```

å¯¼å‡ºä»¥åçš„æ•°æ®æ˜¯ä¸€ä¸ªæ‰“åŒ…çš„ç›®å½•ï¼Œ0000_0æ–‡ä»¶ä¸­å°±æ˜¯å¯¼å‡ºçš„æ•°æ®

```shell
[sakura@hadoop102 employee_insert]$ cat 000000_0 
1zhangsandev
2limingdev
# ... æ‚ä¹±æ— ç« 
```

æƒ³è¦äºŒæ¬¡åˆ©ç”¨æ•°æ®å°±æœ‰å¿…è¦åœ¨å¯¼å‡ºçš„æ—¶å€™==ç¡®å®šå¯¼å‡ºçš„æ•°æ®æ ¼å¼==

```shell
hive (default)> insert overwrite local directory '/opt/module/data/employee_insert'
              > row format delimited
              > fields terminated by '\t'
              > select * from employee;
```

ä½¿ç”¨äº†è¦†ç›–ï¼ˆoverwriteå¯¼å‡ºï¼‰ï¼Œä½¿ç”¨row_formatè§„å®šå¯¼å‡ºæ•°æ®çš„æ ¼å¼

```shell
[sakura@hadoop102 employee_insert]$ cat 000000_0 
1	zhangsan	dev
2	liming	dev
3	wanglei	dev
4	laowang	dev
```



> å¯¼å‡ºæ•°æ®åˆ°HDFS

å’Œload dataä¸€æ ·å»æ‰localå³å¯ï¼Œå…¶ä»–æ“ä½œä¸æœ¬åœ°å¯¼å‡ºä¸€æ¨¡ä¸€æ ·

![image-20200713204239419](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200713204239.png)



### 5.2.2ã€éå¸¸è§„æ•°æ®å¯¼å‡º

- ä½¿ç”¨hdfså‘½ä»¤ç›´æ¥åˆ°è¡¨æ•°æ®ç›®å½•ä¸­getæ•°æ®æ–‡ä»¶

  HDFSå‘½ä»¤ä¸­getå‘½ä»¤å°†æ–‡ä»¶ä¸‹è½½åˆ°æœ¬åœ°

- ä½¿ç”¨Hiveçš„äº¤äº’å¼å‘½ä»¤

  åœ¨å­¦ä¹ äº¤äº’å¼å‘½ä»¤çš„æ—¶å€™ä½¿ç”¨`-e`é€‰é¡¹å‚æ•°åœ¨Linuxå‘½ä»¤è¡Œä¸­æ‰§è¡ŒHiveå‘½ä»¤,ä½¿ç”¨`>`å°†æ‰§è¡Œç»“æœè¾“å‡ºåˆ°æ–‡ä»¶ä¸­

  ```shell
  [sakura@hadoop102 data]bin/hive -e 'select * from staff;' > ./staff_data
  ```



### 5.2.3ã€ä½¿ç”¨Exportæ•°æ®å¯¼å‡ºï¼Œä½¿ç”¨Importæ•°æ®å¯¼å…¥ï¼ˆäº†è§£ï¼‰

> åŸºç¡€å‘½ä»¤

å¯¼å‡ºï¼š`export table table_name [partition] to 'hdfs_path'`
å¯¼å…¥ï¼š`import table table_name [partiton] from 'hdfs_path'`

---

**æ•°æ®å¯¼å‡º**

```shell
hive (default)> export table staff to '/staff_data';
```

HDFSæ•°æ®å±‚çº§ç›®å½•

```shell
[sakura@hadoop102 data]$ hadoop fs -ls -R /staff_data
-rwxr-xr-x   3 sakura supergroup       1324 2020-07-13 21:08 /staff_data/_metadata
drwxr-xr-x   - sakura supergroup          0 2020-07-13 21:08 /staff_data/data
-rwxr-xr-x   3 sakura supergroup         26 2020-07-13 21:08 /staff_data/data/stu.txt
```

==ä¸€ä¸ªå…ƒæ•°æ®æ–‡ä»¶ã€ä¸€ä¸ªçœŸå®æ•°æ®ç›®å½•ã€‚==å°±æ˜¯å› ä¸ºexportå¯¼å‡ºçš„æ•°æ®æœ‰å…ƒæ•°æ®æ‰€ä»¥æ‰èƒ½ä½¿ç”¨importï¼Œå¦åˆ™å…¶ä»–çš„æ•°æ®æ˜¯ä¸èƒ½ä½¿ç”¨importå¯¼å…¥çš„ã€‚



**æ•°æ®å¯¼å…¥**

```shell
hive (default)> import table staff from '/staff_data';
FAILED: SemanticException [Error 10119]: Table exists and contains data files
```

é‡åˆ°é—®é¢˜ï¼š==ä½¿ç”¨Importå¯¼å…¥æ•°æ®ï¼Œè¡¨å¿…é¡»ä¸ºæœªåˆ›å»ºçš„è¡¨æˆ–è€…æ–°è¡¨ï¼ˆæ²¡æœ‰æ’å…¥è¿‡æ•°æ®çš„è¡¨ï¼‰==

```shell
hive (default)> import table emp from '/staff_data';
```

hiveä¼šé€šè¿‡å…ƒæ•°æ®ä¿¡æ¯è‡ªåŠ¨åˆ›å»ºè¡¨ã€åŒ¹é…å­—æ®µã€‚



## 5.3ã€æ¸…ç©ºè¡¨æ•°æ®ï¼ˆTruncateï¼‰

æ³¨æ„ï¼š==truncateåªèƒ½åˆ é™¤ç®¡ç†è¡¨çš„æ•°æ®ï¼Œä¸å¯ä»¥æ¸…ç©ºå¤–éƒ¨è¡¨==

ä¾‹å¦‚ï¼šç°æœ‰ä¸€ä¸ªå¤–éƒ¨è¡¨emp;

```shell
hive (default)> truncate table emp;
FAILED: SemanticException [Error 10146]: Cannot truncate non-managed table emp. 
# æç¤ºä¸èƒ½å¯¹éç®¡ç†è¡¨ä½¿ç”¨truncate
```

ç®¡ç†è¡¨æ¸…ç©º

```shell
hive (default)> truncate table staff;
OK

hive (default)> select * from staff;
OK
staff.id	staff.name
```

å¯ä»¥æƒ³è€ŒçŸ¥ï¼Œå¯¹åº”è¡¨çš„HDFSæ•°æ®ç›®å½•ä¸‹çš„æ•°æ®æ–‡ä»¶è‚¯å®šæ˜¯è¢«åˆ é™¤äº†

![image-20200713212443225](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200713212443.png)

----



# å…­ã€æŸ¥è¯¢

## 6.1ã€åŸºæœ¬æŸ¥è¯¢

Hiveçš„åŸºæœ¬æŸ¥è¯¢è¯­æ³•å’ŒMySQLå‡ ä¹æ²¡ä»€ä¹ˆåŒºåˆ«ã€‚

> å…¨åˆ—æŸ¥è¯¢å’Œç­›é€‰åˆ—æŸ¥è¯¢

```shell
# å…¨åˆ—æŸ¥è¯¢
hive (default)> select * from emp;
OK
emp.id	emp.name
2	lisi
3	wangwu
4	songliu

# ç­›é€‰åˆ—æŸ¥è¯¢
hive (default)> select name from emp;
OK
name
lisi
wangwu
songliu
```

> åˆ—åˆ«åã€è¡¨åˆ«å

ç›´æ¥åœ¨åˆ—åï¼ˆæˆ–è¡¨åï¼‰ååŠ `as`ç„¶ååŠ åˆ«åã€‚ä¹Ÿå¯ä»¥ç›´æ¥çœç•¥ä¸å†™

```shell
# åˆ—åˆ«å
hive (default)> select id staff_id
              > from emp;
OK
staff_id
2
3
4

# è¡¨åˆ«å
hive (default)> select a.id
              > from emp a;
OK
a.id
2
3
4
```

> å¸¸ç”¨æŸ¥è¯¢å‡½æ•°

1. `count()` ç»Ÿè®¡è¡Œæ•°
2. `max()`ã€`min()` æœ€å¤§æœ€å°å€¼
3. `sum()` æ•°æ®æ€»å’Œ
4. `avg()` å‡å€¼



> Limitè¯­å¥

```shell
hive (default)> select * from employee limit 4;
OK
employee.id	employee.name	employee.department
1	zhangsan	dev
2	liming	dev
3	wanglei	dev
4	laowang	dev
```

**è¿™ä¸ªé‡Œé¢limitå¥½åƒåªæœ‰ä¸€ä¸ªå‚æ•°ï¼ï¼Ÿ**æ²¡æœ‰`limit m,n;`è¿™ç§ç”¨æ³•

---



## 6.2ã€Whereè¯­å¥

> å¸¸ç”¨çš„æ¯”è¾ƒè¿ç®—ç¬¦

- `=`ç­‰å€¼åˆ¤æ–­

- `<=>`,ç­‰ä»·è¿ç®—ç¬¦ï¼ŒçœŸå€¼è¡¨ï¼ˆä»…å½“ä¸¤å€¼ç›¸ç­‰ã€æˆ–å‡ä¸ºNULLæ—¶è¾“å‡ºä¸ºtrueï¼Œä»»æ„ä¸€æ–¹ä¸ºnullï¼Œæˆ–è€…å€¼ä¸ç›¸ç­‰ä¸ºfalseï¼‰

  ```shell
  hive (default)> select 'a' <=> null;
  OK
  _c0
  false
  
  hive (default)> select null <=> null;
  OK
  _c0
  true
  ```

- `!= ` ` <>`ä¸ç­‰äº

- `>=` `>` `<=` `<` å¤§å°æ¯”è¾ƒ

- `A [NOT] between B and C`,èŒƒå›´ï¼ˆé—­åŒºé—´ï¼‰æ¡ä»¶

- `A is [NOT] null`,ç©ºå€¼åˆ¤æ–­

- `A in (B,C,..)`,é›†åˆåˆ¤æ–­

- `A [NOT] like 'regex_str'`,ç®€å•çš„SQLæ­£åˆ™åŒ¹é…

  é€šé…ç¬¦ä¸MySQLä¸€è‡´ï¼š`%`,`_`;å‰è€…ä¸ºä»»æ„æ•°é‡çš„å­—ç¬¦ï¼Œåè€…ä¸ºåŒ¹é…ä¸€ä¸ªå­—ç¬¦ã€‚

- `A RLIKE B, A REGEXP B`,å¤æ‚æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ï¼Œä½¿ç”¨JDKä¸­çš„æ­£åˆ™è¡¨è¾¾å¼æ¥å£å®ç°ã€‚



> é€»è¾‘è¿ç®—ç¬¦

- `AND`ï¼Œé€»è¾‘å¹¶
- `OR`ï¼Œé€»è¾‘æˆ–
- `NOT`ï¼Œé€»è¾‘å¦



## 6.3ã€åˆ†ç»„ï¼ˆGroupByï¼‰

==é€šå¸¸GroupByå’Œèšåˆå‡½æ•°ä¸€èµ·ä½¿ç”¨ï¼Œä½¿ç”¨Havingå¯¹åˆ†ç»„æ•°æ®åšäºŒæ¬¡ç­›é€‰ã€‚==

ä¸Whereä¸åŒï¼ŒHavingåªä½œç”¨äºåˆ†ç»„åçš„æ•°æ®ï¼Œè¿‡æ»¤æ‰ä¸ç¬¦åˆæ¡ä»¶çš„åˆ†ç»„ã€‚

==æ³¨æ„ï¼ï¼==è¿™é‡ŒåŒæ ·æœ‰ä¸€ä¸ªå’ŒMySQLä¸€æ ·çš„æœºåˆ¶ï¼š==ONLY_FULL_GROUP_BY==ï¼Œ**ç®€å•è¯´å°±æ˜¯selectä¸­çš„å­—æ®µå¿…é¡»å…¨éƒ¨å‡ºç°åœ¨groupbyä¸­**ã€‚è¯¦æƒ…è§MySQLé«˜çº§éƒ¨åˆ†groupbyã€‚



## 6.4ã€è¿æ¥Join

å·¦(å¤–)è¿æ¥ã€å³(å¤–)è¿æ¥ã€å†…è¿æ¥è¿™äº›éƒ½å’ŒMySQLä¸€æ ·ã€‚

Hiveå’ŒMySQLçš„è¿æ¥æŸ¥è¯¢åŒºåˆ«æœ‰ä¸¤ç‚¹ï¼š

1. ==Hiveä¸æ”¯æŒéç­‰å€¼è¿æ¥ï¼Œä»…èƒ½ä½¿ç”¨ç­‰å€¼è¿æ¥ã€‚==
2. ==Hiveæ”¯æŒæ»¡å¤–è¿æ¥ï¼ˆFull outer joinï¼‰==ï¼Œè€ŒMySQLåªèƒ½é€šè¿‡å¯¹joinçš„æ¡ä»¶è¿›è¡Œå¤„ç†ä»¥è¾¾åˆ°æ»¡è¿æ¥çš„æ•ˆæœã€‚

==joinçš„è¿æ¥æ¡ä»¶ä¸æ”¯æŒä½¿ç”¨`or`ï¼==



> <a name="dikaerji">ç¬›å¡å°”ç§¯</a>

äº§ç”Ÿç¬›å¡å°”ç§¯çš„æ¸…å†µï¼š

- **çœç•¥äº†è¿æ¥æ¡ä»¶**
- è¿æ¥æ¡ä»¶æ— æ•ˆ
- æ‰€æœ‰è¡¨çš„æ‰€æœ‰è¡Œäº’ç›¸è¿æ¥

ä½¿ç”¨ç¬›å¡å°”ç§¯ï¼Œé€šå¸¸æ•°æ®é‡å¢é•¿æ¯”è¾ƒå¤§ï¼Œæ‰€ä»¥==ä¸€èˆ¬å…¨å±€å…³é—­ä½¿ç”¨ç¬›å¡å°”ç§¯ï¼Œä½¿ç”¨æ—¶å¼€å¯ï¼Œé¿å…ä¸å¿…è¦è®¡ç®—èµ„æºå ç”¨ã€‚==



## 6.5ã€æ’åº

### 6.5.1ã€å…¨å±€æ’åºOrder By

==å…¨å±€æ’åºåœ¨MapReduceè¿‡ç¨‹ä¸­å®ç°åªæœ‰ä¸€ä¸ªReduceã€‚==

æ’åºè§„åˆ™ï¼š

- DESCï¼šé™åº
- ASCï¼šå‡åºï¼ˆé»˜è®¤ï¼‰

==åœ¨OrderByä¸­å¯ä»¥ä½¿ç”¨åˆ—åˆ«åï¼Œä¹Ÿæ”¯æŒå¤šåˆ—æ’åºã€‚==



### 6.5.2ã€åŒºå†…æ’åºSort By

å¾€å¾€æˆ‘ä»¬çš„ä¸šåŠ¡éœ€æ±‚ï¼Œæ˜¯å¯¹åˆ†åŒºæ•°æ®è¿›è¡Œæ’åºï¼Œä¿è¯åŒºå†…çš„æ•°æ®æ˜¯æœ‰åºçš„ï¼Œå¹¶ä¸è¦æ±‚æ‰€æœ‰æ•°æ®å…¨å±€æ’åºã€‚åŒºå†…æ’åºå°±è¦ç”¨åˆ°Sort Byï¼Œä½¿ç”¨Sort Byçš„å‰ææ˜¯ MRå¤„ç†æ•°æ®æ˜¯è¿›è¡Œåˆ†åŒºå¤„ç†çš„ï¼Œè¦æƒ³**æ•°æ®åˆ†åŒºå°±è®¾ç½®Reduceçš„æ•°é‡>1(å›é¡¾Hadoopä¹‹MapReduce)**

**åœ¨æ²¡æœ‰è®¾ç½®Reduceçš„æ•°é‡çš„æ—¶å€™ï¼ˆé»˜è®¤-1ï¼‰ï¼Œä½¿ç”¨sort byå’Œorder byçš„è¿è¡Œç»“æœæ˜¯ä¸€æ ·çš„ã€‚**

è¡¨æ•°æ®ï¼š

```shell
staff.id	staff.name	staff.age	staff.sal	staff.deptno
1			xiaowang	25			5900.0		2
2			zhaolaosi	31			7800.0		2
3			wanglaowu	34			6000.0		3
4			songxiaoqi	23			5200.0		2
5			lixiaodan	27			13000.0		1
6			zhaozong29	29			50000.0		1
7			xiaoxiaoli	20			4000.0		2
8			linxiaohong	22			6000.0		3
9			lishasha	24			6450.0		3
10			zhangfeng	31			8000.0		4
11			chendaniu	29			7000.0		3
12			liuerdao	27			6310.0		4
```

> æ²¡æœ‰è®¾ç½®Reduceæ•°é‡æ—¶ï¼ŒOrderByå’ŒSortByæ•ˆæœç›¸åŒ

OrderByï¼š

```shell
hive (default)> select name,sal,deptno
              > from staff
              > order by sal;
name		sal		deptno
xiaoxiaoli	4000.0	2
songxiaoqi	5200.0	2
xiaowang	5900.0	2
linxiaohong	6000.0	3
wanglaowu	6000.0	3
liuerdao	6310.0	4
lishasha	6450.0	3
chendaniu	7000.0	3
zhaolaosi	7800.0	2
zhangfeng	8000.0	4
lixiaodan	13000.0	1
zhaozong29	50000.0	1
```

SortBy:

```shell
hive (default)> select name,sal,deptno
              > from staff
              > sort by sal;
name		sal		deptno
xiaoxiaoli	4000.0	2
songxiaoqi	5200.0	2
xiaowang	5900.0	2
linxiaohong	6000.0	3
wanglaowu	6000.0	3
liuerdao	6310.0	4
lishasha	6450.0	3
chendaniu	7000.0	3
zhaolaosi	7800.0	2
zhangfeng	8000.0	4
lixiaodan	13000.0	1
zhaozong29	50000.0	1
```



> è®¾ç½®Reduceæ•°é‡ä¸º3ï¼ˆåˆ†åŒºï¼‰å

è®¾ç½®å•ä¸ªJobçš„Reduceæ•°é‡

```shell
hive (default)> set mapreduce.job.reduces;
mapreduce.job.reduces=-1
hive (default)> set mapreduce.job.reduces=3;
hive (default)> set mapreduce.job.reduces;
mapreduce.job.reduces=3
```

==è®¾ç½®åï¼Œå¯¹OrderByæ²¡æœ‰ä»»ä½•å½±å“==

SortByæµ‹è¯•ï¼š

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200714101853.png" alt="image-20200714101853021" style="zoom:67%;" />

è¿™ä¸ªè¾“å‡ºå¯ä»¥çœ‹å‡ºæ˜æ˜¾çš„ä¸‰ä¸ªåˆ†åŒºä½†æ˜¯è§„å¾‹ä¸å¯å¯»ï¼Œæˆ‘ä»¬å°è¯•å°†ç»“æœè¾“å‡ºåˆ°æ–‡ä»¶ç³»ç»Ÿä¸­è¯•è¯•çœ‹ã€‚

```shell
hive (default)> insert overwrite local directory '/opt/module/data/staff_orderby'
              > row format delimited fields terminated by '\t'
              > select name,sal,deptno
              > from staff
              > sort by sal;
#-------------------------------
[sakura@hadoop102 data]$ cd staff_orderby/
[sakura@hadoop102 staff_orderby]$ ll
-rw-r--r--. 1 sakura sakura 119 7æœˆ  14 10:22 000000_0
-rw-r--r--. 1 sakura sakura  95 7æœˆ  14 10:22 000001_0
-rw-r--r--. 1 sakura sakura  18 7æœˆ  14 10:22 000002_0
# æœç„¶ä¸‰ä¸ªåˆ†åŒºå°±æœ‰ä¸‰ä¸ªè¾“å‡ºæ–‡ä»¶

[sakura@hadoop102 staff_orderby]$ cat 000000_0 
xiaoxiaoli	4000.0	2
linxiaohong	6000.0	3
lishasha	6450.0	3
zhangfeng	8000.0	4
lixiaodan	13000.0	1
zhaozong29	50000.0	1
[sakura@hadoop102 staff_orderby]$ cat 000001_0 
songxiaoqi	5200.0	2
wanglaowu	6000.0	3
liuerdao	6310.0	4
chendaniu	7000.0	3
zhaolaosi	7800.0	2
[sakura@hadoop102 staff_orderby]$ cat 000002_0 
xiaowang	5900.0	2
# ä¸‰ä¸ªæ–‡ä»¶ä¸­å†…å®¹å’Œæˆ‘ä»¬åˆ’å‡ºçš„ä¸‰ä¸ªåˆ†åŒºæ˜¯ä¸€æ ·çš„
```

---



> é—®é¢˜1ï¼šæˆ‘ä»¬å¹¶æ²¡æœ‰æŒ‡å®šæŒ‰ä»€ä¹ˆåˆ†åŒºï¼Œé‚£è¿™äº›æ•°æ®æ˜¯å¦‚ä½•è¿›è¡Œåˆ†åŒºçš„å‘¢ï¼Ÿè‡ªåŠ¨ä½¿ç”¨hashåˆ†åŒºå—ï¼Ÿ
> é—®é¢˜2ï¼šsortby å’Œ orderbyçš„åŒºåˆ«

è¿™äº›éƒ½å¯ä»¥åœ¨å®˜æ–¹æ–‡æ¡£ä¸­æ‰¾åˆ°ç»“æœï¼š

*Hive supports SORT BY which sorts the data per reducer. The difference between "order by" and "sort by" is that the former guarantees total order in the output while the latter only guarantees ordering of the rows within a reducer. If there are more than one reducer, "sort by" may give partially ordered final results.*
*Note: It may be confusing as to the difference between SORT BY alone of a single column and CLUSTER BY. The difference is that CLUSTER BY partitions by the field and ==SORT BY if there are multiple reducers partitions randomly in order to distribute data (and load) uniformly across the reducers.==*
*Basically, the data in each reducer will be sorted according to the order that the user specified.*

è¯‘æ–‡ï¼š

```markdown
Hiveæ”¯æŒSORT BYï¼Œå¯å¯¹æ¯ä¸ªreducerçš„æ•°æ®è¿›è¡Œæ’åºã€‚  â€œ order byâ€å’Œâ€œ sort byâ€ä¹‹é—´çš„åŒºåˆ«åœ¨äºï¼Œå‰è€…ä¿è¯è¾“å‡ºä¸­çš„æ€»é¡ºåºï¼Œè€Œåè€…ä»…ä¿è¯reducerä¸­è¡Œçš„æ’åºã€‚ å¦‚æœå­˜åœ¨å¤šä¸ªreducerï¼Œåˆ™â€œsort byâ€å¯èƒ½ä¼šç»™å‡ºéƒ¨åˆ†æ’åºçš„æœ€ç»ˆç»“æœã€‚

æ³¨æ„ï¼šå…³äºå•ä¸ªåˆ—çš„å•ç‹¬SORT BYä¸CLUSTER BYä¹‹é—´çš„åŒºåˆ«å¯èƒ½ä¼šé€ æˆæ··æ·†ã€‚ åŒºåˆ«åœ¨äºï¼Œå¦‚æœæœ‰å¤šä¸ªreduceråˆ†åŒºï¼Œåˆ™CLUSTER BYæŒ‰å­—æ®µåˆ’åˆ†ï¼Œè€ŒSORT BYåˆ™æ˜¯éšæœºåˆ’åˆ†ï¼Œä»¥ä¾¿åœ¨reducerä¸Šå‡åŒ€åœ°åˆ†å¸ƒæ•°æ®ï¼ˆå’Œè´Ÿè½½ï¼‰ã€‚

åŸºæœ¬ä¸Šï¼Œæ¯ä¸ªreducerä¸­çš„æ•°æ®å°†æ ¹æ®ç”¨æˆ·æŒ‡å®šçš„é¡ºåºè¿›è¡Œæ’åºã€‚
```

**å›ç­”é—®é¢˜1**ï¼š==SORT BYæ˜¯éšæœºåˆ’åˆ†ï¼Œä»¥ä¾¿åœ¨reducerä¸Šå‡åŒ€åœ°åˆ†å¸ƒæ•°æ®ï¼ˆå’Œè´Ÿè½½ï¼‰ã€‚==åœ¨æ²¡æœ‰æ˜ç¡®å¦‚ä½•åˆ’åˆ†æ•°æ®çš„æ—¶å€™ï¼ŒSortByæ˜¯éšæœºåˆ’åˆ†ï¼Œä»¥ç¡®ä¿æ•°æ®çš„å‡åŒ€åˆ†é…ã€‚ï¼ˆé˜²æ­¢æ•°æ®å€¾æ–œé—®é¢˜ï¼‰

**å›ç­”é—®é¢˜2**ï¼šâ€œ order byâ€å’Œâ€œ sort byâ€ä¹‹é—´çš„åŒºåˆ«åœ¨äºï¼Œå‰è€…ä¿è¯è¾“å‡ºä¸­çš„æ€»é¡ºåºï¼Œè€Œåè€…ä»…ä¿è¯reducerä¸­è¡Œçš„æ’åºã€‚ å¦‚æœå­˜åœ¨å¤šä¸ªreducerï¼Œåˆ™â€œsort byâ€å¯èƒ½ä¼šç»™å‡ºéƒ¨åˆ†æ’åºçš„æœ€ç»ˆç»“æœã€‚



ä¸­é—´æœ‰æåˆ°`Cluster By`é©¬ä¸Šå°±ä¼šæåˆ°ï¼åœ¨æ­¤ä¹‹å‰æˆ‘ä»¬å…ˆå­¦ä¹ `Distribute By`ï¼Œç”¨äºæ•°æ®åˆ†åŒºé€šå¸¸å’Œsortbyä¸€èµ·ä½¿ç”¨ã€‚



### 6.5.3ã€æ•°æ®åˆ†åŒºDistribute By

åœ¨SortByä¸­æˆ‘ä»¬æ²¡æœ‰æŒ‡å®šæŒ‰ä»€ä¹ˆå¯¹æ•°æ®åˆ†åŒºï¼Œç¨‹åºéšæœºåˆ’åˆ†ä¿è¯æ•°æ®çš„å‡åŒ€ã€‚è€Œè¿™é‡ŒDistributeByå°±ç›¸å½“äºMapReduceä¸­çš„Partitonerï¼Œç»è¿‡äº†åˆ†åŒºçš„æ•°æ®å†ä½¿ç”¨SortByå°±å¯ä»¥ä¿è¯åˆ†åŒºå†…æ˜¯æœ‰åºçš„ï¼Œä¸”è¾“å‡ºçš„æ–‡ä»¶ä¸­å†…å®¹ä¹Ÿæ˜¯æŒ‰ç…§DistributeByæ¥åˆ’åˆ†çš„ï¼Œ
==ï¼é‡è¦ä½¿ç”¨äº†DistributeByçš„æ—¶å€™ï¼Œå½“å¯åˆ†åŒºæ•°é‡å¤§äºReduceçš„æ•°é‡æ—¶ï¼Œå¹¶ä¸ä¿è¯æ¯ä¸ªåˆ†åŒºä¸­åˆ†åŒºå­—æ®µéƒ½ä¸€æ ·ï¼Œä¸€èˆ¬ä½¿ç”¨hashcode%NumReduceræ¥ç¡®å®šåœ¨å“ªä¸ªåˆ†åŒº==

DistributeByå•ç‹¬ä½¿ç”¨

```shell
hive (default)> select name,sal,deptno
              > from staff
              > distribute by deptno;
name		sal		deptno
#---------------------------3%3=0
chendaniu	7000.0	3
lishasha	6450.0	3
linxiaohong	6000.0	3
wanglaowu	6000.0	3
#---------------------------4%3=1%3=1
liuerdao	6310.0	4
zhangfeng	8000.0	4
zhaozong29	50000.0	1
lixiaodan	13000.0	1
#---------------------------2%3=2
xiaoxiaoli	4000.0	2
songxiaoqi	5200.0	2
zhaolaosi	7800.0	2
xiaowang	5900.0	2
```

æˆ‘ä»¬å°†å…¶è¾“å‡ºåˆ°æ–‡ä»¶ä¸­æ¥çœ‹ä¸€ä¸‹æ˜¯ä¸æ˜¯å’Œæˆ‘ä»¬é¢„æœŸçš„ç›¸åŒï¼š

```shell
hive (default)> insert overwrite local directory '/opt/module/data/distributeby_staff'
              > row format
              > row format delimited  
              > fields terminated by '\t'
              > select name,sal,deptno
              > from staff
              > distribute by deptno;

# æ²¡æ¯›ç—…å•Šé“æ±
[sakura@hadoop102 distributeby_staff]$ cat 000000_0 
chendaniu	7000.0	3
lishasha	6450.0	3
linxiaohong	6000.0	3
wanglaowu	6000.0	3
[sakura@hadoop102 distributeby_staff]$ cat 000001_0 
liuerdao	6310.0	4
zhangfeng	8000.0	4
zhaozong29	50000.0	1
lixiaodan	13000.0	1
[sakura@hadoop102 distributeby_staff]$ cat 000002_0 
xiaoxiaoli	4000.0	2
songxiaoqi	5200.0	2
zhaolaosi	7800.0	2
xiaowang	5900.0	2
```

----

ç»“åˆOrderByä½¿ç”¨

```shell
hive (default)> insert overwrite local directory '/opt/module/data/dist_sort_staff'
              > row format delimited 
              > fields terminated by '\t'
              > select name,sal,deptno
              > from staff
              > distribute by deptno       
              > sort by sal;

[sakura@hadoop102 dist_sort_staff]$ cat 000000_0 
linxiaohong	6000.0	3
wanglaowu	6000.0	3
lishasha	6450.0	3
chendaniu	7000.0	3
[sakura@hadoop102 dist_sort_staff]$ cat 000001_0 
liuerdao	6310.0	4
zhangfeng	8000.0	4
lixiaodan	13000.0	1
zhaozong29	50000.0	1
[sakura@hadoop102 dist_sort_staff]$ cat 000002_0 
xiaoxiaoli	4000.0	2
songxiaoqi	5200.0	2
xiaowang	5900.0	2
zhaolaosi	7800.0	2
```



### 6.5.4ã€ClusterBy

ä¸‹é¢æˆ‘ä»¬å­¦ä¹ ä¸€ä¸‹`ClusterBy`ï¼Œå…¶å®å®ƒåªé€‚ç”¨äºåˆ†åŒºæ’åºä¸­çš„ç‰¹æ®Šæƒ…å†µï¼š
==DistributeByå’ŒOrderByçš„å­—æ®µæ˜¯åŒä¸€ä¸ªå­—æ®µæ—¶ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨Cluster Byä»£æ›¿ã€‚==

> å‘é—®ï¼šå¯¹ä¸€ä¸ªå­—æ®µéƒ½åˆ†åŒºäº†ï¼Œæ¯ä¸ªåˆ†åŒºä¸­åˆ†åŒºå­—æ®µä¸åº”è¯¥éƒ½æ˜¯ä¸€æ ·çš„å—ï¼Ÿé‚£å†å¯¹å­—æ®µæ’åºä¸æ˜¯æ¯«æ— æ„ä¹‰å—ï¼Ÿ

å†å›å¤´çœ‹çœ‹åœ¨DistributeByä¸­æ ‡æ³¨çš„é‚£å¥è¯ï¼Œå½“ç†è®ºåˆ†åŒºæ•°é‡å¤§äºå®é™…çš„Reduceræ•°é‡çš„æ—¶å€™ï¼Œæ˜¯ä¼šå‡ºç°åˆ†åŒºä¸­åˆ†åŒºå­—æ®µä¸åŒçš„æƒ…å†µçš„ï¼ˆå‚è€ƒä¸Šä¸ªä¾‹å­ï¼‰ï¼æ‰€ä»¥è¿™ç§æ“ä½œè¿˜æ˜¯æœ‰æ„ä¹‰çš„ã€‚

å®æ“ï¼š

```shell
hive (default)> insert overwrite local directory '/opt/module/data/cluster_staff'
              > row format delimited 
              > fields terminated by '\t'
              > select name,sal,deptno
              > from staff
              > cluster by deptno;

# ç»“æœè‡ªè¡Œç†ä¼š
[sakura@hadoop102 cluster_staff]$ cat 000000_0 
chendaniu	7000.0	3
lishasha	6450.0	3
linxiaohong	6000.0	3
wanglaowu	6000.0	3
[sakura@hadoop102 cluster_staff]$ cat 000001_0 
zhaozong29	50000.0	1
lixiaodan	13000.0	1
liuerdao	6310.0	4
zhangfeng	8000.0	4
[sakura@hadoop102 cluster_staff]$ cat 000002_0 
xiaoxiaoli	4000.0	2
songxiaoqi	5200.0	2
zhaolaosi	7800.0	2
xiaowang	5900.0	2
```

----



## 6.6ã€åˆ†æ¡¶åŠæŠ½æ ·æŸ¥è¯¢

### 6.6.1ã€åˆ†æ¡¶è¡¨åŠæ•°æ®å­˜å‚¨

==åˆ†æ¡¶è¡¨ï¼šå»ºè¡¨æ—¶æŒ‡å®šå­—æ®µè¿›è¡Œåˆ†æ¡¶ï¼ŒæŒ‰ç…§åˆ†æ¡¶çš„è§„åˆ™å°†æ¯æ¡æ•°æ®ç»†åˆ†åˆ°æ¯ä¸ªæ¡¶ä¸­ï¼Œæ¯ä¸€ä¸ªæ¡¶åœ¨HDFSæ–‡ä»¶ç³»ç»Ÿä¸­è¡¨ç°ä¸ºä¸€ä¸ªæ–‡ä»¶ã€‚==å…¶è¡Œä¸ºç±»ä¼¼ä¸MapReduceä¸­Mapç«¯çš„æ•°æ®åˆ†åŒºã€‚

> è”ç³»ä¸Šé¢çš„åˆ†åŒºDistributeBy

å¦‚æœæ•°æ®çš„åˆ†åŒºè§„åˆ™æ˜¯ç¨³å®šçš„ï¼Œä½¿ç”¨äº†åˆ†æ¡¶ä»¥åï¼Œåç»­çš„æ•°æ®æ’å…¥éƒ½ä¼šåˆ¤æ–­åˆ†æ¡¶å­—æ®µç„¶åæ”¾å…¥å¯¹åº”çš„æ¡¶ä¸­ï¼Œå¹¶ä¸”æŸ¥è¯¢çš„æ—¶å€™æ— éœ€ä½¿ç”¨DistributeByæ¥æŒ‡å®šåˆ’åˆ†ï¼Œ==MRç¨‹åºå¯ä»¥æ ¹æ®æ¡¶çš„ä¸ªæ•°è‡ªè¡Œé€‰æ‹©Reducerçš„ä¸ªæ•°ï¼==

> å¯¹æ¯”åˆ†åŒºè¡¨

1. åˆ’åˆ†è§„åˆ™ä¸Šï¼Œ
   åœ¨åˆ†åŒºè¡¨ä¸­ï¼Œåˆ†åŒºä¾æ®çš„å­—æ®µæ˜¯ç‹¬ç«‹äºæ•°æ®çš„ï¼Œæ˜¯æˆ‘ä»¬é¢å¤–å¢åŠ çš„ä¸€ä¸ªå­—æ®µç”¨äºåˆ†åŒºï¼Œå¹¶ä¸èƒ½å¯¹æ•°æ®çš„æŸä¸€ä¸ªåˆ—å®Œæˆåˆ’åˆ†ã€‚
   åˆ†æ¡¶è¡¨ä¸­ï¼Œåˆ†æ¡¶çš„å­—æ®µæ˜¯æ•°æ®ä¸­çš„ï¼ŒæŒ‰ç…§ç‰¹å®šçš„åˆ—è¿›è¡Œåˆ’åˆ†ã€‚
2. å­˜å‚¨ä¸Šï¼Œ
   åˆ†åŒºè¡¨æ¯ä¸€ä¸ªåˆ†åŒºåœ¨HDFSä¸Šå¯¹åº”ä¸€ä¸ªç›®å½•
   åˆ†æ¡¶è¡¨æ¯ä¸€æ¡¶åœ¨HDFSä¸Šå¯¹åº”ä¸€ä¸ªæ•°æ®æ–‡ä»¶

> åˆ†æ¡¶è¡¨åˆ›å»ºï¼ˆå‚è€ƒ4.2.1ä¸­å»ºè¡¨è¯­æ³•ï¼‰

```shell
hive (default)> create table stu(id int,name string)
              > clustered by (id)  
              > into 3 buckets
              > row format delimited  
              > fields terminated by '\t';
# æ•°æ®æŒ‰ç…§idåˆ†æ¡¶ï¼Œæ•°æ®åˆ†åˆ°3ä¸ªæ¡¶ä¸­ã€‚
```



> é—®é¢˜ï¼šæ€ä¹ˆå‘åˆ†æ¡¶è¡¨æ’å…¥æ•°æ®å‘¢ï¼Ÿ

ç›´æ¥Load dataï¼Ÿï¼ˆå¾ˆæ˜¾ç„¶æ˜¯ä¸å¯ä»¥çš„ï¼ŒLoadæ“ä½œåº•å±‚å°±æ˜¯ä½¿ç”¨Hadoopçš„putï¼Œè¿™æ ·ä¸ç»è¿‡è®¡ç®—æ˜¾ç„¶æ˜¯ä¸è¡Œçš„ï¼Œå¬è¯´Hive3.Xå¯ä»¥ç›´æ¥ä½¿ç”¨Loadï¼Ÿï¼‰
æ‰€ä»¥å¾€åˆ†æ¡¶è¡¨ä¸­æ’å…¥æ•°æ®å¿…å®šè¦ç»è¿‡ä¸€æ¬¡MRï¼Œé‚£å°±è”æƒ³åˆ°äº†Insertå¯¼å…¥æ•°æ®ã€‚
==åœ¨æ­¤ä¹‹å‰æ£€æŸ¥ä¸¤ä¸ªå‚æ•°ï¼š==

- `hive.enforce.bucketing`(åˆ†æ¡¶æ”¯æŒï¼Œé»˜è®¤falseï¼Œéœ€æ”¹ä¸ºtrue)
- `mapreduce.job.reduces`(Ruduceræ•°é‡ï¼Œé»˜è®¤-1ï¼Œè¡¨ç¤ºMRè‡ªåŠ¨åˆ†é…)

```shell
hive (default)> set hive.enforce.bucketing=true;
hive (default)> set mapreduce.job.reduces=-1;
```

è®¾ç½®è¿™ä¿©å‚æ•°åï¼Œåˆ†æ¡¶æ‰èƒ½æœ‰æ•ˆï¼ŒMRç¨‹åºæ ¹æ®æ¡¶æ•°é‡å†³å®šReduceæ•°é‡ã€‚



==å¯¼å…¥æ•°æ®è¿‡ç¨‹==ï¼š

1. åˆ›å»ºä¸€ä¸ªæ™®é€šè¡¨ï¼Œé™¤äº†æ²¡æœ‰åˆ†æ¡¶å…¶ä»–å’Œåˆ†æ¡¶è¡¨ä¸€æ¨¡ä¸€æ ·

2. å…ˆæŠŠæ•°æ®å¯¼å…¥åˆ°æ™®é€šè¡¨ä¸­

   ```shell
   # åˆå§‹æ•°æ®
   stu_tmp.id	stu_tmp.name
   2			lisi
   3			wangwu
   4			songliu
   5			xiaoming
   6			xiaohong
   7			xiaoqiang
   8			aaa
   9			bbb
   10			ccc
   11			kongxiaoliu
   12			abaaba
   13			lvbuwei
   14			liubei
   15			guanyu
   ```

3. ä½¿ç”¨Insertå°†æ™®é€šè¡¨ä¸­çš„æ•°æ®å¯¼å…¥åˆ°åˆ†æ¡¶è¡¨

   ```shell
   hive (default)> insert into table stu
                 > select * from stu_tmp;
   ```

4. æŸ¥çœ‹HDFSæ–‡ä»¶çœ‹æ˜¯å¦åˆ†æ¡¶æˆåŠŸï¼š

   ![image-20200714163535166](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200714163535.png)

   ```shell
   [sakura@hadoop102 data]$ hadoop fs -cat /user/hive/warehouse/stu/000000_0
   6	xiaohong
   12	abaaba
   3	wangwu
   9	bbb
   15	guanyu
   [sakura@hadoop102 data]$ hadoop fs -cat /user/hive/warehouse/stu/000001_0
   4	songliu
   13	lvbuwei
   10	ccc
   7	xiaoqiang
   [sakura@hadoop102 data]$ hadoop fs -cat /user/hive/warehouse/stu/000002_0
   8	aaa
   14	liubei
   11	kongxiaoliu
   5	xiaoming
   2	lisi
   ```

   è¿™åˆ†æ¡¶çš„è§„åˆ™ä¸ç”¨å¤šè¯´è‚¯å®šä¹Ÿæ˜¯ **hashcode % bucketNum**

----



### 6.6.2ã€åˆ†æ¡¶çš„æŠ½æ ·æŸ¥è¯¢

> åˆ†æ¡¶æŠ½æ ·æŸ¥è¯¢è¯­å¥

`select * from table_name tablesample (bucket x out of y);`

---

> å‚æ•°è§£è¯»ä»¥åŠæŠ½æ ·è§„åˆ™

`x`ï¼šä»ç¬¬xä¸ªæ¡¶å¼€å§‹æŠ½å–æ•°æ®ï¼ˆæ¡¶ç¼–å·ä»1å¼€å§‹ï¼‰

`y`ï¼š**å¿…é¡»ä¸ºæ¡¶æ•°é‡çš„å€æ•°æˆ–è€…å› å­**ï¼Œé€šè¿‡yçš„å€¼æ¥ç¡®å®šæŠ½å–çš„æ•°æ®æ¯”ä¾‹ã€‚å…¬å¼ï¼šæŠ½å–(æ¡¶æ•°é‡Ã·y)ä¸ªbucketæ•°æ®ã€‚

è§„åˆ™ï¼š

1. å½“éœ€è¦ä»å¤šä¸ªbucketä¸­æŠ½å–æ•°æ®çš„æ—¶å€™ï¼ŒæŠ½å–çš„æ¡¶ç¼–å·ä¹‹é—´é—´éš”y! (x,x+y,x+2y,x+3y,..)

2. æ ¹æ®è§„åˆ™ä¸€æ¼”ç®—ï¼Œ==xæ˜¯ä¸èƒ½å¤§äºyçš„ã€‚==
   è‹¥x>y,æŒ‰ç…§è§„åˆ™ä¸€çš„è§„å¾‹ï¼Œæœ€åæŠ½çš„æ¡¶ç¼–å·i=x+[(æ¡¶æ•°é‡/y)-1]*y=>i=x+æ¡¶æ•°é‡-yï¼Œ
   å› ä¸ºx>yæ‰€ä»¥æœ€åæŠ½çš„æ¡¶ç¼–å·iæ˜¯ä¸€å®šå¤§äºæ¡¶çš„æ•°é‡çš„ï¼Œæ‰€ä»¥æ˜¯ä¸åˆä¹è§„èŒƒçš„ï¼ï¼
   å¦‚æœå‘½ä»¤è¡Œä¸­ä½¿ç”¨å‡ºç°äº†x>yï¼Œç›´æ¥æŠ¥é”™ï¼š

   ```shell
   FAILED: SemanticException [Error 10061]: Numerator should not be bigger than denominator in sample clause for table stu
   ```



> å®é™…æ¼”ç¤º

```shell
hive (default)> select * from stu tablesample (bucket 2 out of 3); #ä»äºŒå·æ¡¶å¼€å§‹æŠ½ä¸€æ¡¶æ•°æ®ï¼Œå³äºŒå·æ¡¶çš„æ‰€æœ‰æ•°æ®
OK
stu.id	stu.name
4	songliu
13	lvbuwei
10	ccc
7	xiaoqiang

select * from stu tablesample (bucket 1 out of 6); # ä»ä¸€å·æ¡¶å¼€å§‹ï¼ŒéšæœºæŠ½å‡º1/2æ¡¶çš„æ•°æ®ï¼Œå³ä¸€å·æ¡¶çš„1/2æ•°æ®
OK
stu.id	stu.name
6	xiaohong
12	abaaba
```



## 6.7ã€å…¶ä»–æŸ¥è¯¢å¸¸ç”¨å‡½æ•°

### ç©ºå­—æ®µèµ‹å€¼

`NVL(col_name,value|col)`

åœ¨æŸ¥è¯¢çš„æ—¶å€™ï¼Œé‚£äº›çƒ¦äººçš„NULLï¼Œçœ‹ç€æœ‰ç‚¹ç¢çœ¼ï¼Œä½¿ç”¨è¿™ä¸ªå‡½æ•°ï¼Œå¯ä»¥ç”¨å›ºå®šå€¼æˆ–è€…æŒ‡å®šåˆ—çš„å€¼æ¥æ›¿æ¢NULLã€‚

å‡½æ•°åŠŸèƒ½æè¿°ï¼šå½“æŸ¥è¯¢ç»“æœä¸­col_nameåˆ—çš„å€¼ä¸ºnullæ—¶ï¼Œä½¿ç”¨valueï¼ˆæˆ–è€…æŒ‡å®šåˆ—colçš„å€¼ï¼‰æ›¿æ¢nullï¼›

```shell
# ä¾‹å¦‚ç°åœ¨æœ‰è¿™æ ·ä¸€ç»„æ•°æ®
id	name	age
a1	zhsa	20
a2	lisi	null
a3	liuliu	19
a4	xiaowu	22
a5	liuyu	null

select name,nvl(age,0) from person;
# æŸ¥è¯¢ç»“æœå°±æ˜¯
name	age
zhsa	20
lisi	0
liuliu	19
xiaowu	22
liuyu	0
```

---



### æ—¶é—´ç±»

- æ—¶é—´æ ¼å¼åŒ–ï¼š`date_format(date_str|col,'format_str')`

  ```shell
  hive (default)> select date_format('2020-7-14','yyyy/MM/dd HH:mm:ss');
  OK
  _c0
  2020/07/14 00:00:00
  
  hive (default)> select date_format('2020/7/14','yyyy/MM/dd HH:mm:ss');
  OK
  _c0
  NULL # ä»¥/åˆ†éš”çš„æ—¶é—´æ ¼å¼ï¼Œhiveæ˜¯ä¸è®¤çš„å“¦ï¼Œå…¶ä»–æ—¶é—´ç›¸å…³çš„å‡½æ•°ä¹Ÿæ˜¯
  ```

  æ³¨æ„ï¼ç¬¬ä¸€ä¸ªå‚æ•°åªè®¤`yyyy-MM-dd`(å³ä»¥çŸ­æ¨ªçº¿åˆ†å‰²çš„)ï¼Œä¸è®¤`/`åˆ†å‰²çš„

  -----

- æ—¶é—´å’Œå¤©æ•°åŠ å‡ï¼š`date_add`æˆ–è€…`date_sub`(è®°ä½å…¶ä¸€å°±OKï¼Œå› ä¸ºå¤©æ•°å‚æ•°æ˜¯å¯ä»¥ä¸ºè´Ÿæ•°çš„)

  ```shell
  hive (default)> select date_add('2020-07-14',5);
  OK
  _c0
  2020-07-19
  Time taken: 0.042 seconds, Fetched: 1 row(s)
  hive (default)> select date_add('2020-07-14',-5);
  OK
  _c0
  2020-07-09
  ```

  æ³¨æ„æ—¶é—´æ ¼å¼ï¼

  ----

- æ—¥æœŸå¤©æ•°é—´éš”ï¼š`datediff()`

  ```shell
  hive (default)> select datediff('2020-7-14','2020-1-13');
  OK
  _c0
  183
  
  hive (default)> select datediff('2019-8-17','2020-7-14');
  OK
  _c0
  -332
  ```

  -----



ä¸‹é¢è¿™ä¸ªå‡½æ•°ä¸æ—¶é—´è®¡ç®—å…³ç³»ä¸å¤§ï¼Œä½†æ˜¯å¯ä»¥è§£å†³æ—¶é—´æ ¼å¼çš„é—®é¢˜ï¼Œæ—¶é—´ç±»å‡½æ•°ä¸­ä¸æ”¯æŒ(yyyy/MM/dd)æ ¼å¼çš„æ—¶é—´æ•°æ®ï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†`/`æ›¿æ¢ä¸º`-`

å­—ç¬¦ä¸²æ›¿æ¢å‡½æ•°ï¼š`regexp_replace('str','target','replace');`

```shell
hive (default)> select regexp_replace('2020/7/14','/','-');
OK
_c0
2020-7-14

# å˜¿å˜¿ï¼Œæ¥ä¸ªç»•çš„
hive (default)> select regexp_replace(date_add(regexp_replace('2020/7/14','/','-'),19),'-','/');
OK
_c0
2020/08/02
```

---



### case when then&if

 å½“åˆ—çš„å€¼æ˜¯æˆ‘ä»¬å¯æ§èŒƒå›´å†…çš„ï¼Œå¹¶ä¸”æˆ‘ä»¬å¸Œæœ›å¯¹æ•°æ®è¿›è¡Œåˆ’åˆ†çš„æ—¶å€™ï¼Œæ¯”å¦‚ç”·å¥³ç»Ÿè®¡ï¼Œå¹´é¾„ã€å·¥èµ„èŒƒå›´ç»Ÿè®¡ç­‰ç­‰ï¼Œå¯ä»¥ä¼šä½¿ç”¨åˆ°Caseåˆ†æ”¯å‡½æ•°ï¼Œæˆ–è€…if-elseã€‚

æ•°æ®å‡†å¤‡

```shell
staff.id	staff.name	staff.age	staff.sal	staff.deptno
1			xiaowang	25			5900.0		2
2			zhaolaosi	31			7800.0		2
3			wanglaowu	34			6000.0		3
4			songxiaoqi	23			5200.0		2
5			lixiaodan	27			13000.0		1
6			zhaozong29	29			50000.0		1
7			xiaoxiaoli	20			4000.0		2
8			linxiaohong	22			6000.0		3
9			lishasha	24			6450.0		3
10			zhangfeng	31			8000.0		4
11			chendaniu	29			7000.0		3
12			liuerdao	27			6310.0		4
```



**caseåˆ†æ”¯å‡½æ•°è¯­æ³•**ï¼š`case [col_name] when bool_exp|value then true_val else false_val end) `
å¯ä»¥ç»“åˆsum()åšæ•°é‡ç»Ÿè®¡ã€‚

```shell
# éœ€æ±‚ä¸€ï¼šåˆ†åˆ«ç»Ÿè®¡å¹´é¾„åœ¨(<22,22~28,>28)çš„ä¸‰ä¸ªåŒºé—´çš„äººæ•°ï¼Œåˆ†åˆ«å®šä½å°ç™½ï¼Œèœé¸Ÿï¼Œè€é¸Ÿ 
hive (default)> select
              > 	sum(case when age<22 then 1 else 0 end) xiaobai,
              > 	sum(case when age>=22 and age<=28 then 1 else 0 end) cainiao,
              > 	sum(case when age>28 then 1 else 0 end) laoniao
              > from staff;

xiaobai	cainiao	laoniao
1	6	5

# éœ€æ±‚äºŒï¼šç»Ÿè®¡å„ä¸ªéƒ¨é—¨çš„äººæ•° 1ï¼šç ”å‘éƒ¨ï¼Œ2ï¼šäººäº‹éƒ¨ï¼Œ3ï¼šè´¢åŠ¡éƒ¨ï¼Œ4ï¼šäº§å“éƒ¨
select
    sum(case deptno when 1 then 1 else 0 end) yanfabu,
    sum(case deptno when 2 then 1 else 0 end) renshibu,
    sum(case deptno when 3 then 1 else 0 end) caiwubu,
    sum(case deptno when 4 then 1 else 0 end) chanpinbu
from staff;

yanfabu	renshibu	caiwubu	chanpinbu
2		4			4		2
```



å½“åˆ†æ”¯åªæœ‰ä¸¤ä¸ªæ—¶ï¼Œå¯ä»¥ä½¿ç”¨`if`æ¥æ›¿ä»£ã€‚

**ifè¯­æ³•**ï¼š`if(bool_exp,true_val,false_val);`

```shell
# éœ€æ±‚ä¸‰ï¼šç»Ÿè®¡å·¥èµ„ä½äº6000å’Œé«˜äº6000çš„äººæ•°
select
    sum(if(sal<=6000,1,0)) xinren,
    sum(if(sal>6000,1,0)) laogou
from staff;

xinren	laogou
5		7
```



==case&ifçš„åˆ†æ”¯å–å€¼ï¼ˆtrue_val,false_valï¼‰ï¼Œå¯ä»¥æ˜¯å›ºå®šå†™æ­»çš„å€¼ï¼Œä¹Ÿå¯ä»¥æ˜¯ä½¿ç”¨åˆ—==

-----



### è¡Œè½¬åˆ—ï¼ˆæ‹¼æ¥å¤šåˆ—æ•°æ®ï¼‰

é€šå¸¸é‡åˆ°éœ€è¦å°†ä¸¤ä¸ªåˆ—çš„æ•°æ®è¿›è¡Œæ‹¼æ¥æ˜¾ç¤ºï¼Œç¦»ä¸å¼€`concat()`å‡½æ•°ï¼Œä¸concatåŠŸèƒ½ä¸€è‡´çš„è¿˜æœ‰ä¸€ä¸ªç‰¹æ®Šçš„å‡½æ•°ï¼š`concat_ws()`ã€‚

**concat() ä½¿ç”¨**ï¼Œ`concat(col_name|str,..)`å¯ä»¥æ‹¼æ¥ä»»æ„å¤šä¸ªå€¼

```shell
hive (default)> select concat('hello','!','world');
OK
_c0
hello!world
```

**concat_ws()ä½¿ç”¨**ï¼Œåœ¨ä½¿ç”¨concatè¿›è¡Œæ‹¼æ¥çš„æ—¶å€™ï¼Œæœ‰æ—¶å€™éœ€è¦é¢‘ç¹ä½¿ç”¨å›ºå®šçš„åˆ†éš”ç¬¦ï¼Œä½¿ç”¨concat_ws()å¯ä»¥å®šå¥½åˆ†éš”ç¬¦ï¼Œåªç®¡å†™æ•°æ®ï¼Œ`concat_ws(separator,value1,valu2,...)`

```shell
hive (default)> select concat_ws('-','this','is','concat_ws','usage');
OK
_c0
this-is-concat_ws-usage
```

ä½†æ˜¯å¾ˆé—æ†¾ï¼Œ==concat_wsåªå¯¹stringç±»å‹æˆ–è€…array<string\>é€‚ç”¨ã€‚==



å†ä»‹ç»ä¸€ä¸ªå‡½æ•°ï¼Œå¯ä»¥å°†æŸ¥è¯¢ç»“æœä¸­æŸä¸€åˆ—çš„æ‰€æœ‰å€¼ï¼Œæ”¶é›†æˆä¸ºsetæˆ–è€…listï¼ï¼`collect_set()/collect_list()`
listå’Œsetçš„åŒºåˆ«ä¸»è¦æ˜¯ï¼š==setæ˜¯å»é‡çš„==ã€‚ä¸¤è€…åˆç†é€‰æ‹©ä½¿ç”¨å³å¯ã€‚

```shell
hive (default)> select collect_set(age) from staff;

[25,31,34,23,27,29,20,22,24]
```

==collect_set,collect_listéƒ½æ˜¯èšåˆå‡½æ•°ï¼æ‰€ä»¥ä¸€èˆ¬ä½¿ç”¨ç¦»ä¸å¼€groupby~==



**å®æ“æ¡ˆä¾‹**

```markdown
# æ¡ˆä¾‹æ•°æ®
stu.name	stu.sex    stu.hobby
liming      man        basketball
wanghong    woman      tennis
liumeng	    woman      basketball
zhangli     man        ping-pong
wanglei     man	       basketball
likun       woman      tennis
zhaoqiang   man        basketball

# éœ€æ±‚åˆ†æ
è¦æ±‚ç»Ÿè®¡æ¯ç§è¿åŠ¨çš„ç”·å¥³åˆ†åˆ«çš„å–œå¥½äººåï¼Œä¾‹å¦‚ï¼š
sports_sex        member
basketball,man	  liming|wanglei|zhaoqiang
basketball,woman  liumeng
ping-pong,mam     zhangli
tennis,woman	  wanghong|likun

# è§£é¢˜æ€è·¯
1. é¦–å…ˆæŠŠsexã€hobbyä½¿ç”¨concat()è¿æ¥æˆå­—æ®µsport_sexå­—æ®µ
2. æŒ‰ç…§sport_sexå­—æ®µåˆ†ç»„ï¼Œä½¿ç”¨collect_set(),ç„¶åç”¨concat_ws()è¿›è¡Œå§“åæ‹¼æ¥ã€‚

# ä»£ç 
select 
    t1.sport_sex,
    concat_ws('|',collect_set(t1.name))
from
    (
        select
            concat(sport,',',sex) sport_sex,
            name
        from 
        	stu_sports
    ) t1
group by t1.sport_sex;

# è®¡ç®—ç»“æœ
basketball,man	liming|wanglei|zhaoqiang
basketball,woman	liumeng
ping-pong,man	zhangli
tennis,woman	wanghong|likun
```



### åˆ—è½¬è¡Œï¼ˆå•åˆ—æ•°æ®æ‹†åˆ†ï¼‰

åœ¨è¡Œè½¬åˆ—ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨collect_set()å’Œconcat()å°†åˆ—ä¸­çš„å¤šè¡Œæ•°æ®è½¬ä¸ºä¸€ä¸ªåˆ—çš„å•è¡Œæ•°æ®ã€‚
åœ¨åˆ—è½¬è¡Œä¸­ï¼Œæ“ä½œæ°æ°ç›¸åï¼šæˆ‘ä»¬è¦å°†==ä¸€ä¸ªåˆ—çš„å•è¡Œæ•°æ®è¿›è¡Œæ‹†åˆ†å½¢æˆå¤šè¡Œæ•°æ®==ã€‚ç±»ä¼¼çš„éœ€æ±‚ï¼šç”µå½±ç±»åˆ«çš„æ‹†åˆ†ã€‚

`explode()`ï¼šå¯ä»¥å°†é›†åˆä¸­å…ƒç´ æ‹†åˆ†æˆå¤šä¸ªå•é¡¹ã€‚
è¿˜æœ‰ä¸€ä¸ªä¸ä¹‹é…åˆä½¿ç”¨çš„è¯­æ³•ï¼š`lateral view`(ä¾§è§†å›¾ï¼Œä¾§å†™)ï¼Œä¸»è¦æ˜¯ç”¨å…¶å°†explode()ç”Ÿæˆçš„æ•°æ®è½¬åŒ–ä¸ºä¸€ä¸ªè§†å›¾æš‚å­˜ï¼Œç„¶åæ–¹ä¾¿å’ŒåŸæ•°æ®è¿›è¡Œå…³è”ã€‚

**æ¡ˆä¾‹å®æµ‹**

```markdown
# æ¡ˆä¾‹æ•°æ®
**movie.name**				**movie.genres**
Extreme Measures (1996)		Drama|Thriller
Upside Down (2012)			Drama|Romance|Sci-Fi
Liability, The (2012)		Action|Thriller
Angst  (1983)				Drama|Horror
Stand Up Guys (2012)		Comedy|Crime
Side Effects (2013)			Crime|Drama|Mystery|Thriller
Identity Thief (2013)		Comedy|Crime
ABCs of Death, The (2012)	Horror
Glimmer Man, The (1996)		Action|Thriller

# éœ€æ±‚æè¿°
å°†æ¯éƒ¨ç”µå½±å’Œå…¶æ¯ä¸ªåˆ†ç±»æµæ´¾å•ç‹¬å½¢æˆä¸€è¡Œè®°å½•ï¼Œæ–¹ä¾¿åç»­ç»Ÿè®¡ã€‚

# ç›®æ ‡ç»“æœ
**movie.name**				**movie.genres**
Extreme Measures (1996)		Drama
Extreme Measures (1996)		Thriller
..							..

# è§£é¢˜æ€è·¯
1. å¯¹genresä½¿ç”¨explode()
2. ä½¿ç”¨lateral viewæš‚å­˜explode()ç»“æœï¼Œç„¶åä¸å…³è”æ•°æ®(ç”µå½±å)åšç¬›å¡å°”ç§¯

# å®ç°è¿‡ç¨‹
- å»ºè¡¨ï¼ˆgenresä¸€å®šè¦å®šä¸ºé›†åˆç±»å‹ï¼Œå¦åˆ™æ˜¯æ— æ³•ä½¿ç”¨explode()ï¼‰
â€‹```sql
    create table movies(name string,genres array<string>)
    row format delimited 
    fields terminated by '\t'
    collection items terminated by '|';
â€‹```

- åŠ è½½æ•°æ®(æ¡ˆä¾‹æ•°æ®éœ€è¦è¿›è¡ŒåŠ å·¥)
Extreme Measures (1996)	["Drama","Thriller"]
Upside Down (2012)	["Drama","Romance","Sci-Fi"]
Liability, The (2012)	["Action","Thriller"]
Angst  (1983)	["Drama","Horror"]
Stand Up Guys (2012)	["Comedy","Crime"]
Side Effects (2013)	["Crime","Drama","Mystery","Thriller"]
Identity Thief (2013)	["Comedy","Crime"]
ABCs of Death, The (2012)	["Horror"]
Glimmer Man, The (1996)	["Action","Thriller"]

- SQLä»£ç æµ‹è¯•
æµ‹è¯•ä½¿ç”¨`explode()`
> `select explode(genres) from movies;`
ç»“æœ(éƒ¨åˆ†)ï¼š
col
Drama
Thriller
Drama
Romance
Sci-Fi
..

- å°è¯•ç›´æ¥ä½¿ç”¨explode(),ä¸ä½¿ç”¨lateral view
> `select name,explode(genres) from movies;`
æŠ¥é”™ï¼šUDTF's are not supported outside the SELECT clause, nor nested in expressions 
åŸå› ï¼šå½“ä½¿ç”¨UDTFå‡½æ•°ï¼ˆä¾‹å¦‚explode()ï¼‰çš„æ—¶å€™,hiveåªå…è®¸å¯¹æ‹†åˆ†å­—æ®µè¿›è¡Œè®¿é—®ï¼Œè€Œnameå¹¶ä¸æ˜¯ã€‚


- æµ‹è¯•ç»“åˆä½¿ç”¨lateral view
â€‹```sql
select 
	name, 
    movie_genre
from
	movies lateral view explode(genres) table_tmp as movie_genre;
â€‹```
ç»“æœï¼ˆéƒ¨åˆ†ï¼‰ï¼š
Extreme Measures (1996)	Drama
Extreme Measures (1996)	Thriller
Upside Down (2012)	Drama
Upside Down (2012)	Romance
Upside Down (2012)	Sci-Fi
```

ä¸Šè¿°æ¡ˆä¾‹ä¸­ä½¿ç”¨çš„`lateral view`ç›¸å½“äºæŠŠexplode()çš„ç»“æœç”¨ä¸€å¼ ä¸´æ—¶çš„è¡¨å­˜äº†èµ·æ¥ï¼Œå¹¶é‡å‘½ååˆ—ï¼Œç„¶åäºåŸæ•°æ®ä¸­çš„nameè¿›è¡Œå…³è”ã€‚å·§å¦™è§£å†³äº†æ­¤å‰çš„æŠ¥é”™é—®é¢˜ã€‚



### çª—å£å‡½æ•°

#### 1ã€äº†è§£å’Œè®¤è¯†çª—å£å‡½æ•°over()

> over:æŒ‡å®šåˆ†æå‡½æ•°å·¥ä½œçš„æ•°æ®çª—å£å¤§å°ï¼Œçª—å£å¤§å°éšç€è¡Œå˜åŒ–è€Œå˜åŒ–ã€‚

æˆ‘ä»¬å…ˆä¸ä»‹ç»å¤ªå¤šï¼Œæµ‹è¯•å¯¹æ¯”ä¸€ä¸‹æ…¢æ…¢ç†è§£ã€‚

æµ‹è¯•æ•°æ®å‡†å¤‡ï¼š

```markdown
**name**	**orderdate**	**cost**
jack	2017-01-01	10
tony	2017-01-02	15
jack	2017-02-03	23
tony	2017-01-04	29
jack	2017-01-05	46
jack	2017-04-06	42
tony	2017-01-07	50
jack	2017-01-08	55
mart	2017-04-08	62
mart	2017-04-09	68
neil	2017-05-10	12
mart	2017-04-11	75
neil	2017-06-12	80
mart	2017-04-13	94

create table marketorder(name string,orderdate string,cost int)
row format delimited 
fields terminated by '\t';
```

éœ€æ±‚ï¼š**ç»Ÿè®¡2017å¹´4æœˆæ¶ˆè´¹çš„äººæ•°ä»¥åŠäººåã€‚**
ç›®æ ‡è¾“å‡ºï¼š

```markdown
jakc	2
mart	2
# è¡¨ç¤ºä¸€å…±ä¸¤äººï¼Œjack mart
```



è§£é¢˜æ€è·¯å…¨è¿‡ç¨‹ï¼š

1. ç»Ÿè®¡æ€»æ•°è‚¯å®šç¦»ä¸å¼€count(),éšä¹‹å°±ä¼šè”æƒ³åˆ°åˆ†ç»„(GroupBy)

2. å¯¹orderdateåˆ†ç»„è‚¯å®šä¸å¤ªç°å®ï¼Œåªèƒ½ç»Ÿè®¡å‡ºæ¯ä¸ªäººçš„è®¢å•çš„æ•°é‡ï¼Œå…¶å®é—®é¢˜å‡ºåœ¨GroupByçš„ä¸€ä¸ªç‰¹æ®Šæœºåˆ¶ï¼Œ==selectä¸­çš„æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»å‡ºç°åœ¨GroupByçš„å­—æ®µä¸­ï¼==ã€‚
   è¿™ä¸ªéœ€æ±‚çš„æè¿°ä¸­å°±æš—ç¤ºç€GroupByä¸­å¿…å®šæœ‰nameè¿™ä¸ªå­—æ®µï¼Œæ‰€ä»¥å³ä¾¿æˆ‘ä»¬æŒ‰ç…§orderdateçš„æœˆä»½åˆ†ç»„å¹¶ç­›é€‰å‡ºæ¥çš„4æœˆè®¢å•ä¹Ÿä¼šè¢«nameåˆ†ä¸ºä¸¤ä¸ªç»„ã€‚

   ```markdown
   # SQL
   select 
   	name,
   	count(*)
   from 
   	marketorder 
   group by 
   	substring(orderdate,1,7),
   	name
   having 
   	substring(orderdate,1,7)='2017-04';
   # groupbyç»“æœ
   > åˆ†ç»„ä¸€
   jack	2017-04
   > åˆ†ç»„äºŒ
   mart	2017-04
   mart	2017-04
   mart	2017-04
   mart	2017-04
   
   # ç»“æœ
   jack	1
   mart	4
   ```

3. è½¬ç§»é˜µåœ°ï¼Œå°±åªå¯¹nameåˆ†ç»„ï¼Œç„¶ååœ¨whereä¸­å¯¹æœˆä»½ç­›é€‰ï¼Œå…¶å®å’Œä¸Šé¢è¿™ç§æ²¡ä»€ä¹ˆåŒºåˆ«ï¼Œ==åªè¦æ˜¯å¯¹nameåˆ†äº†ç»„ï¼Œæƒ³ç»Ÿè®¡æ€»æ•°ï¼ˆç›¸å½“äºç»Ÿè®¡åˆ†ç»„æ•°é‡ï¼‰å°±åŸºæœ¬å¾ˆéš¾å®Œæˆ==

   ```markdown
   # SQL
   select
   	name,
   	count(*) 
   from
   	marketorder
   where
   	substring(orderdate,1,7)='2017-04'
   group by
   	name;
   
   # ç»“æœ
   jack	1
   mart	4
   ```

4. å‘ç°ç»“æœè¿˜æ˜¯è¿™ä¸ªæ ·ï¼ŒåŸå› å°±æ˜¯groupbyå¯¹nameåˆ†ç»„ä»¥åï¼Œè™½ç„¶æ˜¾ç¤ºçš„æ˜¯jackï¼Œmartå…¶å®æ˜¯ä»£è¡¨ä¸¤ä¸ªç»„ï¼Œé‚£ä¹ˆæ‰§è¡Œcount(*)å°±æ˜¯é’ˆå¯¹äºæ¯ä¸ªç»„æ¥ç»Ÿè®¡ã€‚é‚£ä¸¤ä¸ªç»„çš„è®°å½•åœ¨æ­¥éª¤2ä¸­åˆ—å‡ºï¼Œæ‰€ä»¥å¾—åˆ°1,4çš„ç»“æœå¹¶ä¸æ„å¤–ã€‚

   ```markdown
   # SQL
   select 
   	name 
   from 
   	marketorder 
   where 
   	substring(orderdate,1,7)='2017-04' 
   group by
   	name;
   # ç»“æœ
   jack
   mart
   ```

5. ç†æƒ³çš„å®ç°è¿‡ç¨‹ï¼š==æŠŠæ­¥éª¤4çš„ç»“æœå•ç‹¬æ‹å‡ºæ¥å†åšä¸€æ¬¡countå‘¢ï¼Ÿ==
   ç›®å‰æˆ‘ä»¬æˆ‘ä»¬é€šè¿‡å­æŸ¥è¯¢åµŒå¥—è¿˜æ˜¯åªèƒ½ç»Ÿè®¡å‡ºæ€»æ•°é‡ï¼Œè€Œä¸èƒ½æ˜¾ç¤ºåå­—ï¼Œå¦‚æœè¦æ˜¾ç¤ºåå­—ï¼Œå¤–å±‚SQLä¹Ÿè¦ç”¨GroupByï¼Œç»“æœå°±åˆä¸ä¸€æ ·äº†ã€‚

   ```markdown
   # SQL 1
   select
       count(*)
   from
       (
           select 
               name 
           from 
               marketorder 
           where 
               substring(orderdate,1,7)='2017-04' 
           group by
               name
       ) t1;
   # ç»“æœ
   2
   
   # SQL 2
   select
       t1.name,
       count(*)
   from
       (
           select 
               name 
           from 
               marketorder 
           where 
               substring(orderdate,1,7)='2017-04' 
           group by
               name
       ) t1
   group by 
   	t1.name;
   # ç»“æœ
   jack	1
   mart	1
   ```

6. æ— è®ºæ€æ ·ä½¿ç”¨ç°æœ‰çš„çŸ¥è¯†è¿˜ä¸è¶³ä»¥ç”¨å¾ˆç®€å•çš„åŠæ³•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
   ä½†æ˜¯æ€è·¯å·²ç»ç¡®å®šï¼šå°†æŒ‰ç…§åå­—åˆ†ç»„çš„ç»“æœå†åšä¸€æ¬¡å•ç‹¬çš„countã€‚çª—å£å‡½æ•°ä¸­çš„over()ä¹Ÿè®¸å¯ä»¥å¸®ä¸Šå¿™ã€‚
   ==çª—å£å‡½æ•°over()å¯ä»¥åšåˆ°ï¼šå¯¹æ•°æ®é‡æ–°å¼€ä¸€ä¸ªçª—å£è¿›è¡Œåˆ†æè®¡ç®—ã€‚==
   é‚£ä¹ˆè¿™ä¸ªçª—å£æ˜¯ä»€ä¹ˆæ¦‚å¿µå‘¢ï¼Ÿ==ç›®å‰æˆ‘ç®€å•åœ°å°†å…¶è®¤ä¸ºæ˜¯å¯¹å½“å‰çš„æ•°æ®è¿›è¡Œæå–ï¼Œå½¢æˆä¸€ä¸ªæ–°çš„ä¸´æ—¶æ•°æ®é›†ä¾›æˆ‘ä»¬å•ç‹¬ä½¿ç”¨ã€‚==

   ä¾‹å¦‚ï¼š

   ```markdown
   # æ­¥éª¤å››SQLæŸ¥è¯¢ç»“æœ
   jack
   mart
   > è™½ç„¶è¿™ä¸¤è¡Œæ•°æ®åœ¨é‚£ä¸ªSQLä¸­åªæ˜¯ä»£è¡¨ç€ä¸¤ä¸ªåˆ†ç»„ï¼Œæ¯ä¸ªåˆ†ç»„ä¸­åˆæœ‰è‹¥å¹²æ•°æ®ã€‚ä½†æ˜¯åœ¨ä½¿ç”¨çª—å£å‡½æ•°over()çš„æ—¶å€™ï¼Œæˆ‘å°±åªå½“å®ƒæ˜¯ä¸¤è¡Œæ•°æ®æå–å‡ºæ¥å°±æ˜¯æ™®æ™®é€šé€šçš„ä¸¤è¡Œè®°å½•ï¼Œç„¶åå†ä½¿ç”¨count(),ç»“æœä¸º2ï¼›
   ```

7. çª—å£å‡½æ•°over()æµ‹è¯•ä½¿ç”¨

   ```markdown
   # SQL
   select
       name,
       count(*) over()
   from
       marketorder
   where
       substring(orderdate,1,7)='2017-04'
   group by
       name;
       
   # ç»“æœ
   name	count_window_0
   mart	2
   jack	2
   ```

   - over():==æ— å‚==è¡¨ç¤ºçª—å£å¤§å°å¯¹åº”==æ‰€æœ‰==æ•°æ®è¡Œã€‚
   - over()åœ¨èšåˆå‡½æ•°count(*)ä¹‹å: è¡¨ç¤ºå¯¹åˆ†ç»„åçš„ç»“æœæ•°æ®é‡æ–°å¼€è¾Ÿçª—å£ç„¶åä½¿ç”¨count(\*);



over()ç»ƒä¹ æ¡ˆä¾‹ï¼š**è¾“å‡ºè®¢å•æ˜ç»†ï¼Œå¹¶ç»Ÿè®¡è®¢å•æ€»é‡‘é¢ã€‚**

```markdown
# ä½ ä»¥ä¸ºçš„SQL
select 
	*,
    sum(cost)
from
	marketorder;
# ç»“æœ
è¦æ±‚ä½¿ç”¨groupbyï¼Œso æ²¡è¿™ä¹ˆç®€å•ã€‚

# å®é™…ä¸Šçš„SQL
select 
	*,
    sum(cost) over()
from
	marketorder;
	
# ç»“æœï¼ˆéƒ¨åˆ†ï¼‰
marketorder.name	marketorder.orderdate	marketorder.cost	sum_window_0
mart	2017-04-13	94	661
neil	2017-06-12	80	661
mart	2017-04-11	75	661
..
```

> ä¸Šè¿°æ¡ˆä¾‹éƒ½æ¶‰åŠä¸€ä¸ªé—®é¢˜å°±æ˜¯ï¼š==SQLä¸­åªè¦ç”¨åˆ°èšåˆå‡½æ•°å°±ä¸€å®šè¦ç”¨åˆ°group by å—ï¼Ÿ==
>
> å›ç­”ï¼šä¸ä¸€å®šï¼Œè¦åˆ†æƒ…å†µè€Œå®š
> 1ã€å½“èšé›†å‡½æ•°å’Œéèšé›†å‡½æ•°å‡ºç°åœ¨ä¸€èµ·æ—¶ï¼Œéœ€è¦å°†éèšé›†å‡½æ•°è¿›è¡Œgroup by
> 2ã€å½“åªåšèšé›†å‡½æ•°æŸ¥è¯¢æ—¶å€™ï¼Œå°±ä¸éœ€è¦è¿›è¡Œåˆ†ç»„äº†ã€‚
>
> ä¸Šè¿°æƒ…å†µä¸­ï¼Œselectå­—æ®µä¸­æ—¢æœ‰ä½¿ç”¨äº†èšåˆå‡½æ•°çš„åˆ—ï¼Œåˆæœ‰æœªä½¿ç”¨èšåˆå‡½æ•°çš„åˆ—ï¼Œæ­¤æ—¶å¯¹äºæœªä½¿ç”¨èšåˆå‡½æ•°çš„åˆ—è¦è¿›è¡Œgroupby
>
>  
>
> é™¤æ­¤ä»¥å¤–å†äº†è§£ä¸€ä¸‹SQLçš„æ‰§è¡Œé¡ºåº
>
> ==from -> join on -> where -> group by -> having -> select -> order by -> limit==

---



#### 2ã€äº†è§£over()å‡½æ•°å‚æ•°é€‰æ‹©

åœ¨over()å‡½æ•°çš„å…¥é—¨äº†è§£é˜¶æ®µï¼Œæˆ‘ä»¬æåˆ°å½“overå‡½æ•°çš„å‚æ•°ä¸ºç©ºæ—¶ï¼Œ==é»˜è®¤å¼€å¯çš„çª—å£å¤§å°æ˜¯æ‰€æœ‰æ•°æ®è¡Œ==ã€‚ä¹Ÿå°±æ˜¯æ˜¯æˆ‘ä»¬å¯ä»¥é€šè¿‡å‚æ•°è°ƒåˆ¶çª—å£å¤§å°ï¼Œç„¶èšåˆå‡½æ•°å¯¹éƒ¨åˆ†åŒºåŸŸçš„æ•°æ®æœ‰æ•ˆã€‚

å¯æ€•çš„éœ€æ±‚æ¥å’¯ï¼š

- åŸºç¡€ç‰ˆï¼šæŒ‰ç…§æ—¥æœŸé¡ºåºç»Ÿè®¡å½“å‰æ”¶ç›Šé‡‘é¢ã€‚ï¼ˆcostç´¯åŠ ï¼‰

  ```markdown
  # æœŸæœ›è¾“å‡º
  jack	2017-01-01	10
  tony	2017-01-02	25
  tony	2017-01-04	54
  jack	2017-01-05	100
  ...
  
  # é‡åˆ°éº»çƒ¦äº†..
  > ä½¿ç”¨ä¹‹å‰çš„over(),ç„¶åä½¿ç”¨èšé›†å‡½æ•°sum(),åªèƒ½ç»Ÿè®¡å‡ºæ¥æ€»æ•°ã€‚
  
  # æ­£ç¡®çš„è§£é¢˜æ€è·¯
  > å°†è®¢å•æŒ‰ç…§æ—¥æœŸæ’åºï¼Œç„¶åé€æ¸æ”¾å¤§çª—å£å¤§å°ï¼Œä»1æ¡ï¼Œ2æ¡ï¼Œç›´åˆ°æ‰€æœ‰ã€‚å®Œç¾å¥‘åˆéœ€æ±‚ã€‚
  
  # æ€ä¹ˆæ§åˆ¶çª—å£å¤§å°é¡ºåºå˜å¤§å‘¢ï¼Ÿä»£ç å‘ˆä¸Š=>
  select
      *,
      sum(cost) over(order by orderdate)
  from
      marketorder;
  
  # ç»“æœ
  name	orderdate	cost	sum_window_0
  jack	2017-01-01	10	10
  tony	2017-01-02	15	25
  tony	2017-01-04	29	54
  jack	2017-01-05	46	100
  tony	2017-01-07	50	150
  jack	2017-01-08	55	205
  ..
  ```

  æ ¹æ®ä»£ç æ¥çœ‹ï¼Œå¾ˆæ¸…æ¥šæˆ‘ä»¬å°±æ˜¯åœ¨overçš„å‚æ•°ä¸Šåšæ–‡ç« ã€‚`order by`å¹¶æ²¡æœ‰å†™åœ¨selectæŸ¥è¯¢è¯­å¥ä¸­ï¼Œè€Œæ˜¯æ¬åˆ°äº†`over()`å‡½æ•°çš„å‚æ•°ä¸­ã€‚å‘Šè¯‰å¼€çª—å‡½æ•°æŒ‰ç€æ—¥æœŸçš„é¡ºåºä¾æ¬¡æ”¾å¤§çª—å£ï¼Œæ¯ä¸€ä¸ªçª—å£æ‰§è¡Œä¸€æ¬¡sumï¼Œå°±å¾—åˆ°äº†ç»“æœã€‚

  ----

- è¿›é˜¶ç‰ˆï¼šåœ¨åŸºç¡€ç‰ˆçš„åŸºç¡€ä¸Šæ”¹ä¸ºç»Ÿè®¡æ¯ä¸ªäººçš„æ¶ˆè´¹ç´¯åŠ ã€‚(æŒ‰äººååˆ†ç»„ï¼Œæ¯ç»„ç´¯åŠ cost)

  ```markdown
  # è§£é¢˜æ€è·¯
  > çª—å£æŒ‰ç…§nameåˆ†ç»„å¼€æ”¾,æ¯ä¸ªåˆ†ç»„å†…æŒ‰ç…§æ—¥æœŸé€æ¸æ”¾å¤§çª—å£
  
  # æ€ä¹ˆè¿›è¡Œçª—å£åˆ†ç»„å¼€æ”¾ï¼Ÿä»£ç å‘ˆä¸Š=>
  select
      *,
      sum(cost) over(distribute by name sort by orderdate)
  from
      marketorder;
  
  # ç»“æœ(éƒ¨åˆ†)
  jack	2017-01-01	10	10
  jack	2017-01-05	46	56
  jack	2017-01-08	55	111
  jack	2017-02-03	23	134
  jack	2017-04-06	42	176
  ..
  
  # å°åˆ†æ
  `distribute by`å’Œ`sort by`æ˜¯é‡ç‚¹ï¼åœ¨6.5ä¸­ä»‹ç»ä¸¤è€…çš„åŠŸèƒ½åˆ†åˆ«æ˜¯ï¼šæ•°æ®åˆ†åŒºã€åŒºå†…æ’åºã€‚
  ä¹Ÿå¯ä»¥ä½¿ç”¨partition byå’Œorder byç»“åˆä½¿ç”¨æ›¿æ¢ã€‚
  ```



é™¤äº†å¸¸ç”¨çš„`distribute by`ã€`sort by`ã€`partition by`ã€`order by`ã€‚
è¿˜æœ‰å¯ä»¥ä½¿ç”¨ä½¿ç”¨` rows [betweem .. and ..]`ï¼Œä¸¤å¤„å¯å¡«ä»¥ä¸‹æ•°å€¼

- **current row**ï¼šä»£è¡¨å½“å‰è¡Œ
- **n perceding**ï¼šå¾€å‰nè¡Œæ•°æ®
- **n following**ï¼šå¾€ånè¡Œæ•°æ®
- **unbounded**ï¼šèµ·æ­¢ä½ç½®
  - unbounded precedingï¼šè¡¨ç¤ºä»æ•°æ®çš„èµ·ç‚¹
  - unbounded followingï¼šè¡¨ç¤ºåˆ°æ•°æ®çš„ç»ˆç‚¹



---



#### 3ã€over()å¤–å¸¸ç”¨å‡½æ•°

`lag(col,n,default_val)`ï¼šå½“å‰æ•°æ®å¾€**å‰**ç¬¬næ¡è®°å½•ä¸­colåˆ—çš„æ•°å€¼

`lead(col,n,default_val)`ï¼šå½“å‰æ•°æ®å¾€**å**ç¬¬næ¡è®°å½•ä¸­colåˆ—çš„æ•°å€¼

ä»¥ä¸Šä¸¤ä¸ªå‡½æ•°éœ€è¦ç”¨over()è¿›è¡Œè¾…åŠ©ä½¿ç”¨ã€‚==å¯ä»¥åœ¨ä¸ºæ¯æ¡è®°å½•å¼€è¾Ÿçª—å£çš„æ—¶å€™è·¨è¡Œè®¿é—®åˆ°æ•°æ®å¹¶åŠ ä»¥åˆ©ç”¨ã€‚==



**ä½¿ç”¨åœºæ™¯ï¼šåœ¨æ¯ä¸€æ¡æ¶ˆè´¹è®°å½•ä¸Šå¢åŠ ä¸€åˆ—ï¼Œæ˜¾ç¤ºç”¨æˆ·ä¸Šä¸€æ¬¡æ¶ˆè´¹çš„æ—¥æœŸã€‚**

```markdown
# è§£é¢˜æ€è·¯
> å…ˆæŒ‰ç…§nameåˆ†ç»„ï¼Œæ¯ç»„æŒ‰ç…§orderdateé¡ºåºå¼€æ”¾çª—å£ï¼Œæ¯æ¬¡ä¸ºä¸€æ¡è®°å½•å¼€è¾Ÿçª—å£æ—¶ï¼Œè·å–å‰ä¸€è¡Œæ•°æ®çš„orderdateåˆ—å¹¶åŠ åˆ°æŸ¥è¯¢ç»“æœåˆ—ä¸­ã€‚

# ä½¿ç”¨lag()å®Œæˆéœ€æ±‚
select
    *,
    lag(orderdate,1,'1970-01-01') over(distribute by name sort by orderdate)
from
    marketorder;

# ç»“æœ(éƒ¨åˆ†)
name	orderdate	cost	lasttime
jack	2017-01-01	10	1970-01-01
jack	2017-01-05	46	2017-01-01
jack	2017-01-08	55	2017-01-05
jack	2017-02-03	23	2017-01-08
jack	2017-04-06	42	2017-02-03
...
```

leadçš„ç”¨æ³•ä¸ä¹‹ç›¸åŒï¼Œå¥½å¥½ç†ä¼šå…¶ä¸­çš„æ‰§è¡Œè¿‡ç¨‹å§ã€‚





`ntile(n)`ï¼šå¯¹æœ‰åºçš„æ•°æ®åˆ†ä¸ºnä¸ªç»„ï¼Œå¹¶ä¿è¯åˆ†ç»„ä¸­çš„æ•°æ®å‡åŒ€ã€‚æ¯æ¡è®°å½•éƒ½æœ‰å¯¹åº”çš„åˆ†ç»„å·ï¼ˆä»1å¼€å§‹ï¼‰

æµ‹è¯•ä¸€ä¸‹ï¼š

```markdown
select
    name,
    orderdate,
    cost,
	ntile(5) over(order by orderdate)
from
	marketorder;

# ç»“æœ(éƒ¨åˆ†)
name	orderdate	cost	ntile_window_0
jack	2017-01-01	10	1
tony	2017-01-02	15	1
tony	2017-01-04	29	1
jack	2017-01-05	46	2
tony	2017-01-07	50	2
jack	2017-01-08	55	2
...
```



**éœ€æ±‚ï¼šæŒ‰ç…§æ—¥æœŸé¡ºåºç­›é€‰å‡ºå‰10%çš„è®¢å•**

 ```markdown
# éœ€æ±‚çš„éš¾ç‚¹ï¼Œä»¥åŠä¸ºä»€ä¹ˆä½¿ç”¨ntile
> æ­¤éœ€æ±‚æ˜¯ç«™åœ¨æ€»ä½“æ•°æ®é›†çš„è§’åº¦æ¥çœ‹ï¼Œå¹¶ä¸æ˜¯è¯´å›ºå®šçš„æ¡æ•°ï¼Œè€Œä¸€ä¸ªæ¯”ä¾‹æ•°ï¼Œé‚£ä¹ˆåœ¨ç°å®åœºæ™¯ä¸­æˆ‘ä»¬æ— ä»å¾—çŸ¥æ€»è®°å½•æ•°ï¼Œä¹Ÿå°±éš¾ä»¥åˆ¤æ–­å‰10%æ˜¯å¤šå°‘æ¡æ•°æ®ã€‚
å¯æ˜¯ä½¿ç”¨ntile(10),å…ˆå°†å¹³å‡æ•°æ®åˆ†ç»„æˆ10ä»½ï¼Œå–å‡ºåˆ†ç»„å·ä¸º1çš„åˆ†ç»„å³ä¸ºå‰10%ã€‚

# ä¸Šä»£ç 
- é”™è¯¯ç¤ºèŒƒ
select
    name,
    orderdate,
    cost,
    ntile(10) over(order by orderdate) ntile_10
from
    marketorder
where
    ntile_10=1;
> é”™è¯¯è§£é‡Šï¼šåŸºæœ¬é”™è¯¯ï¼ï¼åœ¨SQLçš„æ‰§è¡Œè¿‡ç¨‹ä¸­whereè¦å…ˆäºselectï¼Œæ‰€ä»¥whereé‡Œé¢ä¸èƒ½ä½¿ç”¨åˆ—åˆ«åï¼ŒåŒç†è¿™é‡Œntile(10)ä¹Ÿæ˜¯åœ¨selectä¸­æ‰æ‰§è¡Œã€‚

- æ­£ç¡®ç¤ºèŒƒ
select
    name,
    orderdate,
    cost
from
    (
        select
            name,
            orderdate,
            cost,
            ntile(10) over(order by orderdate) ntile_10
        from
            marketorder
    ) t1
where
    t1.ntile_10=1;
    
# ç»“æœ
name	orderdate	cost
jack	2017-01-01	10
tony	2017-01-02	15
 ```





#### 4ã€æ’è¡ŒRank

å¸¸ç”¨çš„ä¸‰ç§æ’è¡Œå‡½æ•°ï¼š

- `RANK() `ï¼šæ’åºå­—æ®µç›¸åŒæ—¶ï¼Œé‡å¤ä½†æ€»æ•°ä¸å˜åŒ–(è®¡æ•°å™¨ä¸å½±å“)ã€‚
- `DENSE_RANK()`ï¼šæ’åºå­—æ®µç›¸åŒæ—¶ï¼Œé‡å¤ä½†æ˜¯æ€»æ•°å‡å°‘(è®¡æ•°å™¨åœæ»)ã€‚
- `ROW_NUMBER()`ï¼šæ’åºå­—æ®µç›¸åŒæ—¶ï¼ŒæŒ‰ç…§é¡ºåºè®¡æ•°æ’è¡Œã€‚



**æ¡ˆä¾‹ï¼šç»™å­¦ç”Ÿå¤šç§‘æˆç»©ï¼ŒæŒ‰ç…§å­¦ç§‘åˆ†ç±»æ’åã€‚**

```markdown
# æ¡ˆä¾‹æ•°æ®
**name**	**subject**	**score**
xiaohong	math	98
xiaoming	english	71
xiaolimi	computer	86
xiaoqiang	math	81
xiaoming	computer	93
xiaoqiang	english	81
xiaohong	computer	93
xiaoming	math	88
xiaolimi	english	95
xiaohong	english	95
xiaoqiang	computer	90
xiaolimi	math	87

# å»ºè¡¨
create table score(name string,subject string,score int)
row format delimited
fields terminated by '\t';

# æ¡ˆä¾‹éœ€æ±‚çš„ä»£ç =>
select
    name,
    subject,
    score,
    rank() over(partition by subject order by score DESC) rank,
    dense_rank() over(partition by subject order by score DESC) dense_rank,
    row_number() over(partition by subject order by score DESC) row_number
from
    score;

# è¿è¡Œç»“æœ(éƒ¨åˆ†)
name		subject		score	rank	dense_rank	row_number
xiaohong	computer	93		1		1			1
xiaoming	computer	93		1		1			2
xiaoqiang	computer	90		3		2			3
xiaolimi	computer	86		4		3			4

```

ä¸‰è€…ä¹‹é—´çš„åŒºåˆ«é€šè¿‡ç»“æœå°±å¯ä»¥çœ‹å¾—ä¸€æ¸…äºŒæ¥šã€‚

-----



# ä¸ƒã€å‡½æ•°

## 7.1ã€ç³»ç»Ÿå†…ç½®å‡½æ•°

- æŸ¥çœ‹ç³»ç»Ÿè‡ªå¸¦å‡½æ•°

  `show functions;`

- æŸ¥çœ‹æŸä¸ªå‡½æ•°çš„ç”¨æ³•

  `desc funtion function_name;`
  
- è¯¦ç»†æŸ¥çœ‹ç”¨æ³•ï¼ˆå¸¦ç¤ºä¾‹ï¼‰

  `desc function extended function_name;`

---



## 7.2ã€è‡ªå®šä¹‰å‡½æ•°

åœ¨çœŸå®çš„ä¸šåŠ¡åœºæ™¯ä¸­ï¼Œç³»ç»Ÿå†…ç½®çš„å‡½æ•°ä¸è¶³ä»¥æ»¡è¶³æˆ‘ä»¬çš„æŸäº›ç‰¹æ®Šéœ€æ±‚ï¼Œå³ä½¿å¯ä»¥å®ç°ä¹Ÿè¦ç»è¿‡ä¸€å¥—å¤æ‚çš„æµç¨‹ã€‚é‚£ä¹ˆè¿™æ—¶å¯ä»¥è€ƒè™‘è‡ªå®šä¹‰å‡½æ•°ã€‚ï¼ˆ**UDFï¼šUser-Defined-Function**ï¼‰

> ä¸‰ç±»ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°

- **UDF**(User-Defined-Function)ï¼šä¸€è¿›ä¸€å‡º
- **UDAF**(User-Defined Aggregation-Function)ï¼šèšé›†å‡½æ•°,å¤šè¿›ä¸€å‡º
- **UDTF**(User-Defined Table-Genertating Function)ï¼šä¸€è¿›å¤šå‡ºï¼Œä¾‹å¦‚`lateral view explore()`



### 7.2.1ã€è‡ªå®šä¹‰UDFå‡½æ•°å…·ä½“æ­¥éª¤

1. ç»§æ‰¿ **org.apache.hadoop.hive.ql.UDF**ç±»

2. ==å®ç°evaluate()æ–¹æ³•==ï¼›evaluate()==æ”¯æŒé‡è½½ã€‚==

3. Hiveå‘½ä»¤è¡Œçª—å£æ·»åŠ åˆ›å»ºå‡½æ•°

   - æ·»åŠ jaråŒ…ï¼š`add jar jar_path`

   - åˆ›å»ºfunction

     ```shell
     create [temporary] function [dbname.]function_name as 'class_name';
     ```

4. Hiveå‘½ä»¤çª—å£åˆ é™¤å‡½æ•°

   ```shell
   drop [temporary] function [if exists] [dbname.]function_name;
   ```

==è‡ªå®šä¹‰çš„å‡½æ•°ç±»å¿…é¡»è¦æœ‰è¿”å›å€¼ï¼ï¼è¿”å›ç±»å‹ä¸å¯ä¸ºvoidï¼ï¼å¯ä»¥è¿”å›null==



### 7.2.2ã€è‡ªå®šä¹‰UDF

1. åˆ›å»ºmavenå·¥ç¨‹å¹¶å¯¼å…¥ä¾èµ–

   ```xml
   <dependency>
       <groupId>org.apache.hive</groupId>
       <artifactId>hive-exec</artifactId>
       <version>1.2.2</version>
   </dependency>
   ```

   å¯èƒ½é‡åˆ°æŸäº›ä¾èµ–aliyunä»“åº“ä¸­æ‰¾ä¸åˆ°ï¼Œå°†mavençš„é•œåƒæ¢æˆå®˜æ–¹ä»“åº“å³å¯ã€‚
   
2. åˆ›å»ºè‡ªå®šä¹‰å‡½æ•°ç±»å¹¶ç»§æ‰¿UDFï¼Œå®ç°evaluate()æ–¹æ³•ï¼Œå‚æ•°å’Œè¿”å›å€¼è‡ªå®š

   ```java
   package com.sakura.hive;
   
   import org.apache.hadoop.hive.ql.exec.UDF;
   public class MultiplyFive extends UDF {
   
       public int evaluate(int input) {
           return input * 5;
       }
   }
   ```

3. mavenæ‰“åŒ…ï¼Œå°†jaråŒ…ä¸Šä¼ åˆ°Linuxä¸Šã€‚ï¼ˆä¸ºäº†æ–¹ä¾¿ç®¡ç†ï¼Œæˆ‘ä»¬å°†å…¶åŠ å…¥åˆ°/opt/module/dataç›®å½•ä¸­ï¼Œä½ç½®è‡ªå®šåªæ˜¯åœ¨åç»­åˆ›å»ºå‡½æ•°éœ€è¦ä½¿ç”¨jaråŒ…çš„è·¯å¾„ã€‚**ä¹Ÿå¯ä»¥ç›´æ¥æ”¾åˆ°hiveçš„libç›®å½•ä¸­ï¼Œæ— éœ€æ¯æ¬¡åˆ›å»ºå‡½æ•°çš„æ—¶å€™éƒ½add jaråŒ…**ï¼‰

4. æ·»åŠ jaråŒ…ï¼Œåˆ›å»ºå‡½æ•°

   ```shell
   # æ·»åŠ jaråŒ…
   add jar /opt/module/data/hive-1.0.jar
   
   # åˆ›å»ºå‡½æ•°
   create function multiplyfive as 'com.sakura.MultiplyFive';
   ```

5. æµ‹è¯•å‡½æ•°

   ```shell
   hive (default)> select multiplyfive(13);
   OK
   _c0
   65
   ```

   **åœ¨å½“å‰åº“åˆ›å»ºçš„å‡½æ•°åªèƒ½åœ¨å½“å‰åº“ä¸­ä½¿ç”¨ï¼Œä¸å¯ä»¥è·¨åº“ä½¿ç”¨**

6. åˆ é™¤å‡½æ•°

   ```shell
   drop function if exists multiplyfive;
   ```

   

### 7.2.3ã€è‡ªå®šä¹‰UDTFå‡½æ•°å…·ä½“æ­¥éª¤

æ­¥éª¤ç›¸å¯¹äºUDFè¦å¤æ‚ï¼Œä½†æ˜¯ä¹Ÿæœ‰å›ºå®šçš„å¥—è·¯ã€‚

1. ç»§æ‰¿GenericUDTFç±»(æŠ½è±¡ç±»)
2. é‡å†™`initialize`,`process`,`close`æ–¹æ³•ï¼Œåä¸¤è€…æ˜¯å¼ºåˆ¶è¦æ±‚é‡å†™ã€‚å„è‡ªä½œç”¨åœ¨å®ç°ä¸­ç»†è¯´ã€‚
3. æ‰“åŒ…ä¸Šä¼ ï¼Œåˆ›å»ºå‡½æ•°ã€‚



### 7.2.4ã€è‡ªå®šä¹‰UDTFå‡½æ•°

> initialize()ï¼šStructObjectInspector

**æŠ½è±¡ç±»GenericUDTFå¹¶æ²¡æœ‰å¼ºåˆ¶è¦æ±‚é‡å†™æ­¤æ–¹æ³•ï¼Œä¸ºä½•è¦æ‰‹åŠ¨æ·»åŠ é‡å†™ï¼Ÿ**

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200720112149.png" alt="image-20200720112149187" style="zoom: 50%;" />

**æ€ä¹ˆå†™ï¼Ÿ**

å‚è€ƒå·²æœ‰å®ç°ç±»ï¼šGenericUDTFJSONTupleä¸­çš„initialize()æ–¹æ³•ï¼Œåœ¨returnè¯­å¥ä¸Šåšæ–‡ç« 

```java
return ObjectInspectorFactory.getStandardStructObjectInspector(fieldNames, fieldOIs);
```

ä»ç±»æœ€åéƒ¨åˆ†çš„å†™æ³•ä¸­å¯ä»¥çŸ¥é“`fieldNames`å’Œ`fieldOIs`æ˜¯ä¸¤ä¸ªListï¼Œå¹¶ä¸”ä¸¤è€…å…·æœ‰ä¸€å®šçš„å…³è”å…³ç³»ï¼Œå¹¶ä¸”å’Œå­—æ®µ(åˆ—)æ¯æ¯ç›¸å…³ã€‚
<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200720112741.png" alt="image-20200720112741134" style="zoom:50%;" />

æˆ‘ä»¬æ‰€å†™çš„æ˜¯UDTF(å³ä¸€è¿›å¤šå‡º)ï¼Œå³å¯¹ä¸€è¡Œçš„æŸåˆ—æ•°æ®è¿›è¡Œè§£æå¾—åˆ°å¤šä¸ªæ•°æ®ã€‚åœ¨ä½¿ç”¨`exploded()`çš„æ—¶å€™ï¼Œè§£æå‡ºæ¥çš„æ•°æ®éƒ½æ˜¯åœ¨ä¸€åˆ—ä¸­ã€‚
è€Œæˆ‘ä»¬è‡ªå®šä¹‰UDTFçš„æ—¶å€™å‘ç°çš„fieldNameså±…ç„¶æ˜¯ä¸€ä¸ªListï¼Œé‚£ä¹ˆè¯´æ˜æˆ‘ä»¬å¯ä»¥é€‰æ‹©==å°†æ•°æ®è§£ææˆå¤šä¸ªåˆ—å¤šä¸ªè¡Œçš„æ•°æ®ã€‚==
==fieldOIså…¶å®å°±æ˜¯å¯¹åº”fieldNamesä¸­æ¯ä¸ªå­—æ®µçš„ç±»å‹éªŒè¯ã€‚==åªä¸è¿‡è¿™é‡Œçš„ç±»å‹å¹¶ä¸æ˜¯Javaä¸­çš„æ•°æ®ç±»å‹ã€‚è¿™äº›æ•°æ®ç±»å‹éƒ½è¦é€šè¿‡`PrimitiveObjectInspectorFactory`ç±»æ¥è·å–ã€‚

ä¾‹å¦‚ï¼š`PrimitiveObjectInspectorFactory.javaStringObjectInspector`å°±ç›¸å½“äºJavaä¸­çš„Stringç±»ï¼Œä¹Ÿæœ€å¸¸ç”¨ã€‚



> process()ï¼švoid

Hiveä¸­ä½¿ç”¨æ­¤å‡½æ•°çš„æ—¶å€™ï¼Œé’ˆå¯¹æ¯ä¸€è¡Œæ•°æ®è°ƒç”¨ä¸€ä¸ªprocess()ã€‚å³æ¯è§£æä¸€è¡Œæ•°æ®å°±è¦è°ƒç”¨ä¸€æ¬¡ã€‚è´Ÿè´£ä¸»è¦çš„åŠŸèƒ½é€»è¾‘ã€‚

å‚æ•°æ˜¯é€šè¿‡å‡½æ•°è°ƒç”¨æ—¶çš„å‚æ•°ä¼ å…¥çš„ã€‚æ‰€ä»¥æ˜¯ä¸€ä¸ªObject[];
åŠŸèƒ½å®ç°ç”±ä¸šåŠ¡è€Œå®šä¸å¿…å¤šè¯´ã€‚

å…³é”®åœ¨äºå¤„ç†åçš„æ•°æ®çš„è¾“å‡ºï¼åœ¨åˆå§‹åŒ–çš„æ—¶å€™æˆ‘ä»¬å°±å®šä¸‹äº†æˆ‘ä»¬è¾“å‡ºæ•°æ®çš„å­—æ®µåå’Œç±»å‹æ ¡éªŒã€‚é‚£ä¹ˆæˆ‘ä»¬è¾“å‡ºæ•°æ®ä¹Ÿè¦æŒ‰ç…§è§„åˆ™ä½¿ç”¨Listå­˜æ”¾æ•°æ®ã€‚æœ€åä½¿ç”¨`forward()`å°†listå†™å‡ºã€‚==æ¯è°ƒç”¨ä¸€æ¬¡forwardå°±å†™å‡ºä¸€è¡Œæ•°æ®==ï¼Œæƒ³è¦å¤šåˆ—å†™å‡ºåªéœ€è¦åœ¨å†™å‡ºçš„listä¸­å¤šæ”¾æ•°æ®å³å¯ï¼Œä½†æ˜¯è¦äºåˆå§‹åŒ–ä¸­å­—æ®µæ•°é‡ä¸€è‡´ï¼ï¼



> close()

èµ„æºå…³é—­å’Œé‡Šæ”¾ç­‰æ“ä½œã€‚



**å®æ“æ¡ˆä¾‹ï¼šåå­—åˆ‡åˆ†**

```markdown
# ç¤ºä¾‹æ•°æ®
FranzÂ·Kafka
IsaacÂ·Newton
MichelangeloÂ·Buonarroti
ErwinÂ·SchrÃ¶dinger
AlbertÂ·Einstein
NikolaÂ·Tesla
ClaudeÂ·Monet
WilliamÂ·Shakespeare
# è¦æ±‚å°†åå­—æ‹†åˆ†ä¸ºfirstNameå’ŒlastNameåˆ†å¼€æ˜¾ç¤º
```



**NameExplodeç±»**

```java
public class NameExplode extends GenericUDTF {

    private List<Object> outputData = new ArrayList<>();

    @Override
    public StructObjectInspector initialize(StructObjectInspector argOIs) throws UDFArgumentException {


        List<String> fieldNames = new ArrayList<>();
        fieldNames.add("firstName");
        fieldNames.add("lastName");

        List<ObjectInspector> fieldOIs = new ArrayList<>();
        fieldOIs.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);
        fieldOIs.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);


        return ObjectInspectorFactory.getStandardStructObjectInspector(fieldNames, fieldOIs);
    }

    @Override
    public void process(Object[] args) throws HiveException {
        String fullName = args[0].toString();
        String separator = args[1].toString();
        String[] splitName = fullName.split(separator);

        outputData.clear();
        for (String split : splitName) {
            outputData.add(split);
        }
        forward(outputData);
    }

    @Override
    public void close() throws HiveException {
    }
}
```



æ‰“åŒ…æµ‹è¯•

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200720153046.png" alt="image-20200720153045837" style="zoom:67%;" />



# å…«ã€å‹ç¼©å’Œå­˜å‚¨

## 8.1ã€æ•°æ®å‹ç¼©

ä¸€èˆ¬è¦æ±‚ç¼–è¯‘Hadoopï¼Œä¹Ÿå¯ä»¥å°†ç¼–è¯‘è¿‡çš„Hadoopçš„nativeä¸­çš„æ–‡ä»¶ç›´æ¥æ‹·è´ä¸€ä»½å°±å¯ä»¥ã€‚ç„¶åé‡å¯Hadoopï¼Œä½¿ç”¨`hadoop checknative`æ¥çœ‹å‹ç¼©æ”¯æŒçš„æƒ…å†µï¼Œæˆ‘çš„Hadoopä¹‹å‰ç¼–è¯‘è¿‡ï¼Œè«åå¥‡å¦™å°±æ”¯æŒäº†snappyå‹ç¼©ã€‚

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200720161845.png" alt="image-20200720161845057" style="zoom: 67%;" />



> ç›¸å…³çš„å‚æ•°çš„è®¾ç½®(Hiveå‘½ä»¤è¡Œè®¾ç½®ï¼Œä¸´æ—¶ç”Ÿæ•ˆ)

- `set hive.exec.compress.output=true`:å¼€å¯Hiveæœ€ç»ˆè¾“å‡ºæ•°æ®çš„å‹ç¼©åŠŸèƒ½ã€‚
- `set mapreduce.output.fileoutputformat.compress=true`:å¼€å¯mapreduceæœ€ç»ˆè¾“å‡ºæ•°æ®å‹ç¼©
- `set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.SnappyCodec`:è®¾ç½®mapreduceè¾“å‡ºæ•°æ®å‹ç¼©ç¼–ç å™¨ä¸ºSnappyã€‚
- `set mapreduce.output.fileoutputformat.compress.type=BLOCK`ï¼šè®¾ç½®å‹ç¼©æ–¹å¼ä¸ºå—å‹ç¼©ï¼ˆBLOCKï¼‰,é»˜è®¤ä¸ºè¡Œå‹ç¼©(RECORD)



> æµ‹è¯•å‹ç¼©è¾“å‡º

ä½¿ç”¨insertå¯¼å‡ºæŸ¥è¯¢ç»“æœï¼š

```sql
insert overwrite local directory '/opt/module/data/masters' select * from bbb;
```

å¾—åˆ°snappyå‹ç¼©æ–‡ä»¶ï¼š

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200720163038.png" alt="image-20200720163038154" style="zoom:67%;" />



## 8.2ã€æ–‡ä»¶å­˜å‚¨

>  Hiveæ”¯æŒçš„å­˜å‚¨æ•°æ®æ ¼å¼

- TEXTFILE	ï¼ˆæ–‡æœ¬æ–‡ä»¶ï¼‰
- SEQUENCEFILEï¼ˆåºåˆ—åŒ–æ–‡ä»¶ï¼‰
- **ORC(ä½¿ç”¨æœ€å¤š)**
- PARQUETï¼ˆSparkä¸­é»˜è®¤ä½¿ç”¨ï¼‰ 

**å»ºè¡¨æ—¶ä½¿ç”¨`stored as xxx`æŒ‡å®šæ•°æ®æ–‡ä»¶çš„å­˜å‚¨æ ¼å¼**



### 8.2.1ã€è¡Œå­˜å‚¨å’Œåˆ—å­˜å‚¨

æ­¤å¤„è¯´çš„è¡Œå­˜å‚¨å’Œåˆ—å­˜å‚¨ï¼Œåœ¨æ–‡ä»¶ä¸­éƒ½æ˜¯è¡Œæ¨¡å¼å†™å…¥ï¼Œåªæ˜¯å†™å…¥çš„é¡ºåºæœ‰æ‰€ä¸åŒã€‚

**è¡Œå­˜å‚¨ï¼š**è¡¨ä¸­æ•°æ®å­˜å…¥æ–‡ä»¶æ—¶ï¼Œæ˜¯==ä»¥æ•°æ®è®°å½•çš„é¡ºåºå­˜å‚¨çš„ã€‚==ä¸€æ¡è®°å½•ç´§æ¥ç€ä¸€æ¡è®°å½•ã€‚

**åˆ—å­˜å‚¨ï¼š**å­˜æ•°æ®æ—¶ï¼Œ==æŒ‰ç…§åˆ—çš„é¡ºåºå­˜å‚¨==ï¼Œä¸€åˆ—ï¼ˆå­—æ®µï¼‰æ‰€æœ‰æ•°æ®ç´§æ”¾åœ¨ä¸€èµ·ï¼Œå­˜å®Œåç„¶åå­˜ä¸‹ä¸€ä¸ªåˆ—çš„æ‰€æœ‰æ•°æ®ã€‚

![img](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200721192335.png)

> å„è‡ªçš„ä½¿ç”¨åœºæ™¯ï¼š

- è¡Œå­˜å‚¨

  å½“==æŸ¥è¯¢çš„å­—æ®µå¾ˆå¤šï¼Œä¸”ä¸ç¨³å®šæ—¶ æˆ–è€… æŒ‰æ¡ä»¶ç­›é€‰æŸ¥è¯¢æ—¶==ï¼Œä½¿ç”¨è¡Œå­˜å‚¨æ›´åŠ é«˜æ•ˆï¼Œç”±äºåŒä¸€è¡Œè®°å½•çš„æ•°æ®éƒ½åœ¨â€œé™„è¿‘â€ï¼Œå–æ•°æ®çš„é€Ÿåº¦è¦æ¯”ä½¿ç”¨åˆ—å­˜å‚¨å¿«ã€‚

- åˆ—å­˜å‚¨

  å½“==æŸ¥è¯¢çš„å­—æ®µè¾ƒå°‘ï¼Œä¸”ç¨³å®šæ—¶==ï¼Œä½¿ç”¨åˆ—å­˜å‚¨å¯ä»¥å¿«é€Ÿå–åˆ°æœ¬åˆ—æ‰€æœ‰çš„æ•°æ®ï¼Œæ•ˆç‡æ›´é«˜ã€‚



**TEXTFILEå’ŒSEQUENCEFILE é‡‡ç”¨è¡Œå­˜å‚¨**

**ORCå’ŒPARQUET é‡‡ç”¨åˆ—å­˜å‚¨**



### 8.2.2ã€å­˜å‚¨æ•°æ®æ ¼å¼

> TextFileæ ¼å¼

é»˜è®¤çš„æ ¼å¼ï¼Œæ•°æ®ä¸åšå‹ç¼©ï¼Œç£ç›˜å¼€é”€è¾ƒå¤§ï¼Œæ•°æ®è§£æå¼€é”€å¤§



> ORCï¼ˆOptimized Row Columnarï¼‰æ ¼å¼
>
> å‚è€ƒé˜…è¯»åšå®¢:https://www.cnblogs.com/ITtangtang/p/7677912.html

ORCå…·æœ‰ä»¥ä¸‹ä¸€äº›ä¼˜åŠ¿:

1. ORCæ˜¯åˆ—å¼å­˜å‚¨ï¼Œæœ‰å¤šç§æ–‡ä»¶å‹ç¼©æ–¹å¼ï¼Œå¹¶ä¸”æœ‰ç€å¾ˆ**é«˜çš„å‹ç¼©æ¯”ã€‚**ï¼ˆORC > Parquteï¼‰
2. **æ–‡ä»¶æ˜¯å¯åˆ‡åˆ†ï¼ˆSplitï¼‰çš„**ã€‚å› æ­¤ï¼Œåœ¨Hiveä¸­ä½¿ç”¨ORCä½œä¸ºè¡¨çš„æ–‡ä»¶å­˜å‚¨æ ¼å¼ï¼Œä¸ä»…èŠ‚çœHDFSå­˜å‚¨èµ„æºï¼ŒæŸ¥è¯¢ä»»åŠ¡çš„è¾“å…¥æ•°æ®é‡å‡å°‘ï¼Œä½¿ç”¨çš„MapTaskä¹Ÿå°±å‡å°‘äº†ã€‚
3. **æä¾›äº†å¤šç§ç´¢å¼•**ï¼Œrow group indexã€bloom filter indexã€‚
4. ORCå¯ä»¥**æ”¯æŒå¤æ‚çš„æ•°æ®ç»“æ„**ï¼ˆæ¯”å¦‚Mapç­‰ï¼‰

æ–‡ä»¶ç»“æ„ç¤ºæ„å›¾ï¼š

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200721192946.jpeg" alt="img" style="zoom:67%;" />

ORCæ–‡ä»¶ä¸­é€šå¸¸ç”±å¤šä¸ªstripeç»„æˆï¼Œ==é»˜è®¤æ¯1Wæ¡æ•°æ®åˆ›å»ºä¸€ä¸ªç´¢å¼•(IndexData)ï¼Œåˆ—æ•°æ®å­˜æ”¾åœ¨RowDataä¸­ï¼Œç„¶ååŠ ä¸Šstripeçš„ç›¸å…³å…ƒæ•°æ®æ„æˆä¸€ä¸ªstripe==ã€‚å¹¶ä¸æ˜¯æˆ‘ä»¬æƒ³è±¡ä¸­çš„ä¸€ä¸ªåˆ—å®Œå…¨å­˜æ”¾å®Œå†å­˜æ”¾ä¸‹ä¸€ä¸ªåˆ—ï¼Œè¿™æ ·çš„åšæ³•åœ¨æ£€ç´¢æ•°æ®æ—¶æ•ˆç‡ä½ä¸‹ã€‚è€Œä½¿ç”¨stripeåˆ†å—ï¼ˆè¡Œç»„ï¼‰å­˜å‚¨å•ç‹¬å»ºç«‹ç´¢å¼•ï¼Œæ£€ç´¢æ•°æ®è¦æ›´å¿«ã€‚

**ORCå­˜å‚¨æ ¼å¼è‡ªå¸¦äº†å‹ç¼©ï¼Œé‡‡ç”¨Zlibå‹ç¼©**ï¼Œæ‰€ä»¥ORCçš„å‹ç¼©æ¯”æ¯”è¾ƒå‡ºè‰²ï¼

åœ¨å»ºè¡¨è¯­å¥ä¸­`stored by orc` åæ¥`tblproperties("orc.compress"="xxx")`æ¥ä¿®æ”¹ORCå­˜å‚¨æ—¶å‹ç¼©æ–¹å¼ã€‚ä¾‹å¦‚ï¼šSNAPPYï¼ŒNONE..



> Parquetæ ¼å¼ï¼ˆæ‰©å±•å­¦ä¹ ï¼‰
>
> å‚è€ƒé˜…è¯»åšå®¢ï¼šhttps://blog.csdn.net/yu616568/article/details/50993491

ä¸ORCä¸€æ ·åŒä¸ºåˆ—å­˜å‚¨ï¼Œåœ¨å­˜å‚¨Parquetæ•°æ®çš„æ—¶å€™ä¼šæŒ‰ç…§Blockå¤§å°è®¾ç½®è¡Œç»„çš„å¤§å°ï¼Œç”±äºä¸€èˆ¬æƒ…å†µä¸‹æ¯ä¸€ä¸ªMapperä»»åŠ¡å¤„ç†æ•°æ®çš„æœ€å°å•ä½æ˜¯ä¸€ä¸ªBlockï¼Œè¿™æ ·å¯ä»¥æŠŠæ¯ä¸€ä¸ªè¡Œç»„ç”±ä¸€ä¸ªMapperä»»åŠ¡å¤„ç†ï¼Œå¢å¤§ä»»åŠ¡æ‰§è¡Œå¹¶è¡Œåº¦ã€‚

<img src="https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200721194359.png" alt="Parquetæ–‡ä»¶æ ¼å¼"  />





# ä¹ã€è°ƒä¼˜

## 9.1ã€FetchæŠ“å–

ç®€å•è¯´å°±æ˜¯**Hiveä¸­å¯¹æŸäº›ç‰¹å®šçš„æŸ¥è¯¢æƒ…å†µï¼ˆä¾‹å¦‚ï¼šselect * ..ï¼‰æ˜¯ä¸ä½¿ç”¨MRè®¡ç®—çš„**ï¼Œè¿™æ ·å¯ä»¥å¤§å¤§æé«˜æŸ¥è¯¢çš„é€Ÿåº¦ã€‚

ä½¿ç”¨Select *,Hiveå¯ä»¥ç›´æ¥å»æ•°æ®æ–‡ä»¶ä¸­æŠ“å–æ•°æ®è¾“å‡ºåˆ°æ§åˆ¶å°å°±è¡Œäº†ï¼Œæ— é¡»ä½¿ç”¨MapReduceä»»åŠ¡ã€‚

åœ¨æ—§ç‰ˆæœ¬ä¸­ï¼Œæœ‰ä¸€é¡¹å‚æ•°éœ€è¦è®¾ç½®æ‰èƒ½è¾¾åˆ°è¿™ç§æ•ˆæœã€‚å½“å‰ç‰ˆæœ¬ï¼ˆ1.2.2ï¼‰é»˜è®¤å·²é€‰æ‹©æœ€ä¼˜é…ç½®ã€‚

`hive.fetch.task.conversion`ï¼Œåœ¨hive-default.xml.templateä¸­å¯ä»¥æŸ¥çœ‹å½“å‰é…ç½®ä¸º`more`å³æœ€ä¼˜çš„é…ç½®ï¼Œå¯é€‰çš„é…ç½®æœ‰`none`,`minimal`(æ—§ç‰ˆæœ¬é»˜è®¤)

```xml
<property>
    <name>hive.fetch.task.conversion</name>
    <value>more</value>
    <description>
        Expects one of [none, minimal, more].
        Some select queries can be converted to single FETCH task minimizing latency.
        Currently the query should be single sourced not having any subquery and should not have
        any aggregations or distincts (which incurs RS), lateral views and joins.
        0. none : disable hive.fetch.task.conversion
        1. minimal : SELECT STAR, FILTER on partition columns, LIMIT only
        2. more    : SELECT, FILTER, LIMIT only (support TABLESAMPLE and virtual columns)
    </description>
</property>
```

- ä½¿ç”¨`none`æ—¶ï¼Œæ‰€æœ‰çš„æŸ¥è¯¢è¯­å¥éƒ½è¦èµ°MRä»»åŠ¡ã€‚

- ä½¿ç”¨`minimal`æ—¶ï¼Œselect *ï¼Œå¯¹åˆ†åŒº(partition)å­—æ®µç­›é€‰ï¼ŒlitmitæŸ¥è¯¢ä¸ä½¿ç”¨MRã€‚

- ä½¿ç”¨`more`æ—¶ï¼Œæ‰€æœ‰çš„æ™®é€šselectï¼ˆä¸æ¶‰åŠå‡½æ•°è®¡ç®—ï¼‰ï¼Œä»¥åŠæ™®é€šwhereå­—æ®µç­›é€‰ï¼ŒlimitæŸ¥è¯¢ï¼Œä¸ä½¿ç”¨MRã€‚

  ```sql
  -- è®¾ç½®ä¸ºmoreæ—¶ï¼Œä»¥ä¸‹æŸ¥è¯¢éƒ½ä¸ä¼šä½¿ç”¨MR
  select * from aaa;
  select name,age from aaa where id=3;
  select name,age+2 from aaa where id<4;
  select name from aaa limit 4;
  ```



## 9.2ã€æœ¬åœ°æ¨¡å¼

åœ¨åšæ¡ˆä¾‹ç»ƒä¹ æ—¶ï¼Œä½¿ç”¨`set hive.exec.mode.local.auto=true;`ä¸´æ—¶å¼€å¯æœ¬åœ°æ¨¡å¼ï¼Œå°†MRä»»åŠ¡æäº¤ç»™æœ¬åœ°Hadoopè€Œä¸æ˜¯é›†ç¾¤çš„Yarnä¸Šæ‰§è¡Œï¼Œé€Ÿåº¦è¦å¿«å¾ˆå¤šã€‚ä½†æ˜¯==å¹¶ä¸æ˜¯å¼€å¯äº†æœ¬åœ°æ¨¡å¼å°±ä¸€å®šä¼šèµ°æœ¬åœ°çš„Hadoop==å“¦ï¼Œè¿˜éœ€è¦æ»¡è¶³ä»¥ä¸‹ä¸¤ä¸ªæ¡ä»¶ï¼š

- è¾“å…¥çš„æ•°æ®é‡è¦å°äº`hive.exec.mode.local.auto.inputbytes.max`(é»˜è®¤æ˜¯134217728=**128M**)

- è¾“å…¥çš„æ–‡ä»¶æ•°é‡è¦å°äº`hive.exec.mode.local.auto.input.files.max`(é»˜è®¤æ˜¯4)

  ```markdown
  # å½“Hadoopä¸­è¡¨æ–‡ä»¶æ•°é‡å¤§äº4æ—¶ï¼š
  Cannot run job locally: Number of Input Files (= 5) is larger than hive.exec.mode.local.auto.input.files.max(= 4)
  ```

ä»¥ä¸Šä¸¤ä¸ªå‚æ•°å‡å¯ä»¥è‡ªè¡Œè°ƒæ•´ã€‚





## 9.3ã€è¡¨çš„ä¼˜åŒ–

### 9.3.1ã€å¤§å°è¡¨Join

åœ¨æŸ¥è¯¢ä¸­ï¼Œä½¿ç”¨JoinæŸ¥è¯¢çš„æ—¶å€™ä¼šå¯¹è¡¨è¿›è¡Œæ‰«æï¼Œä½†æ˜¯æ— æ„ä¹‰åå¤å¤šæ¬¡çš„æ‰«æåˆæ˜¯æµªè´¹æ—¶é—´å’Œæ¶ˆè€—èµ„æºçš„ï¼Œåœ¨MapReduceå­¦ä¹ ä¸­**MapJoinå°†å°è¡¨ç¼“å­˜åˆ°äº†å†…å­˜ä¸­**ï¼Œä»¥åŠ å¿«æ‰«æç­›é€‰çš„é€Ÿåº¦ã€‚é€šå¸¸å°è¡¨åœ¨å·¦ï¼Œå¤§è¡¨åœ¨å³ã€‚==Hiveåœ¨æ–°ç‰ˆä¸­å·²ç»é»˜è®¤å¯¹æ­¤è¿›è¡Œä¼˜åŒ–ï¼Œä¸éœ€è¦å†å…³å¿ƒè¡¨çš„ä½ç½®ã€‚==æ‰€ä»¥ç°åœ¨å¤§å°è¡¨å³ä½¿äº¤æ¢ä½ç½®ä¹Ÿä¸ä¼šæœ‰å¾ˆå¤šå·®è·ã€‚



### 9.3.2ã€å¤§è¡¨Join

> ç©ºå€¼ã€æ•°æ®è¿‡æ»¤

åœ¨å¤§è¡¨ä¹‹é—´çš„Joinè¿‡ç¨‹ä¸­ï¼Œæ¯å¤šä¸€æ¡æ— æ„ä¹‰çš„æ•°æ®å°±ä¼šå¤šä¸€æ¬¡æ— æ„ä¹‰çš„å…¨è¡¨æ‰«æã€‚æ‰€ä»¥ä¸ºäº†å‡å°‘è¿™ç§æ— è°“çš„æ‰«æï¼Œæˆ‘ä»¬å¯ä»¥**åœ¨Joinä¹‹å‰å°±å¯¹è¡¨å…ˆè¿›è¡Œè¿‡æ»¤**ã€‚å°†ç©ºå€¼ã€ä¸ç¬¦åˆæ¡ä»¶çš„å€¼è¿‡æ»¤æ‰ï¼Œå‡å°æ•°æ®é›†æé«˜æŸ¥è¯¢æ•ˆç‡ã€‚



> ç©ºKeyæ›¿æ¢

åœ¨æŸ¥è¯¢è¿‡ç¨‹ä¸­ä¹Ÿä¸å¯ä»¥ç›²ç›®å°†ç©ºkeyç›´æ¥è¿‡æ»¤ï¼Œå¯èƒ½å…¶ä»–æ•°æ®å¯¹æŸ¥è¯¢è¿˜æœ‰ä½œç”¨ï¼Œä½†æ˜¯å¦‚æœä¸åŠ ä»¥å¤„ç†ï¼Œä¸€æ—¦ç©ºkeyçš„æ•°é‡å¾ˆå¤§æ—¶ï¼Œè¿™äº›æ‰€æœ‰çš„ç©ºkeyè®°å½•å°±ä¼šåˆ†é…åˆ°åŒä¸€ä¸ªReducerä¸­å»å¤„ç†ï¼Œè¿™æ ·å°±å¯¼è‡´**æ•°æ®å€¾æ–œ**ï¼Œåœ¨ä¼ä¸šä¸šåŠ¡å¼€å‘ä¸­æ˜¯è‡´å‘½çš„ï¼
æ‰€ä»¥åœ¨==é‡åˆ°ç©ºKeyè¦åˆç†æ›¿æ¢ä¸ºå¯å‡åŒ€åˆ†å¸ƒçš„key(ä¾‹å¦‚ä½¿ç”¨éšæœºæ•°)ï¼Œè®©è¿™äº›ç©ºkeyè®°å½•åœ¨è®¡ç®—å¤„ç†æ—¶ï¼Œå°½é‡æ‘Šåˆ†åˆ°å„ä¸ªReducerä¸Šä»¥é¿å…æ•°æ®å€¾æ–œçš„é—®é¢˜ã€‚==å¯¹ç©ºkeyçš„æ›¿æ¢ä¼šä½¿æ•´ä¸ªMapReduceçš„æ—¶é—´å˜é•¿ï¼Œä½†æ˜¯ä¸ºäº†ç¨³å®šæ€§æ˜¯å€¼å¾—çš„ã€‚



### 9.3.3ã€MapJoin

ç›¸å…³å‚æ•°ï¼š

- `hive.auto.convert.join=true`ï¼Œé»˜è®¤å¼€å¯MapJoin
- `hive.mapjoin.smalltable.filesize=25000000`(25M),å¤§å°è¡¨çš„é˜ˆå€¼ï¼Œä»¥æ–‡ä»¶å¤§å°25Mä¸ºåˆ†ç•Œç‚¹

å¼€å¯MapJoinåï¼Œåœ¨Mapé˜¶æ®µå¯¹å°è¡¨è¿›ç¼“å­˜ï¼Œå¤§è¡¨æ‰«æï¼Œé¿å…è¿›å…¥Reduceé˜¶æ®µå¤„ç†ï¼Œå®¹æ˜“å‘ç”Ÿæ•°æ®å€¾æ–œã€‚



### 9.3.4ã€Group By

é»˜è®¤æƒ…å†µä¸‹MRç¨‹åºä¸­ï¼ŒMapé˜¶æ®µè¾“å‡ºæ•°æ®ä¸­ç›¸åŒçš„Keyéƒ½ä¼šæ±‡æ€»åˆ°ä¸€ä¸ªReducerä¸­å»å¤„ç†ï¼Œç„¶è€Œä¸€æ—¦æŸä¸ª(äº›)keyçš„æ•°é‡è¾ƒå¤§çš„æ—¶å€™ï¼Œå°±ä¼šå‘ç”ŸReduceç«¯çš„æ•°æ®å€¾æ–œã€‚
Hadoopä¸­æˆ‘ä»¬å¯ä»¥è®©Mapé˜¶æ®µè¿›è¡Œä¸€æ¬¡å±€éƒ¨æ±‡æ€»ï¼ˆCombineï¼‰,ç„¶åå†å°†æ±‡æ€»åç»“æœç»™Reduceå¤„ç†ã€‚
æ‰€ä»¥ï¼Œ==å¹¶ä¸æ˜¯æ‰€æœ‰çš„èšåˆæ“ä½œéƒ½è¦æ”¾åˆ°Reduceä¸­å®Œæˆï¼Œä¹Ÿå¯ä»¥æå‰åœ¨Mapä¸­è¿›è¡Œéƒ¨åˆ†èšé›†ï¼Œä»¥å‡è½»Reduceçš„å‹åŠ›ã€‚==

> å¼€å¯Mapç«¯èšåˆçš„å‚æ•°è®¾ç½®

- `hive.map.aggr=true`ï¼šæ˜¯å¦å¼€å¯Mapç«¯èšåˆï¼Œé»˜è®¤å¼€å¯ï¼ˆtrueï¼‰

- `hive,groupby.mapaggr,checkinterval=100000`ï¼šæ¯æ¬¡èšåˆçš„æ•°æ®æ•°

- `hive.groupby.skewindata=true`ï¼šå½“æ•°æ®äº§ç”Ÿå€¾æ–œçš„æ—¶å€™é‡‡ç”¨è´Ÿè½½å‡è¡¡ï¼ˆ**é»˜è®¤å…³é—­false**ï¼‰

  å½“æ­¤å‚æ•°é…ç½®ä¸ºtrueæ—¶ï¼Œå½“ä¸€ä¸ªReduceå¤„ç†çš„æ•°æ®é‡å¾ˆå¤§äº§ç”Ÿäº†æ•°æ®å€¾æ–œçš„æ—¶å€™ï¼Œ**æ‰§è¡ŒæŸ¥è¯¢ä¼šæœ‰ä¸¤ä¸ªMRä»»åŠ¡ã€‚**

  ç¬¬ä¸€ä¸ªMRä»»åŠ¡ä¸­Mapé˜¶æ®µMapperå‡åŒ€è¯»å–åˆ†ç‰‡æ•°æ®ï¼Œ**éšæœºè¿›è¡Œåˆ†åŒº**ï¼Œéšæœºåˆ†åŒºä¸­çš„æ•°æ®ç”±Reduceè¿›è¡Œä¸€æ¬¡æ±‡æ€»ï¼Œæ­¤æ—¶æ•°æ®ä»¥åŠç»å†äº†ä¸€éç®€å•çš„æ±‡æ€»ã€‚ç”±äºç¬¬ä¸€æ¬¡æ˜¯éšæœºåˆ†åŒºå¹¶æ²¡æœ‰æŒ‰ç…§GroupByçš„keyå€¼è¿›è¡Œåˆ†åŒºï¼Œæ‰€ä»¥å°±ä¼šå‡ºç°ç›¸åŒçš„keyåœ¨ç¬¬ä¸€æ¬¡MRä¸­åœ¨ä¸åŒçš„Reduceä¸­å¤„ç†ã€‚
  ç¬¬äºŒä¸ªMRä»»åŠ¡ï¼Œåˆ©ç”¨å·²ç»æ±‡æ€»å¤„ç†è¿‡çš„æ•°æ®å†æŒ‰ç…§GroupBy Keyè¿›è¡Œåˆ†åŒºï¼Œ ç»è¿‡å¤šæ¬¡èšåˆåï¼Œæ•°æ®é‡å¤§å¤§å‡å°ï¼Œæ•°æ®å€¾æ–œçš„å¯èƒ½æ€§ä¹Ÿå°±éšä¹‹é™ä½ã€‚

  ==æ³¨æ„ï¼šåªèƒ½å¯¹å•ä¸ªå­—æ®µèšåˆã€‚ä¸æ”¯æŒå¤šä¸ªå­—æ®µçš„GroupBy==



### 9.3.5ã€å»é‡ç»Ÿè®¡Count(distinct())

ä½¿ç”¨Count(distinct)å»é‡ç»Ÿè®¡åˆ—ä¸­å€¼çš„æ•°é‡ã€‚ä½¿ç”¨GroupByä¹Ÿèƒ½è¾¾åˆ°ç›¸åŒæ•ˆæœã€‚

> count(distinct())å­˜åœ¨çš„é—®é¢˜

ä¸€æ—¦ç»Ÿè®¡çš„åˆ—çš„æ•°æ®é‡å·¨å¤§ï¼Œåœ¨å¯åŠ¨MRä»»åŠ¡æ—¶ï¼ŒReduceè¦å¤„ç†çš„æ•°æ®å·¨å¤§ï¼Œå°±æœ‰å¯èƒ½**å¯¼è‡´MRä»»åŠ¡ä¹…ä¹…ä¸èƒ½å®Œæˆï¼Œç”šè‡³ç›´æ¥å¤±è´¥**ã€‚è¿™æ ·çš„æƒ…å†µåœ¨å¼€å‘è¿‡ç¨‹ä¸­ååˆ†å±é™©ã€‚
ä½†æ˜¯æ­£å¸¸æƒ…å†µä¸‹è¿™ç§åšæ³•ç›¸å¯¹äºä½¿ç”¨GroupBy**æ‰§è¡Œæ•ˆç‡æ›´é«˜**

> ä½¿ç”¨GroupBy

ä½¿ç”¨GroupByå®ç°ï¼Œè¿˜éœ€è¦åœ¨å¤–å±‚å¥—ä¸Šä¸€å±‚count()æŸ¥è¯¢ï¼Œä¹Ÿå°±ç›¸åº”å¤šä¸€ä¸ªJobï¼Œä½†æ˜¯æ¯”è¾ƒå®‰å…¨ï¼Œåœ¨å¤§æ•°æ®é‡çš„æƒ…å†µä¸‹ï¼Œè¿™ç§æ—¶é—´çš„ä»˜å‡ºæ˜¯å€¼å¾—çš„ã€‚



### 9.3.6ã€ç¬›å¡å°”ç§¯

<a href="#dikaerji">åœ¨å‰é¢Joinä¸­è®²åˆ°äº†ç¬›å¡å°”ç§¯äº§ç”Ÿçš„æƒ…å†µ</a>ï¼Œä¸€èˆ¬æ˜¯å°†å…¶å…³é—­ï¼Œå› ä¸ºä¸€æ—¦å‡ºç°æ„å¤–æŸ¥è¯¢ä¸­å‡ºç°äº†ç¬›å¡å°”ç§¯ï¼Œæ•°æ®é‡å¢é•¿å¿«ï¼Œå¾—åˆ°çš„æ•°æ®é‡å·¨å¤§ã€‚ä¸”è®¡ç®—**ç¬›å¡å°”ä¼šå ç”¨å¤§é‡çš„è®¡ç®—èµ„æºã€‚**



### 9.3.7ã€è¡Œè¿‡æ»¤ï¼Œåˆ—è¿‡æ»¤

**è¡Œè¿‡æ»¤ï¼š**æŸ¥è¯¢ä¸­åšåˆ°æå‰è¿›è¡Œæ•°æ®è¿‡æ»¤ï¼Œç²¾ç®€æ•°æ®é›†ï¼Œå‡å°æŸ¥è¯¢æ—¶æ‰«æè¡¨çš„æ— æ•ˆæ‰«æã€‚

**åˆ—è¿‡æ»¤ï¼š**æŸ¥è¯¢ä¸­å°½é‡å†™æ˜è¦æŸ¥è¯¢çš„å­—æ®µï¼Œå°‘ä½¿ç”¨select *ï¼Œå³ä½¿æ˜¯è¦æŸ¥è¯¢å…¨åˆ—ï¼Œä¹Ÿå°½é‡å†™åˆ—åï¼;



### 9.3.8ã€åŠ¨æ€åˆ†åŒº

åœ¨ä½¿ç”¨æ™®é€šé™æ€åˆ†åŒºçš„æ—¶å€™ï¼Œåˆ†åŒºå­—æ®µç”±æˆ‘ä»¬å•ç‹¬åˆ›å»ºä¸€ä¸ªåˆ†åŒºå­—æ®µï¼Œå¹¶ä¸”åœ¨æ’å…¥æ•°æ®çš„æ—¶å€™ï¼Œæˆ‘ä»¬è¦æŒ‡å®šæ•°æ®çš„åˆ†åŒºå­—æ®µå€¼ï¼Œä¹Ÿå°±æ˜¯è¯´æ‰€æœ‰çš„æ•°æ®åˆ†åˆ°å“ªä¸ªåŒºæœ‰æˆ‘ä»¬æ’å…¥æ•°æ®æ—¶è‡ªè¡Œå†³å®šã€‚
åŠ¨æ€åˆ†åŒºæ°å¥½ç›¸åï¼Œä½¿ç”¨åŠ¨æ€åˆ†åŒºçš„æ—¶å€™ï¼Œæˆ‘ä»¬æŒ‡å®šæ•°æ®ä¸­çš„ä¸€ä¸ªåˆ—ä½œä¸ºåˆ†åŒºå­—æ®µï¼Œè¿™ä¸ª==åˆ—çš„æ•°æ®ç§ç±»ï¼ˆå³å¯é€‰å€¼çš„æ•°é‡ï¼‰å†³å®šäº†æœ€ç»ˆåˆ†åŒºçš„æ•°é‡ã€‚å¹¶ä¸”åœ¨æ’å…¥æ•°æ®çš„æ—¶å€™ï¼Œé»˜è®¤æ£€æŸ¥å¯¹åº”å­—æ®µçš„å€¼æ¥å†³å®šæ•°æ®å½’å±åˆ°å“ªä¸ªåˆ†åŒºä¸­ã€‚==

> åŠ¨æ€åˆ†åŒºçš„ç›¸å…³å‚æ•°

- `hive.exec.dynamic.partition=true`ï¼šå¼€å¯åŠ¨æ€åˆ†åŒºçš„åŠŸèƒ½ï¼ˆé»˜è®¤å¼€å¯trueï¼‰

- `hive.exec.dynamic.parition.mode=nonstrict`ï¼šè®¾ç½®ä¸ºéä¸¥æ ¼æ¨¡å¼ï¼ˆnonstrictï¼‰,é»˜è®¤æ˜¯ä¸¥æ ¼æ¨¡å¼ï¼ˆstrictï¼‰å³æ’å…¥æ•°æ®æ—¶è¦æ˜¾å¼æŒ‡æ˜åˆ†åŒºå­—æ®µçš„å€¼ã€‚

- `hive.exec.max.dynamic.partitions=1000`ï¼šæ‰€æœ‰MRèŠ‚ç‚¹ä¸€å…±å¯åˆ›å»ºçš„åˆ†åŒºæ•°é‡ï¼ˆé»˜è®¤1000ï¼‰

- `hive.exec.max.dynamic.partition.pernode=100`ï¼šæ¯ä¸ªMRèŠ‚ç‚¹å¯åˆ›å»ºçš„åˆ†åŒºæ•°é‡ï¼ˆé»˜è®¤100ï¼‰

  ä¸€æ—¦å®é™…åˆ†åŒºçš„æ•°é‡è¶…è¿‡æ€»åˆ†åŒºæ•°é‡çš„é™åˆ¶ï¼Œåˆ™ä¼šäº§ç”Ÿé—®é¢˜ï¼Œæ³¨æ„è®¾ç½®ã€‚

- `hive.error.on.empty.partition=false`ï¼šäº§ç”Ÿç©ºåˆ†åŒºæ—¶æ˜¯å¦æŠ›å‡ºå¼‚å¸¸ï¼ˆé»˜è®¤ä¸å¼€å¯falseï¼‰



> å…·ä½“æ“ä½œæ³¨æ„

åˆ›å»ºè¡¨æ—¶ï¼Œåˆ†åŒºçš„å­—æ®µä¸å¿…å†™åœ¨åŸºæœ¬å­—æ®µåˆ—è¡¨ä¸­ï¼Œç›´æ¥ä½¿ç”¨`partitioned by (col_name)`å³å¯ã€‚æ­¤åæ’å…¥æ•°æ®å°±ä¼šè‡ªåŠ¨æ£€æµ‹åˆ†åŒºã€‚ä¸‹é¢æ¥å®æ“æ¼”ç¤ºä¸€ä¸‹ï¼š

å»ºè¡¨ï¼š

```sql
create table dynamic_partition(name string,age int)
partitioned by (grade string)
row format delimited
fields terminated by '\t';

-- æ£€æŸ¥è®¾ç½®å¼€å¯åŠ¨æ€åˆ†åŒºå’Œéä¸¥æ ¼æ¨¡å¼
hive (default)> set hive.exec.dynamic.partition;
hive.exec.dynamic.partition=true

hive (default)> set hive.exec.dynamic.partition.mode;
hive.exec.dynamic.partition.mode=strict

hive (default)> set hive.exec.dynamic.partition.mode=nonstrict;
```

![image-20200722220336870](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200722220336.png)

è¿™é‡Œæœ‰ä¸ªæ³¨æ„ç‚¹ï¼š==åˆ†åŒºå­—æ®µé»˜è®¤åœ¨æœ€åä¸€åˆ—ï¼Œæ‰€ä»¥ä¹‹åæ’å…¥æ•°æ®çš„æ—¶å€™æ³¨æ„æ•°æ®çš„é¡ºåºå“¦ï¼==

æ’å…¥æ•°æ®

æ­¤æ—¶ä½¿ç”¨insertæˆ–è€…load dataéƒ½è¿˜æ˜¯ä¼šè¦æ±‚æŒ‡å®šåˆ†åŒºï¼Œ**insertç›´æ¥ä½¿ç”¨partition(grade)å°±å¯ä»¥å•¦ï¼ï¼load dataæ— æ³•ä»æ–‡æœ¬æ–‡ä»¶ä¸­æå–åˆ†åŒºåˆ—ï¼Œæ‰€ä»¥ä¸èƒ½ä½¿ç”¨load data..**ï¼Œä¸‹é¢åˆ†åˆ«æ¼”ç¤ºä½¿ç”¨insertå¯¼å…¥æ•°æ®ã€‚

**insert**å¯¼å…¥æ•°æ®

```sql
-- æ™®é€šè¡¨
create table stu_tmp(name string,age int,grade string)
row format delimited
fields terminated by '\t';

zhangsan	19	freshman
xiaoqiang	20	sophomore
liming	18	freshman
wanglei	22	junior
zhangli	22	senior
songyu	21	junior
chenkang	21	sophomore
liuyun	23	senior

-- å¯¼å…¥æ•°æ®åˆ°åŠ¨æ€åˆ†åŒºè¡¨
insert overwrite table dynamic_partition partition(grade)
select * from stu_tmp;
```

![image-20200722224730384](https://picbed-sakura.oss-cn-shanghai.aliyuncs.com/notePic/20200722224730.png)



ä¸Šé¢çš„è¿‡ç¨‹æœ‰ä¸€ä¸ªå¾ˆé‡è¦çš„æ³¨æ„ç‚¹ï¼å°±æ˜¯**å…³äºæ’å…¥æ•°æ®çš„å­—æ®µé¡ºåºã€‚**

è™½ç„¶å†™äº†`partition(grade)`ï¼Œè¿™åªèƒ½è¯´æ˜åˆ†åŒºçš„å­—æ®µåå«gradeï¼Œä½†æ˜¯å¹¶ä¸ä¼šå»selectçš„ç»“æœä¸­æ‰¾åˆ°gradeåˆ—æ¥åˆ›å»ºåˆ†åŒºï¼Œè€Œæ˜¯ä»¥åŠ¨æ€åˆ†åŒºè¡¨çš„å­—æ®µé¡ºåºä¸ºæ ‡å‡†ã€‚==é»˜è®¤åˆ†åŒºå­—æ®µåœ¨æœ€å==ï¼Œä½†æ˜¯å¦‚æœä½ æ’å…¥çš„æ•°æ®é›†æœ€åä¸€ä¸ªåˆ—å³ä½¿ä¸æ˜¯åˆ†åŒºå­—æ®µï¼Œå®ƒä¹Ÿä¼šè®¤ä¸ºè¿™ä¸€åˆ—æ•°æ®å°±æ˜¯ç”¨æ¥åˆ†åŒºçš„ï¼Œå°±ä¼šå‡ºç°è¿™ç§æƒ…å†µ

```sql
insert overwrite table dynamic_partition partition(grade)
select grade,age,name from dynamic_partition;
/*
æ’å…¥æ•°æ®é›†æœ€åä¸€ä¸ªå­—æ®µæ˜¯name,ä½†æ˜¯hiveå¹¶ä¸çŸ¥é“ï¼Œåªå¥½ç¡¬ç”Ÿç”¨nameä¹Ÿåšäº†åˆ†åŒºï¼š
    Loading partition {grade=liming}
    Loading partition {grade=chenkang}
    Loading partition {grade=liuyun}
    Loading partition {grade=xiaoqiang}
    Loading partition {grade=zhangli}
*/
```

æ‰€ä»¥==å¯¼å…¥æ•°æ®çš„æ—¶å€™åƒä¸‡è«è¦æé”™äº†å­—æ®µçš„é¡ºåºã€‚==



é™¤æ­¤ä»¥å¤–insert intoä¹Ÿæ˜¯å¯ä»¥æ’å…¥æ•°æ®çš„ï¼Œä½†æ˜¯æ•ˆç‡è¾ƒä½ï¼š

`insert into table dynamic_partition partition(grade) values('zhangqiang',19,'freshman');`



## 9.4ã€MRä¼˜åŒ–

å¯ä»¥å‚è€ƒHadoop-MapReduceå­¦ä¹ ç¬”è®°ä¸­MRè°ƒä¼˜çš„å†…å®¹ã€‚

> Mapç«¯è°ƒä¼˜

1. **åˆç†**è°ƒæ•´Mapçš„æ•°é‡
2. ç»“åˆæ•°æ®é›†è®¾ç½®åˆé€‚çš„åˆ†åŒºå¤§å°ï¼ˆå‚è€ƒMapReduceå­¦ä¹ æ–‡ä»¶ä¸­åˆ†åŒºå¤§å°è®¾ç½®ï¼‰
3. å…¶ä»–ç›¸å…³çš„è°ƒä¼˜å‚æ•°è®¾ç½®



> Reduceè°ƒæ•´

1. Reduceæ•°é‡çš„è®¾ç½®

   Reduceçš„æ•°é‡å—å¤šä¸ªæƒ…å†µçš„æ§åˆ¶ï¼Œä¼˜å…ˆçº§ä¾æ¬¡ä¸º

   - æŸ¥è¯¢è¯­å¥ä¸­ä½¿ç”¨äº†`distinct`ã€`order by`ï¼š**å¼ºåˆ¶ä½¿ç”¨ä¸€ä¸ªReduce**
   - æ‰‹åŠ¨å‚æ•°è®¾ç½®ï¼š`set mapreduce.job.reduces = n`
   - `mapreduce.job.reduces`é»˜è®¤å€¼ï¼š-1è¡¨ç¤ºæŒ‰ä»»åŠ¡è‡ªåŠ¨è®¾ç½®ï¼Œè‡ªåŠ¨é…ç½®æ¶‰åŠä»¥ä¸‹å‚æ•°
     - æ¯ä¸ªReduceå¤„ç†çš„æ•°æ®é‡`hive.exec.reducers.bytes.per.reducer=256000000` **é»˜è®¤256M**
     - æ¯ä¸ªJobçš„æœ€å¤§Reduceæ•°é‡`hive.exec.reducers.max=1009 `  **é»˜è®¤1009**
     - ==è‡ªåŠ¨è®¡ç®—reduceä¸ªæ•°==ï¼š`min(reducersæœ€å¤§å€¼, jobçš„æ€»æ•°æ®è¾“å…¥é‡/æ¯ä¸ªreducerå¤„ç†çš„æ•°æ®é‡)`

2. å…¶ä»–èµ„æºè°ƒä¼˜å‚æ•°



## 9.5ã€å…¶ä»–è°ƒä¼˜

> å¹¶è¡Œæ‰§è¡Œ

æœ‰æ—¶å€™HIveæ‰§è¡Œä¸€æ¬¡æŸ¥è¯¢çš„æ—¶å€™ï¼Œæäº¤çš„ä»»åŠ¡åˆ†ä¸ºå¤šä¸ªé˜¶æ®µï¼Œæœ‰å¯èƒ½è¿™äº›é˜¶æ®µåœ¨æ•°æ®ä¸Šå¹¶ä¸ç›¸äº’ä¾èµ–ï¼Œå¯ä»¥å¼€å¯å¹¶è¡Œæ¨¡å¼è®©å„ä¸ªé˜¶æ®µå¹¶è¡Œæ‰§è¡Œï¼Œä»¥ç¼©çŸ­æ•´ä¸ªçš„ä»»åŠ¡çš„å®Œæˆå®é™…ã€‚==ä½†æ˜¯æ¯ä¸ªé˜¶æ®µçš„MRä»»åŠ¡ä¸­åªèƒ½é¡ºåºæ‰§è¡Œ==

- å¼€å¯å¹¶è¡Œæ¨¡å¼ï¼š`set hive.exec.parallel=true`
- è®¾ç½®æœ€å¤§å¹¶è¡Œæ•°é‡ï¼š`set hive.exec.parallel.thread.number=n`é»˜è®¤å€¼ä¸º8ã€‚

å¹¶è¡Œæ¨¡å¼åªæœ‰åœ¨èµ„æºæ¯”è¾ƒç©ºé—²çš„æ—¶å€™å¼€å¯æ‰èƒ½æœ‰æ¯”è¾ƒæ˜æ˜¾çš„é€Ÿåº¦ä¼˜åŠ¿ï¼Œå½“èµ„æºç´§å¼ çš„æ—¶å€™ï¼Œå³ä½¿å¼€å¯äº†å¹¶è¡Œæ¨¡å¼ä¹Ÿæ²¡æ³•å¹¶è¡Œæ‰§è¡Œã€‚



> ä¸¥æ ¼æ¨¡å¼

è¿™é‡Œçš„ä¸¥æ ¼æ¨¡å¼å’ŒåŠ¨æ€åˆ†åŒºçš„ä¸¥æ ¼æ¨¡å¼æ˜¯ä¸¤ä¸ªèŒƒå›´ã€‚æ­¤å¤„çš„ä¸¥æ ¼æ¨¡å¼æ˜¯å…¨å±€çš„ä¸¥æ ¼æ¨¡å¼`hive.mapred.mode`ï¼Œé»˜è®¤æ˜¯éä¸¥æ ¼æ¨¡å¼`nonstrict`

```xml
<property>
    <name>hive.mapred.mode</name>
    <value>nonstrict</value>
    <description>
        The mode in which the Hive operations are being performed. 
        In strict mode, some risky queries are not allowed to run. They include:
        Cartesian Product.
        No partition being picked up for a query.
        Comparing bigints and strings.
        Comparing bigints and doubles.
        Orderby without limit.
    </description>
</property>
```

å¼€å‘åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬é€šå¸¸å°†å…¶è®¾ç½®ä¸ºä¸¥æ ¼æ¨¡å¼ï¼ˆ`strict`ï¼‰,ä¸¥æ ¼æ¨¡å¼ä¸‹ä»¥ä¸‹æ“ä½œæ˜¯ä¸å…è®¸çš„ï¼š

- ç¬›å¡å°”ç§¯
- æŸ¥è¯¢åˆ†åŒºè¡¨æ—¶ä¸æŒ‡å®šåˆ†åŒº
- æ¯”è¾ƒbigintså’Œstringæ•°æ®ã€æ¯”è¾ƒbigintså’Œdoubleæ•°æ®
- ä½¿ç”¨OrderByæ—¶ä¸ä½¿ç”¨limit



> JVMé‡ç”¨ã€æ¨æµ‹æ‰§è¡Œï¼ˆå‚è€ƒMapReduceå­¦ä¹ ç¬”è®°ï¼‰

é€‚å½“æƒ…å†µä¸‹å¼€å¯JVMé‡ç”¨å’Œæ¨æµ‹æ‰§è¡Œèƒ½å¤Ÿæé«˜ä»»åŠ¡çš„æ‰§è¡Œæ•ˆç‡ã€‚**ä½†æ˜¯å¹¶ä¸æ˜¯åªè¦å¼€å¯äº†å°±ä¸€å®šèƒ½æé«˜æ€§èƒ½ï¼**



> æ€§èƒ½åˆ†æè¯­å¥`explain`

ä½¿ç”¨explainå¯¹SQLè¿›è¡Œæ‰§è¡Œè¿‡ç¨‹æ€§èƒ½åˆ†æï¼Œæˆ‘ä»¬èƒ½å¤Ÿè¯¦ç»†çœ‹åˆ°ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­åšäº†å“ªäº›äº‹æƒ…ã€‚



